{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Example\n",
    "\n",
    "We build a simple, 2 convolutional and 1 dense layer neural  net and test it on MNIST fashion dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T01:23:01.442033Z",
     "start_time": "2018-11-24T01:22:40.864057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import E4525_ML.mnist as mnist\n",
    "from E4525_ML.TFClassifier import TFClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T01:23:01.501871Z",
     "start_time": "2018-11-24T01:23:01.446022Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "from tensorflow.keras.backend import set_session\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T01:23:01.523813Z",
     "start_time": "2018-11-24T01:23:01.506859Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data_dir=\"../../raw/fashion\"\n",
    "data_dir=\"../../data/digits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T01:23:07.444980Z",
     "start_time": "2018-11-24T01:23:01.526805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "images_filename=raw_data_dir+\"/train-images-idx3-ubyte.gz\"\n",
    "labels_filename=raw_data_dir+\"/train-labels-idx1-ubyte.gz\"\n",
    "\n",
    "test_images_filename=raw_data_dir+\"/t10k-images-idx3-ubyte.gz\"\n",
    "test_labels_filename=raw_data_dir+\"/t10k-labels-idx1-ubyte.gz\"\n",
    "\n",
    "images=mnist.read_images(images_filename)\n",
    "labels=mnist.read_labels(labels_filename)\n",
    "\n",
    "test_images=mnist.read_images(test_images_filename)\n",
    "test_labels=mnist.read_labels(test_labels_filename)\n",
    "    \n",
    "print(images.shape,labels.shape,test_images.shape,test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T01:23:08.099234Z",
     "start_time": "2018-11-24T01:23:07.448969Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    # keras needs  (Rows x Cols x Channels)\n",
    "    # we must pass input shape, summaries will not work later\n",
    "    keras.layers.Reshape((28,28,1),input_shape=(28,28)),\n",
    "    \n",
    "    \n",
    "    # Convolutional Layers\n",
    "    keras.layers.Conv2D(10, (5, 5), activation='relu',padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(20, (5, 5), activation='relu',padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    \n",
    "    # Dense Layers\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T01:23:08.741513Z",
     "start_time": "2018-11-24T01:23:08.105214Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T01:23:08.760463Z",
     "start_time": "2018-11-24T01:23:08.745502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 54,840\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Trainable parameters: {:,}'.format(model.count_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T01:23:08.817310Z",
     "start_time": "2018-11-24T01:23:08.765450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 10)        260       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 20)        5020      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 20)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 7, 7, 20)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 980)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                49050     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 54,840\n",
      "Trainable params: 54,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T02:50:36.701054Z",
     "start_time": "2018-11-24T01:39:42.905139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 35s 586us/step - loss: 0.3238 - acc: 0.8805 - val_loss: 0.2904 - val_acc: 0.8968\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 34s 574us/step - loss: 0.3021 - acc: 0.8887 - val_loss: 0.2784 - val_acc: 0.8981\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 35s 587us/step - loss: 0.2879 - acc: 0.8931 - val_loss: 0.2695 - val_acc: 0.9007\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 35s 578us/step - loss: 0.2776 - acc: 0.8968 - val_loss: 0.2585 - val_acc: 0.9053\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 35s 579us/step - loss: 0.2674 - acc: 0.9004 - val_loss: 0.2549 - val_acc: 0.9036\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 35s 579us/step - loss: 0.2588 - acc: 0.9027 - val_loss: 0.2521 - val_acc: 0.9084\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 35s 591us/step - loss: 0.2539 - acc: 0.9043 - val_loss: 0.2513 - val_acc: 0.9070\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 34s 574us/step - loss: 0.2481 - acc: 0.9073 - val_loss: 0.2454 - val_acc: 0.9088\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 34s 565us/step - loss: 0.2427 - acc: 0.9085 - val_loss: 0.2508 - val_acc: 0.9036\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 34s 570us/step - loss: 0.2387 - acc: 0.9099 - val_loss: 0.2339 - val_acc: 0.9146\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 34s 573us/step - loss: 0.2324 - acc: 0.9116 - val_loss: 0.2511 - val_acc: 0.9079\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 36s 593us/step - loss: 0.2291 - acc: 0.9135 - val_loss: 0.2376 - val_acc: 0.9134\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 35s 579us/step - loss: 0.2279 - acc: 0.9139 - val_loss: 0.2345 - val_acc: 0.9159\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 35s 584us/step - loss: 0.2231 - acc: 0.9157 - val_loss: 0.2397 - val_acc: 0.9107\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 35s 589us/step - loss: 0.2221 - acc: 0.9160 - val_loss: 0.2289 - val_acc: 0.9149\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 35s 586us/step - loss: 0.2205 - acc: 0.9163 - val_loss: 0.2310 - val_acc: 0.9166\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 35s 588us/step - loss: 0.2177 - acc: 0.9171 - val_loss: 0.2325 - val_acc: 0.9145\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 35s 590us/step - loss: 0.2155 - acc: 0.9171 - val_loss: 0.2289 - val_acc: 0.9168\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 35s 586us/step - loss: 0.2117 - acc: 0.9190 - val_loss: 0.2318 - val_acc: 0.9145\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 35s 588us/step - loss: 0.2129 - acc: 0.9196 - val_loss: 0.2333 - val_acc: 0.9150\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 35s 590us/step - loss: 0.2069 - acc: 0.9203 - val_loss: 0.2433 - val_acc: 0.9144\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 35s 590us/step - loss: 0.2068 - acc: 0.9216 - val_loss: 0.2284 - val_acc: 0.9188\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 36s 602us/step - loss: 0.2062 - acc: 0.9216 - val_loss: 0.2290 - val_acc: 0.9172\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 36s 595us/step - loss: 0.2036 - acc: 0.9228 - val_loss: 0.2298 - val_acc: 0.9153\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 36s 605us/step - loss: 0.1998 - acc: 0.9248 - val_loss: 0.2288 - val_acc: 0.9159\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 36s 607us/step - loss: 0.2043 - acc: 0.9236 - val_loss: 0.2296 - val_acc: 0.9172\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 36s 606us/step - loss: 0.1956 - acc: 0.9253 - val_loss: 0.2422 - val_acc: 0.9138\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 35s 591us/step - loss: 0.1990 - acc: 0.9237 - val_loss: 0.2273 - val_acc: 0.9179\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 36s 601us/step - loss: 0.1968 - acc: 0.9250 - val_loss: 0.2350 - val_acc: 0.9151\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 36s 595us/step - loss: 0.1950 - acc: 0.9253 - val_loss: 0.2302 - val_acc: 0.9175\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 36s 597us/step - loss: 0.1953 - acc: 0.9259 - val_loss: 0.2287 - val_acc: 0.9171\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 36s 602us/step - loss: 0.1959 - acc: 0.9251 - val_loss: 0.2259 - val_acc: 0.9172\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 37s 610us/step - loss: 0.1902 - acc: 0.9268 - val_loss: 0.2273 - val_acc: 0.9211\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 36s 607us/step - loss: 0.1893 - acc: 0.9268 - val_loss: 0.2299 - val_acc: 0.9152\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 36s 598us/step - loss: 0.1923 - acc: 0.9264 - val_loss: 0.2268 - val_acc: 0.9192\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 36s 601us/step - loss: 0.1885 - acc: 0.9280 - val_loss: 0.2312 - val_acc: 0.9191\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 37s 612us/step - loss: 0.1931 - acc: 0.9274 - val_loss: 0.2252 - val_acc: 0.9197\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 39s 645us/step - loss: 0.1869 - acc: 0.9287 - val_loss: 0.2283 - val_acc: 0.9194\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 55s 919us/step - loss: 0.1857 - acc: 0.9289 - val_loss: 0.2351 - val_acc: 0.9169\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1852 - acc: 0.9295 - val_loss: 0.2287 - val_acc: 0.9190\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 55s 923us/step - loss: 0.1842 - acc: 0.9300 - val_loss: 0.2251 - val_acc: 0.9187\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 49s 819us/step - loss: 0.1862 - acc: 0.9287 - val_loss: 0.2283 - val_acc: 0.9176\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1825 - acc: 0.9305 - val_loss: 0.2247 - val_acc: 0.9215\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.1796 - acc: 0.9307 - val_loss: 0.2309 - val_acc: 0.9174\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1812 - acc: 0.9302 - val_loss: 0.2272 - val_acc: 0.9173\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1805 - acc: 0.9304 - val_loss: 0.2254 - val_acc: 0.9209\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.1769 - acc: 0.9315 - val_loss: 0.2425 - val_acc: 0.9192\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.1789 - acc: 0.9317 - val_loss: 0.2275 - val_acc: 0.9196\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.1743 - acc: 0.9338 - val_loss: 0.2298 - val_acc: 0.9183\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.1755 - acc: 0.9315 - val_loss: 0.2360 - val_acc: 0.9186\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 105s 2ms/step - loss: 0.1768 - acc: 0.9332 - val_loss: 0.2348 - val_acc: 0.9200\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 104s 2ms/step - loss: 0.1788 - acc: 0.9310 - val_loss: 0.2317 - val_acc: 0.9191\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.1749 - acc: 0.9337 - val_loss: 0.2276 - val_acc: 0.9193\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 59s 987us/step - loss: 0.1734 - acc: 0.9336 - val_loss: 0.2369 - val_acc: 0.9186\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 51s 849us/step - loss: 0.1728 - acc: 0.9332 - val_loss: 0.2349 - val_acc: 0.9183\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 51s 852us/step - loss: 0.1765 - acc: 0.9319 - val_loss: 0.2245 - val_acc: 0.9210\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 47s 781us/step - loss: 0.1761 - acc: 0.9334 - val_loss: 0.2334 - val_acc: 0.9159\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 49s 818us/step - loss: 0.1726 - acc: 0.9341 - val_loss: 0.2331 - val_acc: 0.9166\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 37s 617us/step - loss: 0.1730 - acc: 0.9340 - val_loss: 0.2360 - val_acc: 0.9186\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 36s 596us/step - loss: 0.1694 - acc: 0.9355 - val_loss: 0.2367 - val_acc: 0.9187\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 36s 593us/step - loss: 0.1753 - acc: 0.9325 - val_loss: 0.2296 - val_acc: 0.9182\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 36s 598us/step - loss: 0.1706 - acc: 0.9344 - val_loss: 0.2407 - val_acc: 0.9196\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 36s 597us/step - loss: 0.1704 - acc: 0.9356 - val_loss: 0.2326 - val_acc: 0.9162\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 36s 601us/step - loss: 0.1678 - acc: 0.9354 - val_loss: 0.2341 - val_acc: 0.9196\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 36s 599us/step - loss: 0.1698 - acc: 0.9354 - val_loss: 0.2494 - val_acc: 0.9127\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 36s 601us/step - loss: 0.1675 - acc: 0.9359 - val_loss: 0.2342 - val_acc: 0.9175\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 36s 599us/step - loss: 0.1695 - acc: 0.9355 - val_loss: 0.2397 - val_acc: 0.9182\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 36s 600us/step - loss: 0.1662 - acc: 0.9366 - val_loss: 0.2326 - val_acc: 0.9216\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 36s 597us/step - loss: 0.1687 - acc: 0.9350 - val_loss: 0.2408 - val_acc: 0.9183\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 36s 608us/step - loss: 0.1670 - acc: 0.9356 - val_loss: 0.2316 - val_acc: 0.9181\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 36s 604us/step - loss: 0.1705 - acc: 0.9354 - val_loss: 0.2314 - val_acc: 0.9219\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 36s 599us/step - loss: 0.1669 - acc: 0.9359 - val_loss: 0.2348 - val_acc: 0.9197\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 36s 600us/step - loss: 0.1676 - acc: 0.9356 - val_loss: 0.2385 - val_acc: 0.9170\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 36s 601us/step - loss: 0.1691 - acc: 0.9352 - val_loss: 0.2398 - val_acc: 0.9148\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 36s 603us/step - loss: 0.1660 - acc: 0.9364 - val_loss: 0.2292 - val_acc: 0.9213\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 37s 611us/step - loss: 0.1660 - acc: 0.9374 - val_loss: 0.2462 - val_acc: 0.9149\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 37s 612us/step - loss: 0.1636 - acc: 0.9383 - val_loss: 0.2326 - val_acc: 0.9175\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 37s 611us/step - loss: 0.1656 - acc: 0.9368 - val_loss: 0.2360 - val_acc: 0.9200\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 37s 610us/step - loss: 0.1636 - acc: 0.9364 - val_loss: 0.2356 - val_acc: 0.9186\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 37s 610us/step - loss: 0.1642 - acc: 0.9374 - val_loss: 0.2354 - val_acc: 0.9173\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 37s 611us/step - loss: 0.1645 - acc: 0.9375 - val_loss: 0.2312 - val_acc: 0.9191\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 37s 617us/step - loss: 0.1625 - acc: 0.9375 - val_loss: 0.2354 - val_acc: 0.9175\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 37s 613us/step - loss: 0.1645 - acc: 0.9373 - val_loss: 0.2337 - val_acc: 0.9205\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 37s 612us/step - loss: 0.1619 - acc: 0.9385 - val_loss: 0.2377 - val_acc: 0.9209\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 37s 613us/step - loss: 0.1636 - acc: 0.9373 - val_loss: 0.2401 - val_acc: 0.9166\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 37s 612us/step - loss: 0.1626 - acc: 0.9373 - val_loss: 0.2301 - val_acc: 0.9193\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 37s 612us/step - loss: 0.1601 - acc: 0.9392 - val_loss: 0.2539 - val_acc: 0.9152\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 37s 614us/step - loss: 0.1616 - acc: 0.9383 - val_loss: 0.2380 - val_acc: 0.9180\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 37s 615us/step - loss: 0.1604 - acc: 0.9389 - val_loss: 0.2388 - val_acc: 0.9172\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 37s 612us/step - loss: 0.1622 - acc: 0.9391 - val_loss: 0.2346 - val_acc: 0.9180\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 37s 615us/step - loss: 0.1584 - acc: 0.9395 - val_loss: 0.2389 - val_acc: 0.9171\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 37s 614us/step - loss: 0.1626 - acc: 0.9387 - val_loss: 0.2334 - val_acc: 0.9215\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 37s 615us/step - loss: 0.1558 - acc: 0.9392 - val_loss: 0.2307 - val_acc: 0.9230\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 37s 616us/step - loss: 0.1579 - acc: 0.9401 - val_loss: 0.2504 - val_acc: 0.9143\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 38s 631us/step - loss: 0.1598 - acc: 0.9386 - val_loss: 0.2389 - val_acc: 0.9194\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 37s 617us/step - loss: 0.1584 - acc: 0.9399 - val_loss: 0.2469 - val_acc: 0.9153\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 37s 617us/step - loss: 0.1566 - acc: 0.9405 - val_loss: 0.2403 - val_acc: 0.9194\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 37s 616us/step - loss: 0.1618 - acc: 0.9389 - val_loss: 0.2388 - val_acc: 0.9192\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 37s 614us/step - loss: 0.1588 - acc: 0.9388 - val_loss: 0.2447 - val_acc: 0.9163\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 37s 615us/step - loss: 0.1587 - acc: 0.9397 - val_loss: 0.2492 - val_acc: 0.9166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x194d15354e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(images, labels, epochs=100,validation_data=(test_images,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T02:50:47.188875Z",
     "start_time": "2018-11-24T02:50:44.893299Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_pred=np.argmax(model.predict(test_images),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T02:50:47.195856Z",
     "start_time": "2018-11-24T02:50:47.189873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(Y_pred==test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
