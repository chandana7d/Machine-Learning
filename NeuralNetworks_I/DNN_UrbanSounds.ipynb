{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Neural Network on Urban Sounds Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a 2 layer dense neural network on manually engineered sound features.\n",
    "\n",
    "We perform a seach on the size of the layers and find that a very large network ($1024\\times 256$) has the best performance\n",
    "$\\approx 93$%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-14T20:15:53.841495Z",
     "start_time": "2017-12-14T20:15:53.838459Z"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T11:15:49.629370Z",
     "start_time": "2019-01-14T11:15:30.609778Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from E4525_ML.multiclass_logistic import LogisticGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Preprocessed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T11:15:49.643189Z",
     "start_time": "2019-01-14T11:15:49.629370Z"
    }
   },
   "outputs": [],
   "source": [
    "features_dir=\"../../data/UrbanSounds\"\n",
    "\n",
    "#model_dir=\"../../data/models/tf/DNN_UrbanSounds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T11:15:58.239923Z",
     "start_time": "2019-01-14T11:15:58.208676Z"
    }
   },
   "outputs": [],
   "source": [
    "filename=features_dir+\"/features.p\"\n",
    "if False:\n",
    "    features_all, labels_all = extract_features(raw_data_dir,sub_dirs)\n",
    "\n",
    "    print(features.shape)\n",
    "    file=open(filename,\"wb\")\n",
    "    pickle.dump((features_all,labels_all),file)\n",
    "else:\n",
    "    file=open(filename,\"rb\")\n",
    "    (features_all,labels_all)=pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Train, Validation and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T11:17:30.234307Z",
     "start_time": "2019-01-14T11:17:30.203045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6315, 193) (1579, 193)\n"
     ]
    }
   ],
   "source": [
    "features,features_test,labels,labels_test=train_test_split(features_all,labels_all,test_size=0.2)\n",
    "print(features.shape,features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T11:17:30.941400Z",
     "start_time": "2019-01-14T11:17:30.910248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5052, 193) (1263, 193)\n"
     ]
    }
   ],
   "source": [
    "features_train,features_val,labels_train,labels_val=train_test_split(features,labels,test_size=0.2)\n",
    "print(features_train.shape,features_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T11:17:44.689955Z",
     "start_time": "2019-01-14T11:17:44.674459Z"
    }
   },
   "outputs": [],
   "source": [
    "from E4525_ML.multiclass_logistic import LogisticGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T11:17:45.361273Z",
     "start_time": "2019-01-14T11:17:45.345812Z"
    }
   },
   "outputs": [],
   "source": [
    "model=LogisticGDClassifier(max_iter=5000,learning_rate=0.00001,penalty=0,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T11:18:27.384685Z",
     "start_time": "2019-01-14T11:17:46.039638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 0 Loss = 17230.500133554528 Train_Accuracy 0.101 Evaluation Loss = 17236.327498542756 Accuracy = 0.095\n",
      "\t 500 Loss = 1378.9783188747497 Train_Accuracy 0.728 Evaluation Loss = 2086.3886622847494 Accuracy = 0.652\n",
      "\t 1000 Loss = 1090.5553613416623 Train_Accuracy 0.753 Evaluation Loss = 1621.3227256111072 Accuracy = 0.717\n",
      "\t 1500 Loss = 1071.4710925530858 Train_Accuracy 0.728 Evaluation Loss = 1742.960867906273 Accuracy = 0.66\n",
      "\t 2000 Loss = 1251.4246682693833 Train_Accuracy 0.708 Evaluation Loss = 2093.626369116404 Accuracy = 0.642\n",
      "\t 2500 Loss = 1707.3824058997084 Train_Accuracy 0.686 Evaluation Loss = 2058.521991152697 Accuracy = 0.656\n",
      "\t 3000 Loss = 1227.8340993865377 Train_Accuracy 0.728 Evaluation Loss = 1608.0907181922464 Accuracy = 0.706\n",
      "\t 3500 Loss = 1480.126926306245 Train_Accuracy 0.708 Evaluation Loss = 1941.0545027393428 Accuracy = 0.663\n",
      "\t 4000 Loss = 1621.0287739350847 Train_Accuracy 0.689 Evaluation Loss = 2348.7527980251734 Accuracy = 0.646\n",
      "\t 4500 Loss = 1331.2192035831063 Train_Accuracy 0.72 Evaluation Loss = 2128.9095819740987 Accuracy = 0.678\n",
      "\t 4999 Loss = 1205.6308494219707 Train_Accuracy 0.752 Evaluation Loss = 1905.9925046936128 Accuracy = 0.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Training accuracy', 0.7404988123515439)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features_train.reshape(len(features_train),-1),labels_train,features_val.reshape(len(features_val),-1),labels_val)\n",
    "Y_pred=model.predict(features_train.reshape(len(features_train),-1))\n",
    "\"Training accuracy\",np.mean(Y_pred==labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T11:18:27.400305Z",
     "start_time": "2019-01-14T11:18:27.384685Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Test Accuracy', 0.694110196326789)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred=model.predict(features_test.reshape((len(features_test),-1)))\n",
    "\"Test Accuracy\",np.mean(Y_pred==labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Dense Neural Network on Urban Sound Features Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T10:17:45.922681Z",
     "start_time": "2019-01-15T10:17:45.907088Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T11:39:40.112393Z",
     "start_time": "2019-01-14T11:39:40.096902Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReportCallback(keras.callbacks.Callback):\n",
    "    def __init__(self,frequency,use_val=True):\n",
    "        self.freq=frequency\n",
    "        self.use_val=use_val\n",
    "        self.separator=\" || \"\n",
    "        if not(self.use_val):\n",
    "            self.separator=\"\\n\"\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (epoch % self.freq ==0):\n",
    "            train_loss=logs[\"loss\"]\n",
    "            train_acc=logs[\"acc\"]\n",
    "            print(f\"\\t{epoch}: TRAIN loss {train_loss:.4f},  acc {train_acc:.4f}\",end=self.separator)\n",
    "            if self.use_val:\n",
    "                val_loss=logs[\"val_loss\"]\n",
    "                val_acc=logs[\"val_acc\"]\n",
    "                print(f\"VAL loss {val_loss:.4f}, acc {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T11:51:14.412879Z",
     "start_time": "2019-01-14T11:51:14.397259Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(hidden1,hidden2):\n",
    "    model=keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(193,)),\n",
    "        keras.layers.Dense(hidden1,activation=\"relu\"),\n",
    "        keras.layers.Dense(hidden2,activation=\"relu\"),\n",
    "        keras.layers.Dense(num_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    optimizer=keras.optimizers.Adam(lr=0.001,decay=1e-4)\n",
    "    model.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T11:51:15.236937Z",
     "start_time": "2019-01-14T11:51:15.101198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_11 (Flatten)         (None, 193)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 512)               99328     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 233,226\n",
      "Trainable params: 233,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model0=build_model(512,256)\n",
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T11:51:16.269383Z",
     "start_time": "2019-01-14T11:51:16.253836Z"
    }
   },
   "outputs": [],
   "source": [
    "nepochs=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T11:52:04.657209Z",
     "start_time": "2019-01-14T11:51:17.005401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0: TRAIN loss 7.7082,  acc 0.3294 || VAL loss 4.4935, acc 0.4402\n",
      "\t10: TRAIN loss 1.2543,  acc 0.8268 || VAL loss 1.6064, acc 0.7728\n",
      "\t20: TRAIN loss 0.9637,  acc 0.9082 || VAL loss 1.3789, acc 0.8353\n",
      "\t30: TRAIN loss 1.0119,  acc 0.9024 || VAL loss 1.4670, acc 0.8242\n",
      "\t40: TRAIN loss 0.8720,  acc 0.9343 || VAL loss 1.3735, acc 0.8480\n",
      "\t50: TRAIN loss 0.8426,  acc 0.9430 || VAL loss 1.3005, acc 0.8686\n",
      "\t60: TRAIN loss 0.8639,  acc 0.9353 || VAL loss 1.4006, acc 0.8535\n",
      "\t70: TRAIN loss 0.8953,  acc 0.9355 || VAL loss 1.3529, acc 0.8717\n",
      "\t80: TRAIN loss 0.8676,  acc 0.9446 || VAL loss 1.3349, acc 0.8812\n",
      "\t90: TRAIN loss 0.8347,  acc 0.9475 || VAL loss 1.3023, acc 0.8836\n",
      "\t100: TRAIN loss 0.4555,  acc 0.9238 || VAL loss 0.7997, acc 0.8749\n",
      "\t110: TRAIN loss 0.1863,  acc 0.9800 || VAL loss 0.6903, acc 0.9018\n",
      "\t120: TRAIN loss 0.1343,  acc 0.9905 || VAL loss 0.6449, acc 0.9145\n",
      "\t130: TRAIN loss 0.1319,  acc 0.9907 || VAL loss 0.6234, acc 0.9177\n",
      "\t140: TRAIN loss 0.1316,  acc 0.9903 || VAL loss 0.6178, acc 0.9216\n",
      "\t150: TRAIN loss 0.1779,  acc 0.9727 || VAL loss 0.6618, acc 0.9066\n",
      "\t160: TRAIN loss 0.0933,  acc 0.9929 || VAL loss 0.6168, acc 0.9161\n",
      "\t170: TRAIN loss 0.0930,  acc 0.9927 || VAL loss 0.6279, acc 0.9200\n",
      "\t180: TRAIN loss 0.0942,  acc 0.9929 || VAL loss 0.6231, acc 0.9153\n",
      "\t190: TRAIN loss 0.1808,  acc 0.9834 || VAL loss 0.6103, acc 0.9153\n",
      "\t200: TRAIN loss 0.1468,  acc 0.9897 || VAL loss 0.5236, acc 0.9264\n",
      "\t210: TRAIN loss 0.1032,  acc 0.9915 || VAL loss 0.5714, acc 0.9216\n",
      "\t220: TRAIN loss 0.1027,  acc 0.9925 || VAL loss 0.5616, acc 0.9248\n",
      "\t230: TRAIN loss 0.1025,  acc 0.9919 || VAL loss 0.5708, acc 0.9216\n",
      "\t240: TRAIN loss 0.1034,  acc 0.9917 || VAL loss 0.5644, acc 0.9224\n",
      "\t250: TRAIN loss 0.1148,  acc 0.9905 || VAL loss 0.5867, acc 0.9192\n",
      "\t260: TRAIN loss 0.1110,  acc 0.9921 || VAL loss 0.5917, acc 0.9264\n",
      "\t270: TRAIN loss 0.1122,  acc 0.9917 || VAL loss 0.6038, acc 0.9248\n",
      "\t280: TRAIN loss 0.1116,  acc 0.9911 || VAL loss 0.6128, acc 0.9272\n",
      "\t290: TRAIN loss 0.1109,  acc 0.9919 || VAL loss 0.6125, acc 0.9279\n"
     ]
    }
   ],
   "source": [
    "result=model0.fit(features_train,labels_train,validation_data=(features_val,labels_val),\n",
    "                  epochs=nepochs,batch_size=100,\n",
    "                  verbose=0,callbacks=[ReportCallback(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T11:52:10.022820Z",
     "start_time": "2019-01-14T11:52:09.766523Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x235cd25a320>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history=result.history\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history[\"loss\"],label=\"loss\")\n",
    "plt.plot(history[\"val_loss\"],label=\"valuation loss\")\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history[\"acc\"],label=\"accuracy\")\n",
    "plt.plot(history[\"val_acc\"],label=\"valuation accuracy\")\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T11:53:06.532915Z",
     "start_time": "2019-01-14T11:53:06.310672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9287410926365796"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred=np.argmax(model0.predict(features_val),axis=1)\n",
    "np.mean(Y_pred==labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now search on parameter space for the optimal size of both layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T13:01:03.497927Z",
     "start_time": "2019-01-14T11:55:46.613951Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0: TRAIN loss 5.7940,  acc 0.1261 || VAL loss 3.1946, acc 0.1449\n",
      "\t10: TRAIN loss 1.4170,  acc 0.5230 || VAL loss 1.4787, acc 0.5099\n",
      "\t20: TRAIN loss 1.0940,  acc 0.6243 || VAL loss 1.2365, acc 0.6160\n",
      "\t30: TRAIN loss 0.9605,  acc 0.6746 || VAL loss 1.1408, acc 0.6477\n",
      "\t40: TRAIN loss 0.8611,  acc 0.7068 || VAL loss 1.1029, acc 0.6722\n",
      "\t50: TRAIN loss 0.7923,  acc 0.7276 || VAL loss 1.0738, acc 0.6912\n",
      "\t60: TRAIN loss 0.7285,  acc 0.7530 || VAL loss 1.0477, acc 0.7023\n",
      "\t70: TRAIN loss 0.6936,  acc 0.7694 || VAL loss 1.0147, acc 0.7268\n",
      "\t80: TRAIN loss 0.6400,  acc 0.7914 || VAL loss 0.9891, acc 0.7427\n",
      "\t90: TRAIN loss 0.6112,  acc 0.8011 || VAL loss 0.9839, acc 0.7348\n",
      "\t100: TRAIN loss 0.5937,  acc 0.8007 || VAL loss 0.9708, acc 0.7530\n",
      "\t110: TRAIN loss 0.5573,  acc 0.8151 || VAL loss 0.9699, acc 0.7411\n",
      "\t120: TRAIN loss 0.5315,  acc 0.8268 || VAL loss 0.9921, acc 0.7451\n",
      "\t130: TRAIN loss 0.5116,  acc 0.8369 || VAL loss 0.9930, acc 0.7451\n",
      "\t140: TRAIN loss 0.4953,  acc 0.8411 || VAL loss 0.9943, acc 0.7451\n",
      "\t150: TRAIN loss 0.4833,  acc 0.8450 || VAL loss 0.9607, acc 0.7538\n",
      "\t160: TRAIN loss 0.4770,  acc 0.8476 || VAL loss 0.9837, acc 0.7514\n",
      "\t170: TRAIN loss 0.4572,  acc 0.8510 || VAL loss 0.9702, acc 0.7546\n",
      "\t180: TRAIN loss 0.4479,  acc 0.8567 || VAL loss 0.9821, acc 0.7530\n",
      "\t190: TRAIN loss 0.4486,  acc 0.8561 || VAL loss 0.9960, acc 0.7577\n",
      "\t200: TRAIN loss 0.4273,  acc 0.8644 || VAL loss 0.9878, acc 0.7585\n",
      "\t210: TRAIN loss 0.4204,  acc 0.8644 || VAL loss 0.9972, acc 0.7569\n",
      "\t220: TRAIN loss 0.4182,  acc 0.8658 || VAL loss 1.0112, acc 0.7577\n",
      "\t230: TRAIN loss 0.4070,  acc 0.8725 || VAL loss 1.0213, acc 0.7538\n",
      "\t240: TRAIN loss 0.3996,  acc 0.8739 || VAL loss 1.0355, acc 0.7585\n",
      "\t250: TRAIN loss 0.3922,  acc 0.8739 || VAL loss 1.0270, acc 0.7546\n",
      "\t260: TRAIN loss 0.3941,  acc 0.8755 || VAL loss 1.0189, acc 0.7577\n",
      "\t270: TRAIN loss 0.3826,  acc 0.8775 || VAL loss 1.0275, acc 0.7617\n",
      "\t280: TRAIN loss 0.3804,  acc 0.8791 || VAL loss 1.0325, acc 0.7617\n",
      "\t290: TRAIN loss 0.3862,  acc 0.8765 || VAL loss 1.0514, acc 0.7648\n",
      "16 16 0.8846001583531274 0.7624703087885986\n",
      "\t0: TRAIN loss 6.7651,  acc 0.1817 || VAL loss 5.3007, acc 0.2193\n",
      "\t10: TRAIN loss 1.2046,  acc 0.6031 || VAL loss 1.4124, acc 0.5883\n",
      "\t20: TRAIN loss 0.9073,  acc 0.6964 || VAL loss 1.0938, acc 0.6698\n",
      "\t30: TRAIN loss 0.7574,  acc 0.7482 || VAL loss 0.9654, acc 0.7221\n",
      "\t40: TRAIN loss 0.6816,  acc 0.7817 || VAL loss 0.9357, acc 0.7427\n",
      "\t50: TRAIN loss 0.5999,  acc 0.8086 || VAL loss 0.8687, acc 0.7736\n",
      "\t60: TRAIN loss 0.5584,  acc 0.8201 || VAL loss 0.8327, acc 0.7775\n",
      "\t70: TRAIN loss 0.5196,  acc 0.8319 || VAL loss 0.8200, acc 0.7854\n",
      "\t80: TRAIN loss 0.4771,  acc 0.8438 || VAL loss 0.8080, acc 0.7941\n",
      "\t90: TRAIN loss 0.4489,  acc 0.8519 || VAL loss 0.8131, acc 0.7981\n",
      "\t100: TRAIN loss 0.4343,  acc 0.8575 || VAL loss 0.8687, acc 0.7878\n",
      "\t110: TRAIN loss 0.4060,  acc 0.8676 || VAL loss 0.8637, acc 0.7973\n",
      "\t120: TRAIN loss 0.3867,  acc 0.8684 || VAL loss 0.8886, acc 0.7862\n",
      "\t130: TRAIN loss 0.3720,  acc 0.8761 || VAL loss 0.8986, acc 0.7973\n",
      "\t140: TRAIN loss 0.3606,  acc 0.8808 || VAL loss 0.9060, acc 0.7965\n",
      "\t150: TRAIN loss 0.3485,  acc 0.8854 || VAL loss 0.9123, acc 0.7918\n",
      "\t160: TRAIN loss 0.3360,  acc 0.8919 || VAL loss 0.9429, acc 0.7918\n",
      "\t170: TRAIN loss 0.3297,  acc 0.8923 || VAL loss 0.9527, acc 0.7910\n",
      "\t180: TRAIN loss 0.3199,  acc 0.8959 || VAL loss 0.9303, acc 0.8029\n",
      "\t190: TRAIN loss 0.3085,  acc 0.8985 || VAL loss 0.9446, acc 0.7933\n",
      "\t200: TRAIN loss 0.3091,  acc 0.9014 || VAL loss 0.9428, acc 0.7981\n",
      "\t210: TRAIN loss 0.2987,  acc 0.9028 || VAL loss 0.9683, acc 0.7973\n",
      "\t220: TRAIN loss 0.2959,  acc 0.9038 || VAL loss 0.9604, acc 0.8005\n",
      "\t230: TRAIN loss 0.2844,  acc 0.9084 || VAL loss 0.9554, acc 0.8044\n",
      "\t240: TRAIN loss 0.2863,  acc 0.9097 || VAL loss 0.9944, acc 0.7981\n",
      "\t250: TRAIN loss 0.2726,  acc 0.9086 || VAL loss 0.9714, acc 0.8005\n",
      "\t260: TRAIN loss 0.2704,  acc 0.9133 || VAL loss 0.9736, acc 0.8092\n",
      "\t270: TRAIN loss 0.2592,  acc 0.9179 || VAL loss 1.0183, acc 0.8029\n",
      "\t280: TRAIN loss 0.2551,  acc 0.9198 || VAL loss 0.9824, acc 0.8108\n",
      "\t290: TRAIN loss 0.2524,  acc 0.9181 || VAL loss 0.9987, acc 0.8100\n",
      "16 32 0.9231987331749802 0.8060174188440221\n",
      "\t0: TRAIN loss 6.8780,  acc 0.1791 || VAL loss 3.0224, acc 0.2842\n",
      "\t10: TRAIN loss 1.0689,  acc 0.6679 || VAL loss 1.2050, acc 0.6453\n",
      "\t20: TRAIN loss 0.7947,  acc 0.7413 || VAL loss 1.0277, acc 0.7023\n",
      "\t30: TRAIN loss 0.6664,  acc 0.7791 || VAL loss 0.9518, acc 0.7253\n",
      "\t40: TRAIN loss 0.5661,  acc 0.8131 || VAL loss 0.8999, acc 0.7633\n",
      "\t50: TRAIN loss 0.4956,  acc 0.8345 || VAL loss 0.9041, acc 0.7783\n",
      "\t60: TRAIN loss 0.4523,  acc 0.8567 || VAL loss 0.9118, acc 0.7759\n",
      "\t70: TRAIN loss 0.3991,  acc 0.8698 || VAL loss 0.8779, acc 0.7910\n",
      "\t80: TRAIN loss 0.3948,  acc 0.8775 || VAL loss 0.8680, acc 0.8029\n",
      "\t90: TRAIN loss 0.3557,  acc 0.8852 || VAL loss 0.8747, acc 0.7918\n",
      "\t100: TRAIN loss 0.3160,  acc 0.8977 || VAL loss 0.8613, acc 0.8084\n",
      "\t110: TRAIN loss 0.2921,  acc 0.9056 || VAL loss 0.8771, acc 0.8052\n",
      "\t120: TRAIN loss 0.2874,  acc 0.9058 || VAL loss 0.8565, acc 0.7973\n",
      "\t130: TRAIN loss 0.2482,  acc 0.9216 || VAL loss 0.8453, acc 0.8084\n",
      "\t140: TRAIN loss 0.2441,  acc 0.9200 || VAL loss 0.8563, acc 0.8092\n",
      "\t150: TRAIN loss 0.2224,  acc 0.9291 || VAL loss 0.8713, acc 0.7997\n",
      "\t160: TRAIN loss 0.2476,  acc 0.9242 || VAL loss 0.9016, acc 0.8100\n",
      "\t170: TRAIN loss 0.2018,  acc 0.9355 || VAL loss 0.9123, acc 0.8147\n",
      "\t180: TRAIN loss 0.1921,  acc 0.9400 || VAL loss 0.9137, acc 0.8044\n",
      "\t190: TRAIN loss 0.1832,  acc 0.9428 || VAL loss 0.9252, acc 0.8052\n",
      "\t200: TRAIN loss 0.1781,  acc 0.9464 || VAL loss 0.9403, acc 0.8044\n",
      "\t210: TRAIN loss 0.1998,  acc 0.9384 || VAL loss 1.0023, acc 0.8116\n",
      "\t220: TRAIN loss 0.1636,  acc 0.9511 || VAL loss 0.9784, acc 0.8076\n",
      "\t230: TRAIN loss 0.1540,  acc 0.9549 || VAL loss 0.9861, acc 0.8124\n",
      "\t240: TRAIN loss 0.1489,  acc 0.9561 || VAL loss 0.9985, acc 0.8108\n",
      "\t250: TRAIN loss 0.1449,  acc 0.9586 || VAL loss 1.0249, acc 0.8124\n",
      "\t260: TRAIN loss 0.1386,  acc 0.9590 || VAL loss 1.0345, acc 0.8029\n",
      "\t270: TRAIN loss 0.1309,  acc 0.9630 || VAL loss 1.0317, acc 0.8124\n",
      "\t280: TRAIN loss 0.1359,  acc 0.9590 || VAL loss 1.0458, acc 0.8076\n",
      "\t290: TRAIN loss 0.1335,  acc 0.9622 || VAL loss 1.0991, acc 0.8076\n",
      "16 64 0.9675376088677752 0.8131433095803642\n",
      "\t0: TRAIN loss 3.3600,  acc 0.2492 || VAL loss 2.0548, acc 0.3721\n",
      "\t10: TRAIN loss 1.0011,  acc 0.6623 || VAL loss 1.1063, acc 0.6667\n",
      "\t20: TRAIN loss 0.7719,  acc 0.7445 || VAL loss 1.0107, acc 0.6975\n",
      "\t30: TRAIN loss 0.6296,  acc 0.8056 || VAL loss 0.9063, acc 0.7506\n",
      "\t40: TRAIN loss 0.5164,  acc 0.8385 || VAL loss 0.8705, acc 0.7728\n",
      "\t50: TRAIN loss 0.4531,  acc 0.8567 || VAL loss 0.8272, acc 0.7862\n",
      "\t60: TRAIN loss 0.4048,  acc 0.8781 || VAL loss 0.8026, acc 0.7886\n",
      "\t70: TRAIN loss 0.3636,  acc 0.8903 || VAL loss 0.7847, acc 0.8013\n",
      "\t80: TRAIN loss 0.3109,  acc 0.9111 || VAL loss 0.7831, acc 0.8084\n",
      "\t90: TRAIN loss 0.2879,  acc 0.9161 || VAL loss 0.7480, acc 0.8179\n",
      "\t100: TRAIN loss 0.2654,  acc 0.9194 || VAL loss 0.7803, acc 0.8108\n",
      "\t110: TRAIN loss 0.2411,  acc 0.9262 || VAL loss 0.7712, acc 0.8361\n",
      "\t120: TRAIN loss 0.2352,  acc 0.9349 || VAL loss 0.7902, acc 0.8290\n",
      "\t130: TRAIN loss 0.2185,  acc 0.9365 || VAL loss 0.8463, acc 0.8179\n",
      "\t140: TRAIN loss 0.2418,  acc 0.9246 || VAL loss 0.7757, acc 0.8385\n",
      "\t150: TRAIN loss 0.1891,  acc 0.9454 || VAL loss 0.8152, acc 0.8226\n",
      "\t160: TRAIN loss 0.1697,  acc 0.9529 || VAL loss 0.8413, acc 0.8226\n",
      "\t170: TRAIN loss 0.1619,  acc 0.9515 || VAL loss 0.8450, acc 0.8393\n",
      "\t180: TRAIN loss 0.1624,  acc 0.9505 || VAL loss 0.8886, acc 0.8345\n",
      "\t190: TRAIN loss 0.1495,  acc 0.9567 || VAL loss 0.8699, acc 0.8337\n",
      "\t200: TRAIN loss 0.1453,  acc 0.9600 || VAL loss 0.8622, acc 0.8329\n",
      "\t210: TRAIN loss 0.1331,  acc 0.9628 || VAL loss 0.9045, acc 0.8345\n",
      "\t220: TRAIN loss 0.1264,  acc 0.9650 || VAL loss 0.9163, acc 0.8393\n",
      "\t230: TRAIN loss 0.1206,  acc 0.9687 || VAL loss 0.9292, acc 0.8377\n",
      "\t240: TRAIN loss 0.1087,  acc 0.9731 || VAL loss 1.0012, acc 0.8258\n",
      "\t250: TRAIN loss 0.1040,  acc 0.9737 || VAL loss 0.9410, acc 0.8409\n",
      "\t260: TRAIN loss 0.1000,  acc 0.9784 || VAL loss 0.9647, acc 0.8306\n",
      "\t270: TRAIN loss 0.0958,  acc 0.9784 || VAL loss 1.0132, acc 0.8369\n",
      "\t280: TRAIN loss 0.0926,  acc 0.9778 || VAL loss 1.0344, acc 0.8298\n",
      "\t290: TRAIN loss 0.0884,  acc 0.9808 || VAL loss 1.0451, acc 0.8369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 128 0.9853523357086302 0.836104513064133\n",
      "\t0: TRAIN loss 3.2002,  acc 0.2755 || VAL loss 1.8597, acc 0.4442\n",
      "\t10: TRAIN loss 0.8057,  acc 0.7310 || VAL loss 0.9956, acc 0.7031\n",
      "\t20: TRAIN loss 0.5513,  acc 0.8215 || VAL loss 0.8764, acc 0.7672\n",
      "\t30: TRAIN loss 0.4327,  acc 0.8577 || VAL loss 0.8208, acc 0.7870\n",
      "\t40: TRAIN loss 0.4253,  acc 0.8624 || VAL loss 0.8416, acc 0.7965\n",
      "\t50: TRAIN loss 0.2830,  acc 0.9099 || VAL loss 0.7315, acc 0.8290\n",
      "\t60: TRAIN loss 0.2522,  acc 0.9196 || VAL loss 0.7180, acc 0.8440\n",
      "\t70: TRAIN loss 0.1966,  acc 0.9408 || VAL loss 0.7195, acc 0.8401\n",
      "\t80: TRAIN loss 0.1659,  acc 0.9553 || VAL loss 0.7413, acc 0.8480\n",
      "\t90: TRAIN loss 0.1387,  acc 0.9630 || VAL loss 0.7878, acc 0.8424\n",
      "\t100: TRAIN loss 0.1167,  acc 0.9715 || VAL loss 0.8206, acc 0.8409\n",
      "\t110: TRAIN loss 0.1007,  acc 0.9759 || VAL loss 0.8107, acc 0.8496\n",
      "\t120: TRAIN loss 0.0825,  acc 0.9814 || VAL loss 0.8289, acc 0.8559\n",
      "\t130: TRAIN loss 0.0704,  acc 0.9844 || VAL loss 0.8623, acc 0.8511\n",
      "\t140: TRAIN loss 0.1635,  acc 0.9592 || VAL loss 1.0081, acc 0.8337\n",
      "\t150: TRAIN loss 0.0633,  acc 0.9869 || VAL loss 0.8903, acc 0.8480\n",
      "\t160: TRAIN loss 0.0552,  acc 0.9897 || VAL loss 0.9109, acc 0.8504\n",
      "\t170: TRAIN loss 0.0503,  acc 0.9913 || VAL loss 0.9230, acc 0.8527\n",
      "\t180: TRAIN loss 0.0441,  acc 0.9933 || VAL loss 0.9301, acc 0.8543\n",
      "\t190: TRAIN loss 0.0397,  acc 0.9941 || VAL loss 0.9628, acc 0.8543\n",
      "\t200: TRAIN loss 0.0377,  acc 0.9952 || VAL loss 0.9678, acc 0.8575\n",
      "\t210: TRAIN loss 0.0354,  acc 0.9949 || VAL loss 0.9958, acc 0.8567\n",
      "\t220: TRAIN loss 0.0338,  acc 0.9958 || VAL loss 1.0389, acc 0.8496\n",
      "\t230: TRAIN loss 0.0293,  acc 0.9968 || VAL loss 1.0375, acc 0.8543\n",
      "\t240: TRAIN loss 0.0287,  acc 0.9972 || VAL loss 1.0359, acc 0.8583\n",
      "\t250: TRAIN loss 0.0258,  acc 0.9976 || VAL loss 1.0356, acc 0.8551\n",
      "\t260: TRAIN loss 0.0236,  acc 0.9980 || VAL loss 1.0561, acc 0.8551\n",
      "\t270: TRAIN loss 0.0232,  acc 0.9980 || VAL loss 1.0623, acc 0.8551\n",
      "\t280: TRAIN loss 0.0236,  acc 0.9976 || VAL loss 1.0696, acc 0.8599\n",
      "\t290: TRAIN loss 0.0438,  acc 0.9919 || VAL loss 1.1169, acc 0.8527\n",
      "16 256 0.9984164687252574 0.8574821852731591\n",
      "\t0: TRAIN loss 2.3088,  acc 0.3108 || VAL loss 1.7352, acc 0.4331\n",
      "\t10: TRAIN loss 0.8366,  acc 0.7177 || VAL loss 1.0210, acc 0.6912\n",
      "\t20: TRAIN loss 0.6149,  acc 0.7971 || VAL loss 0.9526, acc 0.7427\n",
      "\t30: TRAIN loss 0.4861,  acc 0.8444 || VAL loss 0.8670, acc 0.7743\n",
      "\t40: TRAIN loss 0.3769,  acc 0.8804 || VAL loss 0.8183, acc 0.7957\n",
      "\t50: TRAIN loss 0.3561,  acc 0.8858 || VAL loss 0.8250, acc 0.7957\n",
      "\t60: TRAIN loss 0.2672,  acc 0.9157 || VAL loss 0.8239, acc 0.8060\n",
      "\t70: TRAIN loss 0.2240,  acc 0.9268 || VAL loss 0.8154, acc 0.8187\n",
      "\t80: TRAIN loss 0.1953,  acc 0.9380 || VAL loss 0.7966, acc 0.8226\n",
      "\t90: TRAIN loss 0.1608,  acc 0.9505 || VAL loss 0.8309, acc 0.8266\n",
      "\t100: TRAIN loss 0.1452,  acc 0.9588 || VAL loss 0.8199, acc 0.8266\n",
      "\t110: TRAIN loss 0.1266,  acc 0.9622 || VAL loss 0.8650, acc 0.8290\n",
      "\t120: TRAIN loss 0.0989,  acc 0.9719 || VAL loss 0.9013, acc 0.8314\n",
      "\t130: TRAIN loss 0.0967,  acc 0.9707 || VAL loss 0.9257, acc 0.8345\n",
      "\t140: TRAIN loss 0.1056,  acc 0.9764 || VAL loss 0.9728, acc 0.8290\n",
      "\t150: TRAIN loss 0.1780,  acc 0.9563 || VAL loss 1.0928, acc 0.8131\n",
      "\t160: TRAIN loss 0.0642,  acc 0.9844 || VAL loss 0.9588, acc 0.8409\n",
      "\t170: TRAIN loss 0.0576,  acc 0.9867 || VAL loss 0.9955, acc 0.8377\n",
      "\t180: TRAIN loss 0.0523,  acc 0.9875 || VAL loss 0.9950, acc 0.8480\n",
      "\t190: TRAIN loss 0.0508,  acc 0.9881 || VAL loss 1.0704, acc 0.8337\n",
      "\t200: TRAIN loss 0.0404,  acc 0.9917 || VAL loss 1.0588, acc 0.8440\n",
      "\t210: TRAIN loss 0.0394,  acc 0.9921 || VAL loss 1.0909, acc 0.8353\n",
      "\t220: TRAIN loss 0.0355,  acc 0.9943 || VAL loss 1.0857, acc 0.8377\n",
      "\t230: TRAIN loss 0.0404,  acc 0.9923 || VAL loss 1.0940, acc 0.8337\n",
      "\t240: TRAIN loss 0.0313,  acc 0.9945 || VAL loss 1.1031, acc 0.8416\n",
      "\t250: TRAIN loss 0.0299,  acc 0.9949 || VAL loss 1.1286, acc 0.8361\n",
      "\t260: TRAIN loss 0.0283,  acc 0.9964 || VAL loss 1.1519, acc 0.8353\n",
      "\t270: TRAIN loss 0.0269,  acc 0.9964 || VAL loss 1.1406, acc 0.8337\n",
      "\t280: TRAIN loss 0.0630,  acc 0.9881 || VAL loss 1.1968, acc 0.8353\n",
      "\t290: TRAIN loss 0.0257,  acc 0.9974 || VAL loss 1.2060, acc 0.8416\n",
      "16 512 0.9978226444972288 0.8424386381631037\n",
      "\t0: TRAIN loss 2.3574,  acc 0.3298 || VAL loss 1.6554, acc 0.4806\n",
      "\t10: TRAIN loss 0.6637,  acc 0.7862 || VAL loss 0.9266, acc 0.7577\n",
      "\t20: TRAIN loss 0.4235,  acc 0.8608 || VAL loss 0.7481, acc 0.8171\n",
      "\t30: TRAIN loss 0.2516,  acc 0.9194 || VAL loss 0.7165, acc 0.8290\n",
      "\t40: TRAIN loss 0.2013,  acc 0.9426 || VAL loss 0.6611, acc 0.8535\n",
      "\t50: TRAIN loss 0.1510,  acc 0.9559 || VAL loss 0.6777, acc 0.8567\n",
      "\t60: TRAIN loss 0.0802,  acc 0.9790 || VAL loss 0.6530, acc 0.8622\n",
      "\t70: TRAIN loss 0.0923,  acc 0.9760 || VAL loss 0.7499, acc 0.8448\n",
      "\t80: TRAIN loss 0.0391,  acc 0.9923 || VAL loss 0.7048, acc 0.8694\n",
      "\t90: TRAIN loss 0.1697,  acc 0.9513 || VAL loss 0.8549, acc 0.8440\n",
      "\t100: TRAIN loss 0.0313,  acc 0.9941 || VAL loss 0.7367, acc 0.8773\n",
      "\t110: TRAIN loss 0.0192,  acc 0.9976 || VAL loss 0.7372, acc 0.8812\n",
      "\t120: TRAIN loss 0.0178,  acc 0.9974 || VAL loss 0.7609, acc 0.8789\n",
      "\t130: TRAIN loss 0.0157,  acc 0.9980 || VAL loss 0.7779, acc 0.8781\n",
      "\t140: TRAIN loss 0.0342,  acc 0.9905 || VAL loss 0.7989, acc 0.8757\n",
      "\t150: TRAIN loss 0.0110,  acc 0.9984 || VAL loss 0.8151, acc 0.8844\n",
      "\t160: TRAIN loss 0.0098,  acc 0.9984 || VAL loss 0.8406, acc 0.8820\n",
      "\t170: TRAIN loss 0.0434,  acc 0.9911 || VAL loss 0.9124, acc 0.8614\n",
      "\t180: TRAIN loss 0.0107,  acc 0.9978 || VAL loss 0.8268, acc 0.8789\n",
      "\t190: TRAIN loss 0.0083,  acc 0.9986 || VAL loss 0.8405, acc 0.8860\n",
      "\t200: TRAIN loss 0.0080,  acc 0.9986 || VAL loss 0.8513, acc 0.8804\n",
      "\t210: TRAIN loss 0.0109,  acc 0.9976 || VAL loss 0.8563, acc 0.8812\n",
      "\t220: TRAIN loss 0.0091,  acc 0.9980 || VAL loss 0.8708, acc 0.8812\n",
      "\t230: TRAIN loss 0.0142,  acc 0.9970 || VAL loss 0.8702, acc 0.8797\n",
      "\t240: TRAIN loss 0.0096,  acc 0.9984 || VAL loss 0.8747, acc 0.8765\n",
      "\t250: TRAIN loss 0.0096,  acc 0.9980 || VAL loss 0.8640, acc 0.8757\n",
      "\t260: TRAIN loss 0.0094,  acc 0.9976 || VAL loss 0.8880, acc 0.8773\n",
      "\t270: TRAIN loss 0.0059,  acc 0.9988 || VAL loss 0.8967, acc 0.8757\n",
      "\t280: TRAIN loss 0.0095,  acc 0.9984 || VAL loss 0.9110, acc 0.8789\n",
      "\t290: TRAIN loss 0.0085,  acc 0.9978 || VAL loss 0.8968, acc 0.8773\n",
      "16 1024 0.9990102929532858 0.8780680918448139\n",
      "\t0: TRAIN loss 9.8292,  acc 0.1354 || VAL loss 5.7274, acc 0.1615\n",
      "\t10: TRAIN loss 1.3140,  acc 0.5592 || VAL loss 1.4933, acc 0.5447\n",
      "\t20: TRAIN loss 0.9557,  acc 0.6886 || VAL loss 1.1776, acc 0.6556\n",
      "\t30: TRAIN loss 0.7658,  acc 0.7546 || VAL loss 1.0157, acc 0.7173\n",
      "\t40: TRAIN loss 0.6162,  acc 0.8046 || VAL loss 0.9103, acc 0.7403\n",
      "\t50: TRAIN loss 0.5108,  acc 0.8375 || VAL loss 0.8362, acc 0.7712\n",
      "\t60: TRAIN loss 0.4622,  acc 0.8494 || VAL loss 0.8694, acc 0.7886\n",
      "\t70: TRAIN loss 0.3843,  acc 0.8727 || VAL loss 0.8296, acc 0.8029\n",
      "\t80: TRAIN loss 0.3452,  acc 0.8882 || VAL loss 0.8342, acc 0.8187\n",
      "\t90: TRAIN loss 0.3074,  acc 0.9026 || VAL loss 0.8101, acc 0.8147\n",
      "\t100: TRAIN loss 0.2866,  acc 0.9040 || VAL loss 0.8079, acc 0.8155\n",
      "\t110: TRAIN loss 0.2536,  acc 0.9202 || VAL loss 0.8230, acc 0.8195\n",
      "\t120: TRAIN loss 0.2358,  acc 0.9222 || VAL loss 0.8231, acc 0.8234\n",
      "\t130: TRAIN loss 0.2154,  acc 0.9309 || VAL loss 0.8568, acc 0.8242\n",
      "\t140: TRAIN loss 0.2091,  acc 0.9289 || VAL loss 0.8800, acc 0.8171\n",
      "\t150: TRAIN loss 0.1873,  acc 0.9388 || VAL loss 0.8736, acc 0.8211\n",
      "\t160: TRAIN loss 0.1776,  acc 0.9424 || VAL loss 0.8840, acc 0.8242\n",
      "\t170: TRAIN loss 0.1673,  acc 0.9448 || VAL loss 0.9039, acc 0.8195\n",
      "\t180: TRAIN loss 0.1530,  acc 0.9473 || VAL loss 0.9182, acc 0.8250\n",
      "\t190: TRAIN loss 0.1502,  acc 0.9491 || VAL loss 0.9397, acc 0.8131\n",
      "\t200: TRAIN loss 0.1424,  acc 0.9521 || VAL loss 0.9264, acc 0.8274\n",
      "\t210: TRAIN loss 0.1353,  acc 0.9529 || VAL loss 0.9735, acc 0.8163\n",
      "\t220: TRAIN loss 0.1261,  acc 0.9561 || VAL loss 0.9767, acc 0.8219\n",
      "\t230: TRAIN loss 0.1177,  acc 0.9648 || VAL loss 1.0085, acc 0.8226\n",
      "\t240: TRAIN loss 0.1381,  acc 0.9572 || VAL loss 0.9899, acc 0.8274\n",
      "\t250: TRAIN loss 0.1085,  acc 0.9693 || VAL loss 0.9797, acc 0.8282\n",
      "\t260: TRAIN loss 0.1047,  acc 0.9713 || VAL loss 1.0321, acc 0.8234\n",
      "\t270: TRAIN loss 0.1013,  acc 0.9729 || VAL loss 1.0366, acc 0.8274\n",
      "\t280: TRAIN loss 0.0957,  acc 0.9729 || VAL loss 1.0662, acc 0.8219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t290: TRAIN loss 0.1032,  acc 0.9709 || VAL loss 1.0962, acc 0.8234\n",
      "32 16 0.9766429136975455 0.8210609659540776\n",
      "\t0: TRAIN loss 6.5271,  acc 0.2225 || VAL loss 3.8969, acc 0.3167\n",
      "\t10: TRAIN loss 0.9141,  acc 0.7126 || VAL loss 1.1622, acc 0.6817\n",
      "\t20: TRAIN loss 0.6395,  acc 0.8064 || VAL loss 0.9734, acc 0.7427\n",
      "\t30: TRAIN loss 0.5140,  acc 0.8529 || VAL loss 0.8571, acc 0.7910\n",
      "\t40: TRAIN loss 0.4245,  acc 0.8798 || VAL loss 0.8379, acc 0.8060\n",
      "\t50: TRAIN loss 0.3593,  acc 0.8971 || VAL loss 0.8158, acc 0.8139\n",
      "\t60: TRAIN loss 0.3012,  acc 0.9143 || VAL loss 0.8119, acc 0.8242\n",
      "\t70: TRAIN loss 0.2719,  acc 0.9256 || VAL loss 0.7978, acc 0.8298\n",
      "\t80: TRAIN loss 0.2469,  acc 0.9281 || VAL loss 0.7690, acc 0.8361\n",
      "\t90: TRAIN loss 0.2123,  acc 0.9446 || VAL loss 0.7736, acc 0.8448\n",
      "\t100: TRAIN loss 0.1933,  acc 0.9477 || VAL loss 0.7990, acc 0.8416\n",
      "\t110: TRAIN loss 0.1799,  acc 0.9535 || VAL loss 0.8085, acc 0.8488\n",
      "\t120: TRAIN loss 0.1679,  acc 0.9578 || VAL loss 0.8608, acc 0.8385\n",
      "\t130: TRAIN loss 0.1477,  acc 0.9662 || VAL loss 0.8787, acc 0.8369\n",
      "\t140: TRAIN loss 0.1364,  acc 0.9697 || VAL loss 0.8616, acc 0.8448\n",
      "\t150: TRAIN loss 0.1252,  acc 0.9737 || VAL loss 0.9297, acc 0.8361\n",
      "\t160: TRAIN loss 0.1183,  acc 0.9757 || VAL loss 0.9110, acc 0.8480\n",
      "\t170: TRAIN loss 0.1111,  acc 0.9780 || VAL loss 0.9365, acc 0.8456\n",
      "\t180: TRAIN loss 0.1085,  acc 0.9766 || VAL loss 0.9604, acc 0.8480\n",
      "\t190: TRAIN loss 0.1028,  acc 0.9802 || VAL loss 1.0092, acc 0.8401\n",
      "\t200: TRAIN loss 0.0950,  acc 0.9826 || VAL loss 0.9670, acc 0.8448\n",
      "\t210: TRAIN loss 0.0905,  acc 0.9834 || VAL loss 1.0089, acc 0.8472\n",
      "\t220: TRAIN loss 0.0889,  acc 0.9840 || VAL loss 1.0104, acc 0.8440\n",
      "\t230: TRAIN loss 0.0842,  acc 0.9838 || VAL loss 1.0436, acc 0.8480\n",
      "\t240: TRAIN loss 0.0797,  acc 0.9856 || VAL loss 1.0806, acc 0.8424\n",
      "\t250: TRAIN loss 0.0763,  acc 0.9873 || VAL loss 1.0825, acc 0.8480\n",
      "\t260: TRAIN loss 0.0728,  acc 0.9887 || VAL loss 1.0854, acc 0.8424\n",
      "\t270: TRAIN loss 0.0681,  acc 0.9895 || VAL loss 1.1088, acc 0.8448\n",
      "\t280: TRAIN loss 0.0683,  acc 0.9897 || VAL loss 1.1209, acc 0.8504\n",
      "\t290: TRAIN loss 0.0694,  acc 0.9895 || VAL loss 1.1341, acc 0.8393\n",
      "32 32 0.9908946951702297 0.8432304038004751\n",
      "\t0: TRAIN loss 5.9634,  acc 0.1956 || VAL loss 3.2983, acc 0.2961\n",
      "\t10: TRAIN loss 0.9080,  acc 0.7102 || VAL loss 1.0990, acc 0.6659\n",
      "\t20: TRAIN loss 0.6637,  acc 0.7979 || VAL loss 0.9240, acc 0.7538\n",
      "\t30: TRAIN loss 0.5130,  acc 0.8458 || VAL loss 0.9144, acc 0.7728\n",
      "\t40: TRAIN loss 0.4090,  acc 0.8769 || VAL loss 0.8128, acc 0.7831\n",
      "\t50: TRAIN loss 0.3851,  acc 0.8931 || VAL loss 0.8058, acc 0.8044\n",
      "\t60: TRAIN loss 0.3004,  acc 0.9173 || VAL loss 0.7655, acc 0.8234\n",
      "\t70: TRAIN loss 0.2638,  acc 0.9264 || VAL loss 0.7806, acc 0.8179\n",
      "\t80: TRAIN loss 0.2455,  acc 0.9325 || VAL loss 0.7507, acc 0.8258\n",
      "\t90: TRAIN loss 0.2138,  acc 0.9434 || VAL loss 0.7635, acc 0.8314\n",
      "\t100: TRAIN loss 0.1968,  acc 0.9491 || VAL loss 0.7748, acc 0.8432\n",
      "\t110: TRAIN loss 0.1904,  acc 0.9565 || VAL loss 0.8435, acc 0.8409\n",
      "\t120: TRAIN loss 0.1732,  acc 0.9563 || VAL loss 0.8505, acc 0.8401\n",
      "\t130: TRAIN loss 0.1476,  acc 0.9630 || VAL loss 0.8614, acc 0.8424\n",
      "\t140: TRAIN loss 0.1395,  acc 0.9658 || VAL loss 0.8544, acc 0.8488\n",
      "\t150: TRAIN loss 0.1272,  acc 0.9709 || VAL loss 0.8747, acc 0.8488\n",
      "\t160: TRAIN loss 0.1176,  acc 0.9749 || VAL loss 0.8868, acc 0.8409\n",
      "\t170: TRAIN loss 0.1081,  acc 0.9782 || VAL loss 0.9271, acc 0.8496\n",
      "\t180: TRAIN loss 0.1066,  acc 0.9798 || VAL loss 0.8993, acc 0.8519\n",
      "\t190: TRAIN loss 0.1000,  acc 0.9788 || VAL loss 0.9019, acc 0.8511\n",
      "\t200: TRAIN loss 0.0984,  acc 0.9814 || VAL loss 0.8946, acc 0.8480\n",
      "\t210: TRAIN loss 0.0872,  acc 0.9856 || VAL loss 0.9301, acc 0.8472\n",
      "\t220: TRAIN loss 0.0920,  acc 0.9824 || VAL loss 0.9227, acc 0.8535\n",
      "\t230: TRAIN loss 0.0810,  acc 0.9846 || VAL loss 0.9551, acc 0.8480\n",
      "\t240: TRAIN loss 0.0750,  acc 0.9869 || VAL loss 0.9193, acc 0.8551\n",
      "\t250: TRAIN loss 0.0716,  acc 0.9875 || VAL loss 0.9388, acc 0.8527\n",
      "\t260: TRAIN loss 0.0677,  acc 0.9881 || VAL loss 0.9369, acc 0.8472\n",
      "\t270: TRAIN loss 0.0659,  acc 0.9887 || VAL loss 0.9717, acc 0.8480\n",
      "\t280: TRAIN loss 0.0644,  acc 0.9877 || VAL loss 0.9556, acc 0.8496\n",
      "\t290: TRAIN loss 0.0608,  acc 0.9907 || VAL loss 0.9507, acc 0.8488\n",
      "32 64 0.9934679334916865 0.8519398258115598\n",
      "\t0: TRAIN loss 3.1903,  acc 0.2656 || VAL loss 2.2709, acc 0.3872\n",
      "\t10: TRAIN loss 0.9679,  acc 0.7061 || VAL loss 1.1586, acc 0.6817\n",
      "\t20: TRAIN loss 0.7294,  acc 0.7935 || VAL loss 0.9737, acc 0.7577\n",
      "\t30: TRAIN loss 0.5705,  acc 0.8498 || VAL loss 0.9258, acc 0.7791\n",
      "\t40: TRAIN loss 0.4735,  acc 0.8761 || VAL loss 0.8679, acc 0.7997\n",
      "\t50: TRAIN loss 0.4135,  acc 0.8963 || VAL loss 0.8832, acc 0.8044\n",
      "\t60: TRAIN loss 0.3958,  acc 0.9032 || VAL loss 0.8715, acc 0.8108\n",
      "\t70: TRAIN loss 0.3519,  acc 0.9137 || VAL loss 0.8889, acc 0.8306\n",
      "\t80: TRAIN loss 0.3498,  acc 0.9173 || VAL loss 0.9500, acc 0.8187\n",
      "\t90: TRAIN loss 0.2928,  acc 0.9382 || VAL loss 0.9627, acc 0.8282\n",
      "\t100: TRAIN loss 0.2890,  acc 0.9406 || VAL loss 0.9829, acc 0.8242\n",
      "\t110: TRAIN loss 0.2634,  acc 0.9489 || VAL loss 1.0096, acc 0.8211\n",
      "\t120: TRAIN loss 0.2425,  acc 0.9523 || VAL loss 0.9800, acc 0.8329\n",
      "\t130: TRAIN loss 0.2308,  acc 0.9547 || VAL loss 1.0104, acc 0.8298\n",
      "\t140: TRAIN loss 0.2254,  acc 0.9622 || VAL loss 1.0272, acc 0.8274\n",
      "\t150: TRAIN loss 0.2072,  acc 0.9658 || VAL loss 1.0291, acc 0.8314\n",
      "\t160: TRAIN loss 0.2033,  acc 0.9671 || VAL loss 1.0671, acc 0.8321\n",
      "\t170: TRAIN loss 0.1925,  acc 0.9697 || VAL loss 1.0846, acc 0.8321\n",
      "\t180: TRAIN loss 0.1870,  acc 0.9739 || VAL loss 1.1177, acc 0.8361\n",
      "\t190: TRAIN loss 0.1773,  acc 0.9755 || VAL loss 1.1234, acc 0.8314\n",
      "\t200: TRAIN loss 0.1724,  acc 0.9778 || VAL loss 1.1655, acc 0.8298\n",
      "\t210: TRAIN loss 0.1667,  acc 0.9792 || VAL loss 1.1997, acc 0.8321\n",
      "\t220: TRAIN loss 0.1602,  acc 0.9816 || VAL loss 1.1835, acc 0.8306\n",
      "\t230: TRAIN loss 0.1690,  acc 0.9806 || VAL loss 1.2062, acc 0.8258\n",
      "\t240: TRAIN loss 0.1749,  acc 0.9820 || VAL loss 1.1987, acc 0.8282\n",
      "\t250: TRAIN loss 0.1699,  acc 0.9832 || VAL loss 1.2043, acc 0.8416\n",
      "\t260: TRAIN loss 0.1517,  acc 0.9850 || VAL loss 1.2263, acc 0.8385\n",
      "\t270: TRAIN loss 0.1429,  acc 0.9844 || VAL loss 1.2468, acc 0.8314\n",
      "\t280: TRAIN loss 0.1405,  acc 0.9856 || VAL loss 1.2603, acc 0.8321\n",
      "\t290: TRAIN loss 0.1406,  acc 0.9854 || VAL loss 1.2913, acc 0.8321\n",
      "32 128 0.9871338083927158 0.833729216152019\n",
      "\t0: TRAIN loss 3.0108,  acc 0.2777 || VAL loss 2.0357, acc 0.3824\n",
      "\t10: TRAIN loss 0.7613,  acc 0.7797 || VAL loss 0.9691, acc 0.7553\n",
      "\t20: TRAIN loss 0.4805,  acc 0.8672 || VAL loss 0.7928, acc 0.8100\n",
      "\t30: TRAIN loss 0.3616,  acc 0.9042 || VAL loss 0.7266, acc 0.8282\n",
      "\t40: TRAIN loss 0.2899,  acc 0.9268 || VAL loss 0.7175, acc 0.8456\n",
      "\t50: TRAIN loss 0.2232,  acc 0.9503 || VAL loss 0.7225, acc 0.8519\n",
      "\t60: TRAIN loss 0.2383,  acc 0.9468 || VAL loss 0.7415, acc 0.8559\n",
      "\t70: TRAIN loss 0.1708,  acc 0.9675 || VAL loss 0.7588, acc 0.8599\n",
      "\t80: TRAIN loss 0.1808,  acc 0.9673 || VAL loss 0.7407, acc 0.8638\n",
      "\t90: TRAIN loss 0.1495,  acc 0.9766 || VAL loss 0.7655, acc 0.8694\n",
      "\t100: TRAIN loss 0.1422,  acc 0.9755 || VAL loss 0.7188, acc 0.8702\n",
      "\t110: TRAIN loss 0.1111,  acc 0.9857 || VAL loss 0.7494, acc 0.8694\n",
      "\t120: TRAIN loss 0.1049,  acc 0.9871 || VAL loss 0.7692, acc 0.8812\n",
      "\t130: TRAIN loss 0.0949,  acc 0.9907 || VAL loss 0.7945, acc 0.8844\n",
      "\t140: TRAIN loss 0.1126,  acc 0.9838 || VAL loss 0.8415, acc 0.8725\n",
      "\t150: TRAIN loss 0.0905,  acc 0.9905 || VAL loss 0.8889, acc 0.8717\n",
      "\t160: TRAIN loss 0.0851,  acc 0.9923 || VAL loss 0.8903, acc 0.8741\n",
      "\t170: TRAIN loss 0.0921,  acc 0.9889 || VAL loss 0.9122, acc 0.8733\n",
      "\t180: TRAIN loss 0.0825,  acc 0.9909 || VAL loss 0.9149, acc 0.8709\n",
      "\t190: TRAIN loss 0.0748,  acc 0.9939 || VAL loss 0.9399, acc 0.8741\n",
      "\t200: TRAIN loss 0.0775,  acc 0.9933 || VAL loss 0.9546, acc 0.8757\n",
      "\t210: TRAIN loss 0.0737,  acc 0.9939 || VAL loss 0.9452, acc 0.8741\n",
      "\t220: TRAIN loss 0.0749,  acc 0.9929 || VAL loss 0.9917, acc 0.8686\n",
      "\t230: TRAIN loss 0.1263,  acc 0.9852 || VAL loss 0.9762, acc 0.8781\n",
      "\t240: TRAIN loss 0.0729,  acc 0.9945 || VAL loss 0.9649, acc 0.8797\n",
      "\t250: TRAIN loss 0.0714,  acc 0.9943 || VAL loss 0.9809, acc 0.8757\n",
      "\t260: TRAIN loss 0.0712,  acc 0.9937 || VAL loss 0.9960, acc 0.8654\n",
      "\t270: TRAIN loss 0.0722,  acc 0.9931 || VAL loss 0.9928, acc 0.8757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t280: TRAIN loss 0.0699,  acc 0.9945 || VAL loss 1.0136, acc 0.8773\n",
      "\t290: TRAIN loss 0.0776,  acc 0.9921 || VAL loss 1.0883, acc 0.8646\n",
      "32 256 0.9950514647664291 0.8788598574821853\n",
      "\t0: TRAIN loss 2.8707,  acc 0.3314 || VAL loss 1.5861, acc 0.4925\n",
      "\t10: TRAIN loss 0.5862,  acc 0.8238 || VAL loss 0.8257, acc 0.7688\n",
      "\t20: TRAIN loss 0.3346,  acc 0.9038 || VAL loss 0.6736, acc 0.8226\n",
      "\t30: TRAIN loss 0.3012,  acc 0.9184 || VAL loss 0.6171, acc 0.8496\n",
      "\t40: TRAIN loss 0.1484,  acc 0.9669 || VAL loss 0.6315, acc 0.8725\n",
      "\t50: TRAIN loss 0.1102,  acc 0.9802 || VAL loss 0.6183, acc 0.8789\n",
      "\t60: TRAIN loss 0.1066,  acc 0.9852 || VAL loss 0.6224, acc 0.8765\n",
      "\t70: TRAIN loss 0.0776,  acc 0.9875 || VAL loss 0.6394, acc 0.8868\n",
      "\t80: TRAIN loss 0.0682,  acc 0.9923 || VAL loss 0.6452, acc 0.8955\n",
      "\t90: TRAIN loss 0.0642,  acc 0.9919 || VAL loss 0.7795, acc 0.8646\n",
      "\t100: TRAIN loss 0.0890,  acc 0.9871 || VAL loss 0.7708, acc 0.8781\n",
      "\t110: TRAIN loss 0.0461,  acc 0.9964 || VAL loss 0.6715, acc 0.8907\n",
      "\t120: TRAIN loss 0.0495,  acc 0.9956 || VAL loss 0.7043, acc 0.8931\n",
      "\t130: TRAIN loss 0.0644,  acc 0.9897 || VAL loss 0.7267, acc 0.8860\n",
      "\t140: TRAIN loss 0.0420,  acc 0.9962 || VAL loss 0.7259, acc 0.8915\n",
      "\t150: TRAIN loss 0.0537,  acc 0.9921 || VAL loss 0.7593, acc 0.8868\n",
      "\t160: TRAIN loss 0.0424,  acc 0.9962 || VAL loss 0.6787, acc 0.8971\n",
      "\t170: TRAIN loss 0.0438,  acc 0.9958 || VAL loss 0.6947, acc 0.9018\n",
      "\t180: TRAIN loss 0.0417,  acc 0.9958 || VAL loss 0.7174, acc 0.8994\n",
      "\t190: TRAIN loss 0.1198,  acc 0.9784 || VAL loss 0.8632, acc 0.8702\n",
      "\t200: TRAIN loss 0.0396,  acc 0.9966 || VAL loss 0.7330, acc 0.8971\n",
      "\t210: TRAIN loss 0.0397,  acc 0.9960 || VAL loss 0.7452, acc 0.8979\n",
      "\t220: TRAIN loss 0.0415,  acc 0.9960 || VAL loss 0.7528, acc 0.8947\n",
      "\t230: TRAIN loss 0.0402,  acc 0.9962 || VAL loss 0.7406, acc 0.8987\n",
      "\t240: TRAIN loss 0.0403,  acc 0.9956 || VAL loss 0.7472, acc 0.9018\n",
      "\t250: TRAIN loss 0.0411,  acc 0.9960 || VAL loss 0.7653, acc 0.8987\n",
      "\t260: TRAIN loss 0.0747,  acc 0.9856 || VAL loss 0.8460, acc 0.8789\n",
      "\t270: TRAIN loss 0.0381,  acc 0.9964 || VAL loss 0.7681, acc 0.8994\n",
      "\t280: TRAIN loss 0.0401,  acc 0.9960 || VAL loss 0.7973, acc 0.8979\n",
      "\t290: TRAIN loss 0.0412,  acc 0.9962 || VAL loss 0.7891, acc 0.8923\n",
      "32 512 0.9970308788598575 0.901821060965954\n",
      "\t0: TRAIN loss 2.6381,  acc 0.3608 || VAL loss 1.6309, acc 0.5044\n",
      "\t10: TRAIN loss 0.5592,  acc 0.8234 || VAL loss 0.8391, acc 0.7815\n",
      "\t20: TRAIN loss 0.2944,  acc 0.9103 || VAL loss 0.6813, acc 0.8258\n",
      "\t30: TRAIN loss 0.1909,  acc 0.9432 || VAL loss 0.6974, acc 0.8440\n",
      "\t40: TRAIN loss 0.1127,  acc 0.9691 || VAL loss 0.5770, acc 0.8694\n",
      "\t50: TRAIN loss 0.0956,  acc 0.9751 || VAL loss 0.5760, acc 0.8733\n",
      "\t60: TRAIN loss 0.0559,  acc 0.9885 || VAL loss 0.6204, acc 0.8852\n",
      "\t70: TRAIN loss 0.1156,  acc 0.9753 || VAL loss 0.7471, acc 0.8733\n",
      "\t80: TRAIN loss 0.0470,  acc 0.9943 || VAL loss 0.6454, acc 0.8884\n",
      "\t90: TRAIN loss 0.0493,  acc 0.9945 || VAL loss 0.6626, acc 0.8907\n",
      "\t100: TRAIN loss 0.0379,  acc 0.9960 || VAL loss 0.6641, acc 0.8971\n",
      "\t110: TRAIN loss 0.0401,  acc 0.9941 || VAL loss 0.7170, acc 0.8963\n",
      "\t120: TRAIN loss 0.0339,  acc 0.9958 || VAL loss 0.6940, acc 0.8931\n",
      "\t130: TRAIN loss 0.0970,  acc 0.9757 || VAL loss 0.8339, acc 0.8733\n",
      "\t140: TRAIN loss 0.0506,  acc 0.9958 || VAL loss 0.7042, acc 0.9010\n",
      "\t150: TRAIN loss 0.0500,  acc 0.9954 || VAL loss 0.7092, acc 0.9002\n",
      "\t160: TRAIN loss 0.0553,  acc 0.9952 || VAL loss 0.7417, acc 0.8971\n",
      "\t170: TRAIN loss 0.0392,  acc 0.9909 || VAL loss 0.8224, acc 0.8820\n",
      "\t180: TRAIN loss 0.0189,  acc 0.9974 || VAL loss 0.7693, acc 0.8971\n",
      "\t190: TRAIN loss 0.0184,  acc 0.9972 || VAL loss 0.7833, acc 0.8931\n",
      "\t200: TRAIN loss 0.1144,  acc 0.9731 || VAL loss 0.9062, acc 0.8789\n",
      "\t210: TRAIN loss 0.0167,  acc 0.9978 || VAL loss 0.6963, acc 0.8979\n",
      "\t220: TRAIN loss 0.0173,  acc 0.9976 || VAL loss 0.6996, acc 0.8963\n",
      "\t230: TRAIN loss 0.0161,  acc 0.9980 || VAL loss 0.7143, acc 0.8994\n",
      "\t240: TRAIN loss 0.0173,  acc 0.9976 || VAL loss 0.7191, acc 0.8979\n",
      "\t250: TRAIN loss 0.0156,  acc 0.9980 || VAL loss 0.7358, acc 0.8994\n",
      "\t260: TRAIN loss 0.0176,  acc 0.9976 || VAL loss 0.7320, acc 0.8987\n",
      "\t270: TRAIN loss 0.0173,  acc 0.9980 || VAL loss 0.7275, acc 0.9018\n",
      "\t280: TRAIN loss 0.0160,  acc 0.9980 || VAL loss 0.7415, acc 0.9026\n",
      "\t290: TRAIN loss 0.0160,  acc 0.9978 || VAL loss 0.7486, acc 0.9042\n",
      "32 1024 0.9980205859065716 0.9002375296912114\n",
      "\t0: TRAIN loss 8.1616,  acc 0.1993 || VAL loss 4.2961, acc 0.3104\n",
      "\t10: TRAIN loss 0.9584,  acc 0.7140 || VAL loss 1.2561, acc 0.6738\n",
      "\t20: TRAIN loss 0.6796,  acc 0.7928 || VAL loss 1.0341, acc 0.7340\n",
      "\t30: TRAIN loss 0.5131,  acc 0.8438 || VAL loss 0.8811, acc 0.7799\n",
      "\t40: TRAIN loss 0.4341,  acc 0.8672 || VAL loss 0.8510, acc 0.7870\n",
      "\t50: TRAIN loss 0.3444,  acc 0.8967 || VAL loss 0.8298, acc 0.8060\n",
      "\t60: TRAIN loss 0.3013,  acc 0.9086 || VAL loss 0.8248, acc 0.8068\n",
      "\t70: TRAIN loss 0.2789,  acc 0.9198 || VAL loss 0.8709, acc 0.8100\n",
      "\t80: TRAIN loss 0.2399,  acc 0.9307 || VAL loss 0.8054, acc 0.8195\n",
      "\t90: TRAIN loss 0.2124,  acc 0.9408 || VAL loss 0.8453, acc 0.8298\n",
      "\t100: TRAIN loss 0.2132,  acc 0.9422 || VAL loss 0.8242, acc 0.8234\n",
      "\t110: TRAIN loss 0.1808,  acc 0.9535 || VAL loss 0.8613, acc 0.8250\n",
      "\t120: TRAIN loss 0.1844,  acc 0.9511 || VAL loss 0.8410, acc 0.8345\n",
      "\t130: TRAIN loss 0.1642,  acc 0.9592 || VAL loss 0.9142, acc 0.8361\n",
      "\t140: TRAIN loss 0.1498,  acc 0.9642 || VAL loss 0.9024, acc 0.8321\n",
      "\t150: TRAIN loss 0.1432,  acc 0.9667 || VAL loss 0.9471, acc 0.8369\n",
      "\t160: TRAIN loss 0.1418,  acc 0.9671 || VAL loss 0.9958, acc 0.8242\n",
      "\t170: TRAIN loss 0.1403,  acc 0.9660 || VAL loss 0.9519, acc 0.8306\n",
      "\t180: TRAIN loss 0.1138,  acc 0.9762 || VAL loss 0.9746, acc 0.8329\n",
      "\t190: TRAIN loss 0.1080,  acc 0.9780 || VAL loss 0.9881, acc 0.8314\n",
      "\t200: TRAIN loss 0.1051,  acc 0.9792 || VAL loss 1.0323, acc 0.8258\n",
      "\t210: TRAIN loss 0.1035,  acc 0.9784 || VAL loss 1.0365, acc 0.8361\n",
      "\t220: TRAIN loss 0.0984,  acc 0.9782 || VAL loss 1.0575, acc 0.8314\n",
      "\t230: TRAIN loss 0.0918,  acc 0.9806 || VAL loss 1.0823, acc 0.8321\n",
      "\t240: TRAIN loss 0.1002,  acc 0.9780 || VAL loss 1.0115, acc 0.8385\n",
      "\t250: TRAIN loss 0.0916,  acc 0.9818 || VAL loss 1.0682, acc 0.8385\n",
      "\t260: TRAIN loss 0.0830,  acc 0.9852 || VAL loss 1.0978, acc 0.8321\n",
      "\t270: TRAIN loss 0.0834,  acc 0.9838 || VAL loss 1.0757, acc 0.8361\n",
      "\t280: TRAIN loss 0.0770,  acc 0.9856 || VAL loss 1.1067, acc 0.8369\n",
      "\t290: TRAIN loss 0.0748,  acc 0.9863 || VAL loss 1.1205, acc 0.8416\n",
      "64 16 0.9875296912114014 0.8432304038004751\n",
      "\t0: TRAIN loss 5.3805,  acc 0.1696 || VAL loss 2.4423, acc 0.2526\n",
      "\t10: TRAIN loss 1.0083,  acc 0.6463 || VAL loss 1.2254, acc 0.6144\n",
      "\t20: TRAIN loss 0.5762,  acc 0.8080 || VAL loss 0.8771, acc 0.7664\n",
      "\t30: TRAIN loss 0.4002,  acc 0.8702 || VAL loss 0.8004, acc 0.7981\n",
      "\t40: TRAIN loss 0.3128,  acc 0.8941 || VAL loss 0.7492, acc 0.8266\n",
      "\t50: TRAIN loss 0.2406,  acc 0.9260 || VAL loss 0.7103, acc 0.8369\n",
      "\t60: TRAIN loss 0.2006,  acc 0.9426 || VAL loss 0.7558, acc 0.8377\n",
      "\t70: TRAIN loss 0.1700,  acc 0.9499 || VAL loss 0.7188, acc 0.8543\n",
      "\t80: TRAIN loss 0.1662,  acc 0.9517 || VAL loss 0.7717, acc 0.8448\n",
      "\t90: TRAIN loss 0.1227,  acc 0.9665 || VAL loss 0.7774, acc 0.8583\n",
      "\t100: TRAIN loss 0.1035,  acc 0.9725 || VAL loss 0.7978, acc 0.8551\n",
      "\t110: TRAIN loss 0.0928,  acc 0.9764 || VAL loss 0.7915, acc 0.8567\n",
      "\t120: TRAIN loss 0.0950,  acc 0.9766 || VAL loss 0.8324, acc 0.8488\n",
      "\t130: TRAIN loss 0.0752,  acc 0.9812 || VAL loss 0.8745, acc 0.8551\n",
      "\t140: TRAIN loss 0.0644,  acc 0.9869 || VAL loss 0.8924, acc 0.8535\n",
      "\t150: TRAIN loss 0.0523,  acc 0.9899 || VAL loss 0.9246, acc 0.8575\n",
      "\t160: TRAIN loss 0.0494,  acc 0.9895 || VAL loss 0.9729, acc 0.8488\n",
      "\t170: TRAIN loss 0.0560,  acc 0.9869 || VAL loss 0.9834, acc 0.8559\n",
      "\t180: TRAIN loss 0.0352,  acc 0.9935 || VAL loss 1.0201, acc 0.8559\n",
      "\t190: TRAIN loss 0.0318,  acc 0.9945 || VAL loss 1.0400, acc 0.8567\n",
      "\t200: TRAIN loss 0.0439,  acc 0.9895 || VAL loss 1.0952, acc 0.8472\n",
      "\t210: TRAIN loss 0.0287,  acc 0.9954 || VAL loss 1.0474, acc 0.8527\n",
      "\t220: TRAIN loss 0.0282,  acc 0.9956 || VAL loss 1.0786, acc 0.8511\n",
      "\t230: TRAIN loss 0.0263,  acc 0.9956 || VAL loss 1.0893, acc 0.8527\n",
      "\t240: TRAIN loss 0.0243,  acc 0.9964 || VAL loss 1.1103, acc 0.8543\n",
      "\t250: TRAIN loss 0.0201,  acc 0.9974 || VAL loss 1.1496, acc 0.8567\n",
      "\t260: TRAIN loss 0.0193,  acc 0.9974 || VAL loss 1.1747, acc 0.8464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t270: TRAIN loss 0.0197,  acc 0.9966 || VAL loss 1.1146, acc 0.8583\n",
      "\t280: TRAIN loss 0.0168,  acc 0.9980 || VAL loss 1.1191, acc 0.8567\n",
      "\t290: TRAIN loss 0.0180,  acc 0.9974 || VAL loss 1.1463, acc 0.8543\n",
      "64 32 0.998812351543943 0.8527315914489311\n",
      "\t0: TRAIN loss 9.5500,  acc 0.1936 || VAL loss 4.8336, acc 0.2858\n",
      "\t10: TRAIN loss 0.8286,  acc 0.7763 || VAL loss 1.0729, acc 0.7197\n",
      "\t20: TRAIN loss 0.5868,  acc 0.8664 || VAL loss 0.9197, acc 0.7910\n",
      "\t30: TRAIN loss 0.4655,  acc 0.8992 || VAL loss 0.8601, acc 0.8250\n",
      "\t40: TRAIN loss 0.4443,  acc 0.9125 || VAL loss 0.8025, acc 0.8298\n",
      "\t50: TRAIN loss 0.3405,  acc 0.9420 || VAL loss 0.8056, acc 0.8448\n",
      "\t60: TRAIN loss 0.3319,  acc 0.9434 || VAL loss 0.8128, acc 0.8496\n",
      "\t70: TRAIN loss 0.2726,  acc 0.9565 || VAL loss 0.7904, acc 0.8591\n",
      "\t80: TRAIN loss 0.2439,  acc 0.9652 || VAL loss 0.7813, acc 0.8622\n",
      "\t90: TRAIN loss 0.2303,  acc 0.9705 || VAL loss 0.8012, acc 0.8630\n",
      "\t100: TRAIN loss 0.2178,  acc 0.9749 || VAL loss 0.8204, acc 0.8678\n",
      "\t110: TRAIN loss 0.2041,  acc 0.9788 || VAL loss 0.8351, acc 0.8733\n",
      "\t120: TRAIN loss 0.2390,  acc 0.9725 || VAL loss 0.9741, acc 0.8511\n",
      "\t130: TRAIN loss 0.0899,  acc 0.9895 || VAL loss 0.8041, acc 0.8773\n",
      "\t140: TRAIN loss 0.0810,  acc 0.9903 || VAL loss 0.8045, acc 0.8797\n",
      "\t150: TRAIN loss 0.0795,  acc 0.9909 || VAL loss 0.8366, acc 0.8789\n",
      "\t160: TRAIN loss 0.0750,  acc 0.9915 || VAL loss 0.8546, acc 0.8749\n",
      "\t170: TRAIN loss 0.0722,  acc 0.9921 || VAL loss 0.8762, acc 0.8741\n",
      "\t180: TRAIN loss 0.0662,  acc 0.9943 || VAL loss 0.8891, acc 0.8741\n",
      "\t190: TRAIN loss 0.0637,  acc 0.9947 || VAL loss 0.9222, acc 0.8749\n",
      "\t200: TRAIN loss 0.0789,  acc 0.9919 || VAL loss 0.8799, acc 0.8836\n",
      "\t210: TRAIN loss 0.0712,  acc 0.9931 || VAL loss 0.8796, acc 0.8797\n",
      "\t220: TRAIN loss 0.0655,  acc 0.9949 || VAL loss 0.8720, acc 0.8797\n",
      "\t230: TRAIN loss 0.0746,  acc 0.9919 || VAL loss 0.8865, acc 0.8828\n",
      "\t240: TRAIN loss 0.0643,  acc 0.9949 || VAL loss 0.9049, acc 0.8789\n",
      "\t250: TRAIN loss 0.0634,  acc 0.9952 || VAL loss 0.9039, acc 0.8852\n",
      "\t260: TRAIN loss 0.0726,  acc 0.9923 || VAL loss 0.9294, acc 0.8725\n",
      "\t270: TRAIN loss 0.0639,  acc 0.9945 || VAL loss 0.9222, acc 0.8804\n",
      "\t280: TRAIN loss 0.0643,  acc 0.9941 || VAL loss 0.9217, acc 0.8773\n",
      "\t290: TRAIN loss 0.0639,  acc 0.9949 || VAL loss 0.9217, acc 0.8820\n",
      "64 64 0.9954473475851148 0.8788598574821853\n",
      "\t0: TRAIN loss 6.2661,  acc 0.2935 || VAL loss 2.7700, acc 0.4291\n",
      "\t10: TRAIN loss 0.6087,  acc 0.8155 || VAL loss 0.9440, acc 0.7648\n",
      "\t20: TRAIN loss 0.3580,  acc 0.8927 || VAL loss 0.7779, acc 0.8187\n",
      "\t30: TRAIN loss 0.2495,  acc 0.9285 || VAL loss 0.6969, acc 0.8385\n",
      "\t40: TRAIN loss 0.2537,  acc 0.9266 || VAL loss 0.7175, acc 0.8567\n",
      "\t50: TRAIN loss 0.1586,  acc 0.9553 || VAL loss 0.6760, acc 0.8527\n",
      "\t60: TRAIN loss 0.1062,  acc 0.9729 || VAL loss 0.6643, acc 0.8670\n",
      "\t70: TRAIN loss 0.0891,  acc 0.9778 || VAL loss 0.6495, acc 0.8709\n",
      "\t80: TRAIN loss 0.1050,  acc 0.9725 || VAL loss 0.6526, acc 0.8733\n",
      "\t90: TRAIN loss 0.0592,  acc 0.9879 || VAL loss 0.6585, acc 0.8757\n",
      "\t100: TRAIN loss 0.0600,  acc 0.9863 || VAL loss 0.6649, acc 0.8702\n",
      "\t110: TRAIN loss 0.0429,  acc 0.9917 || VAL loss 0.6615, acc 0.8797\n",
      "\t120: TRAIN loss 0.0436,  acc 0.9933 || VAL loss 0.7525, acc 0.8686\n",
      "\t130: TRAIN loss 0.0612,  acc 0.9921 || VAL loss 0.7022, acc 0.8741\n",
      "\t140: TRAIN loss 0.0471,  acc 0.9939 || VAL loss 0.7002, acc 0.8797\n",
      "\t150: TRAIN loss 0.0430,  acc 0.9954 || VAL loss 0.7051, acc 0.8773\n",
      "\t160: TRAIN loss 0.0371,  acc 0.9958 || VAL loss 0.7119, acc 0.8773\n",
      "\t170: TRAIN loss 0.0657,  acc 0.9863 || VAL loss 0.7876, acc 0.8773\n",
      "\t180: TRAIN loss 0.0353,  acc 0.9964 || VAL loss 0.7182, acc 0.8804\n",
      "\t190: TRAIN loss 0.0335,  acc 0.9962 || VAL loss 0.7216, acc 0.8812\n",
      "\t200: TRAIN loss 0.0332,  acc 0.9968 || VAL loss 0.7552, acc 0.8852\n",
      "\t210: TRAIN loss 0.0300,  acc 0.9962 || VAL loss 0.7422, acc 0.8931\n",
      "\t220: TRAIN loss 0.0274,  acc 0.9964 || VAL loss 0.7139, acc 0.8844\n",
      "\t230: TRAIN loss 0.0275,  acc 0.9966 || VAL loss 0.7332, acc 0.8820\n",
      "\t240: TRAIN loss 0.0295,  acc 0.9962 || VAL loss 0.7254, acc 0.8884\n",
      "\t250: TRAIN loss 0.0209,  acc 0.9978 || VAL loss 0.7380, acc 0.8828\n",
      "\t260: TRAIN loss 0.0210,  acc 0.9972 || VAL loss 0.7482, acc 0.8923\n",
      "\t270: TRAIN loss 0.0209,  acc 0.9972 || VAL loss 0.7523, acc 0.8868\n",
      "\t280: TRAIN loss 0.0205,  acc 0.9978 || VAL loss 0.7782, acc 0.8860\n",
      "\t290: TRAIN loss 0.0157,  acc 0.9980 || VAL loss 0.7865, acc 0.8812\n",
      "64 128 0.9990102929532858 0.8891528107680127\n",
      "\t0: TRAIN loss 3.8330,  acc 0.3205 || VAL loss 1.9702, acc 0.4885\n",
      "\t10: TRAIN loss 0.5666,  acc 0.8316 || VAL loss 0.8451, acc 0.7854\n",
      "\t20: TRAIN loss 0.3402,  acc 0.9133 || VAL loss 0.7420, acc 0.8306\n",
      "\t30: TRAIN loss 0.2895,  acc 0.9307 || VAL loss 0.7355, acc 0.8535\n",
      "\t40: TRAIN loss 0.1647,  acc 0.9656 || VAL loss 0.6887, acc 0.8804\n",
      "\t50: TRAIN loss 0.1288,  acc 0.9784 || VAL loss 0.6934, acc 0.8804\n",
      "\t60: TRAIN loss 0.1083,  acc 0.9830 || VAL loss 0.6714, acc 0.8907\n",
      "\t70: TRAIN loss 0.0872,  acc 0.9901 || VAL loss 0.6777, acc 0.8971\n",
      "\t80: TRAIN loss 0.0996,  acc 0.9848 || VAL loss 0.7205, acc 0.8884\n",
      "\t90: TRAIN loss 0.0997,  acc 0.9903 || VAL loss 0.7227, acc 0.8931\n",
      "\t100: TRAIN loss 0.0675,  acc 0.9941 || VAL loss 0.7418, acc 0.9058\n",
      "\t110: TRAIN loss 0.0641,  acc 0.9952 || VAL loss 0.7239, acc 0.9010\n",
      "\t120: TRAIN loss 0.0668,  acc 0.9931 || VAL loss 0.7269, acc 0.8994\n",
      "\t130: TRAIN loss 0.0920,  acc 0.9838 || VAL loss 0.7512, acc 0.8892\n",
      "\t140: TRAIN loss 0.0633,  acc 0.9943 || VAL loss 0.7612, acc 0.9010\n",
      "\t150: TRAIN loss 0.0615,  acc 0.9949 || VAL loss 0.7496, acc 0.9002\n",
      "\t160: TRAIN loss 0.0593,  acc 0.9947 || VAL loss 0.7422, acc 0.9002\n",
      "\t170: TRAIN loss 0.0975,  acc 0.9834 || VAL loss 0.7650, acc 0.8876\n",
      "\t180: TRAIN loss 0.0663,  acc 0.9937 || VAL loss 0.7416, acc 0.9066\n",
      "\t190: TRAIN loss 0.0613,  acc 0.9954 || VAL loss 0.7449, acc 0.9010\n",
      "\t200: TRAIN loss 0.0650,  acc 0.9941 || VAL loss 0.7447, acc 0.9082\n",
      "\t210: TRAIN loss 0.0633,  acc 0.9947 || VAL loss 0.7261, acc 0.9058\n",
      "\t220: TRAIN loss 0.0657,  acc 0.9943 || VAL loss 0.7477, acc 0.9058\n",
      "\t230: TRAIN loss 0.0673,  acc 0.9937 || VAL loss 0.7139, acc 0.9113\n",
      "\t240: TRAIN loss 0.0648,  acc 0.9949 || VAL loss 0.7112, acc 0.9145\n",
      "\t250: TRAIN loss 0.0643,  acc 0.9945 || VAL loss 0.7153, acc 0.9097\n",
      "\t260: TRAIN loss 0.0625,  acc 0.9949 || VAL loss 0.6732, acc 0.9137\n",
      "\t270: TRAIN loss 0.0609,  acc 0.9947 || VAL loss 0.6778, acc 0.9161\n",
      "\t280: TRAIN loss 0.0615,  acc 0.9951 || VAL loss 0.6870, acc 0.9145\n",
      "\t290: TRAIN loss 0.0604,  acc 0.9954 || VAL loss 0.6884, acc 0.9137\n",
      "64 256 0.995249406175772 0.9105304829770388\n",
      "\t0: TRAIN loss 2.7935,  acc 0.3874 || VAL loss 1.8105, acc 0.5091\n",
      "\t10: TRAIN loss 0.4621,  acc 0.8553 || VAL loss 0.7750, acc 0.8005\n",
      "\t20: TRAIN loss 0.2497,  acc 0.9394 || VAL loss 0.6391, acc 0.8519\n",
      "\t30: TRAIN loss 0.2671,  acc 0.9335 || VAL loss 0.6680, acc 0.8480\n",
      "\t40: TRAIN loss 0.1242,  acc 0.9743 || VAL loss 0.5635, acc 0.8828\n",
      "\t50: TRAIN loss 0.1255,  acc 0.9705 || VAL loss 0.6184, acc 0.8757\n",
      "\t60: TRAIN loss 0.0746,  acc 0.9857 || VAL loss 0.6447, acc 0.8931\n",
      "\t70: TRAIN loss 0.0560,  acc 0.9943 || VAL loss 0.6265, acc 0.9026\n",
      "\t80: TRAIN loss 0.0520,  acc 0.9954 || VAL loss 0.6254, acc 0.9050\n",
      "\t90: TRAIN loss 0.0782,  acc 0.9871 || VAL loss 0.6606, acc 0.8939\n",
      "\t100: TRAIN loss 0.0458,  acc 0.9962 || VAL loss 0.6517, acc 0.8994\n",
      "\t110: TRAIN loss 0.0439,  acc 0.9956 || VAL loss 0.6467, acc 0.9082\n",
      "\t120: TRAIN loss 0.0982,  acc 0.9889 || VAL loss 0.6770, acc 0.8963\n",
      "\t130: TRAIN loss 0.0812,  acc 0.9939 || VAL loss 0.6908, acc 0.9042\n",
      "\t140: TRAIN loss 0.0838,  acc 0.9923 || VAL loss 0.6912, acc 0.9034\n",
      "\t150: TRAIN loss 0.0762,  acc 0.9939 || VAL loss 0.7057, acc 0.9050\n",
      "\t160: TRAIN loss 0.0755,  acc 0.9941 || VAL loss 0.7279, acc 0.9018\n",
      "\t170: TRAIN loss 0.0753,  acc 0.9943 || VAL loss 0.7269, acc 0.9034\n",
      "\t180: TRAIN loss 0.0748,  acc 0.9937 || VAL loss 0.7170, acc 0.9066\n",
      "\t190: TRAIN loss 0.0745,  acc 0.9947 || VAL loss 0.7537, acc 0.9018\n",
      "\t200: TRAIN loss 0.0683,  acc 0.9945 || VAL loss 0.7244, acc 0.9058\n",
      "\t210: TRAIN loss 0.0671,  acc 0.9947 || VAL loss 0.7263, acc 0.9042\n",
      "\t220: TRAIN loss 0.0671,  acc 0.9949 || VAL loss 0.7591, acc 0.8994\n",
      "\t230: TRAIN loss 0.0700,  acc 0.9935 || VAL loss 0.7527, acc 0.9002\n",
      "\t240: TRAIN loss 0.0344,  acc 0.9966 || VAL loss 0.6597, acc 0.9050\n",
      "\t250: TRAIN loss 0.0349,  acc 0.9966 || VAL loss 0.6621, acc 0.9074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t260: TRAIN loss 0.0361,  acc 0.9962 || VAL loss 0.6681, acc 0.9074\n",
      "\t270: TRAIN loss 0.0353,  acc 0.9964 || VAL loss 0.6733, acc 0.9089\n",
      "\t280: TRAIN loss 0.0451,  acc 0.9941 || VAL loss 0.6889, acc 0.9089\n",
      "\t290: TRAIN loss 0.0376,  acc 0.9970 || VAL loss 0.6858, acc 0.9002\n",
      "64 512 0.9974267616785432 0.9065716547901821\n",
      "\t0: TRAIN loss 4.4985,  acc 0.3341 || VAL loss 2.7637, acc 0.4212\n",
      "\t10: TRAIN loss 0.4903,  acc 0.8525 || VAL loss 0.7975, acc 0.8076\n",
      "\t20: TRAIN loss 0.3896,  acc 0.8967 || VAL loss 0.7564, acc 0.8290\n",
      "\t30: TRAIN loss 0.1188,  acc 0.9743 || VAL loss 0.5605, acc 0.8915\n",
      "\t40: TRAIN loss 0.0827,  acc 0.9832 || VAL loss 0.6030, acc 0.8860\n",
      "\t50: TRAIN loss 0.0488,  acc 0.9951 || VAL loss 0.5816, acc 0.9002\n",
      "\t60: TRAIN loss 0.1188,  acc 0.9772 || VAL loss 0.6115, acc 0.8884\n",
      "\t70: TRAIN loss 0.0877,  acc 0.9929 || VAL loss 0.5607, acc 0.9042\n",
      "\t80: TRAIN loss 0.1930,  acc 0.9561 || VAL loss 0.8225, acc 0.8614\n",
      "\t90: TRAIN loss 0.0686,  acc 0.9887 || VAL loss 0.7508, acc 0.8876\n",
      "\t100: TRAIN loss 0.0398,  acc 0.9964 || VAL loss 0.6469, acc 0.8963\n",
      "\t110: TRAIN loss 0.0379,  acc 0.9958 || VAL loss 0.6679, acc 0.9010\n",
      "\t120: TRAIN loss 0.0650,  acc 0.9909 || VAL loss 0.9723, acc 0.8472\n",
      "\t130: TRAIN loss 0.0354,  acc 0.9960 || VAL loss 0.6211, acc 0.9034\n",
      "\t140: TRAIN loss 0.0342,  acc 0.9960 || VAL loss 0.6541, acc 0.9034\n",
      "\t150: TRAIN loss 0.0340,  acc 0.9968 || VAL loss 0.6232, acc 0.9066\n",
      "\t160: TRAIN loss 0.0345,  acc 0.9964 || VAL loss 0.6385, acc 0.9034\n",
      "\t170: TRAIN loss 0.0327,  acc 0.9962 || VAL loss 0.6348, acc 0.9082\n",
      "\t180: TRAIN loss 0.1288,  acc 0.9689 || VAL loss 0.6762, acc 0.8836\n",
      "\t190: TRAIN loss 0.0330,  acc 0.9968 || VAL loss 0.6398, acc 0.9058\n",
      "\t200: TRAIN loss 0.0315,  acc 0.9970 || VAL loss 0.6312, acc 0.9137\n",
      "\t210: TRAIN loss 0.0328,  acc 0.9970 || VAL loss 0.6575, acc 0.9082\n",
      "\t220: TRAIN loss 0.0316,  acc 0.9972 || VAL loss 0.6453, acc 0.9161\n",
      "\t230: TRAIN loss 0.0325,  acc 0.9968 || VAL loss 0.7736, acc 0.8915\n",
      "\t240: TRAIN loss 0.0287,  acc 0.9966 || VAL loss 0.6108, acc 0.9137\n",
      "\t250: TRAIN loss 0.0284,  acc 0.9966 || VAL loss 0.6007, acc 0.9153\n",
      "\t260: TRAIN loss 0.0277,  acc 0.9976 || VAL loss 0.6053, acc 0.9169\n",
      "\t270: TRAIN loss 0.0280,  acc 0.9970 || VAL loss 0.6117, acc 0.9153\n",
      "\t280: TRAIN loss 0.0282,  acc 0.9972 || VAL loss 0.6051, acc 0.9192\n",
      "\t290: TRAIN loss 0.0280,  acc 0.9972 || VAL loss 0.6280, acc 0.9145\n",
      "64 1024 0.9924782264449723 0.901821060965954\n",
      "\t0: TRAIN loss 5.7203,  acc 0.1736 || VAL loss 2.3060, acc 0.1663\n",
      "\t10: TRAIN loss 1.3341,  acc 0.5216 || VAL loss 1.4693, acc 0.4917\n",
      "\t20: TRAIN loss 0.9408,  acc 0.6892 || VAL loss 1.1829, acc 0.6619\n",
      "\t30: TRAIN loss 0.6807,  acc 0.7753 || VAL loss 1.0273, acc 0.7007\n",
      "\t40: TRAIN loss 0.4886,  acc 0.8531 || VAL loss 0.8562, acc 0.7878\n",
      "\t50: TRAIN loss 0.3517,  acc 0.8971 || VAL loss 0.8330, acc 0.8203\n",
      "\t60: TRAIN loss 0.2795,  acc 0.9252 || VAL loss 0.8451, acc 0.8274\n",
      "\t70: TRAIN loss 0.2425,  acc 0.9386 || VAL loss 0.8229, acc 0.8242\n",
      "\t80: TRAIN loss 0.1914,  acc 0.9499 || VAL loss 0.7717, acc 0.8416\n",
      "\t90: TRAIN loss 0.1444,  acc 0.9608 || VAL loss 0.8074, acc 0.8401\n",
      "\t100: TRAIN loss 0.1821,  acc 0.9545 || VAL loss 0.8922, acc 0.8234\n",
      "\t110: TRAIN loss 0.1183,  acc 0.9683 || VAL loss 0.8403, acc 0.8496\n",
      "\t120: TRAIN loss 0.1179,  acc 0.9695 || VAL loss 0.8868, acc 0.8416\n",
      "\t130: TRAIN loss 0.0939,  acc 0.9760 || VAL loss 0.9212, acc 0.8432\n",
      "\t140: TRAIN loss 0.0888,  acc 0.9808 || VAL loss 0.9312, acc 0.8440\n",
      "\t150: TRAIN loss 0.0781,  acc 0.9820 || VAL loss 0.9332, acc 0.8519\n",
      "\t160: TRAIN loss 0.0686,  acc 0.9869 || VAL loss 0.9429, acc 0.8488\n",
      "\t170: TRAIN loss 0.0759,  acc 0.9830 || VAL loss 1.0000, acc 0.8488\n",
      "\t180: TRAIN loss 0.0629,  acc 0.9871 || VAL loss 0.9809, acc 0.8527\n",
      "\t190: TRAIN loss 0.0543,  acc 0.9871 || VAL loss 0.9654, acc 0.8583\n",
      "\t200: TRAIN loss 0.0437,  acc 0.9907 || VAL loss 0.9856, acc 0.8567\n",
      "\t210: TRAIN loss 0.0457,  acc 0.9893 || VAL loss 0.9997, acc 0.8622\n",
      "\t220: TRAIN loss 0.0422,  acc 0.9909 || VAL loss 0.9985, acc 0.8591\n",
      "\t230: TRAIN loss 0.0399,  acc 0.9913 || VAL loss 1.0190, acc 0.8575\n",
      "\t240: TRAIN loss 0.0505,  acc 0.9877 || VAL loss 1.0864, acc 0.8432\n",
      "\t250: TRAIN loss 0.0294,  acc 0.9931 || VAL loss 1.0115, acc 0.8559\n",
      "\t260: TRAIN loss 0.0288,  acc 0.9937 || VAL loss 1.0261, acc 0.8622\n",
      "\t270: TRAIN loss 0.0265,  acc 0.9954 || VAL loss 1.0276, acc 0.8583\n",
      "\t280: TRAIN loss 0.0273,  acc 0.9935 || VAL loss 1.0254, acc 0.8591\n",
      "\t290: TRAIN loss 0.0229,  acc 0.9956 || VAL loss 1.0554, acc 0.8583\n",
      "128 16 0.996437054631829 0.8566904196357878\n",
      "\t0: TRAIN loss 3.6220,  acc 0.2827 || VAL loss 2.2385, acc 0.4054\n",
      "\t10: TRAIN loss 0.6714,  acc 0.7945 || VAL loss 0.9669, acc 0.7609\n",
      "\t20: TRAIN loss 0.4314,  acc 0.8753 || VAL loss 0.7782, acc 0.8203\n",
      "\t30: TRAIN loss 0.2937,  acc 0.9161 || VAL loss 0.7438, acc 0.8361\n",
      "\t40: TRAIN loss 0.2326,  acc 0.9347 || VAL loss 0.6889, acc 0.8543\n",
      "\t50: TRAIN loss 0.1664,  acc 0.9582 || VAL loss 0.6877, acc 0.8575\n",
      "\t60: TRAIN loss 0.2498,  acc 0.9402 || VAL loss 0.7789, acc 0.8543\n",
      "\t70: TRAIN loss 0.1297,  acc 0.9723 || VAL loss 0.6977, acc 0.8781\n",
      "\t80: TRAIN loss 0.1020,  acc 0.9826 || VAL loss 0.7039, acc 0.8789\n",
      "\t90: TRAIN loss 0.0946,  acc 0.9826 || VAL loss 0.7331, acc 0.8733\n",
      "\t100: TRAIN loss 0.0853,  acc 0.9867 || VAL loss 0.7589, acc 0.8686\n",
      "\t110: TRAIN loss 0.1042,  acc 0.9830 || VAL loss 0.7211, acc 0.8836\n",
      "\t120: TRAIN loss 0.0549,  acc 0.9933 || VAL loss 0.7077, acc 0.8931\n",
      "\t130: TRAIN loss 0.0553,  acc 0.9925 || VAL loss 0.7833, acc 0.8797\n",
      "\t140: TRAIN loss 0.0485,  acc 0.9937 || VAL loss 0.7890, acc 0.8923\n",
      "\t150: TRAIN loss 0.0416,  acc 0.9964 || VAL loss 0.8043, acc 0.8828\n",
      "\t160: TRAIN loss 0.0582,  acc 0.9925 || VAL loss 0.7527, acc 0.8931\n",
      "\t170: TRAIN loss 0.0372,  acc 0.9960 || VAL loss 0.7891, acc 0.8947\n",
      "\t180: TRAIN loss 0.0361,  acc 0.9970 || VAL loss 0.8126, acc 0.8907\n",
      "\t190: TRAIN loss 0.0370,  acc 0.9962 || VAL loss 0.8139, acc 0.8884\n",
      "\t200: TRAIN loss 0.0443,  acc 0.9941 || VAL loss 0.8295, acc 0.8907\n",
      "\t210: TRAIN loss 0.0335,  acc 0.9972 || VAL loss 0.8472, acc 0.8955\n",
      "\t220: TRAIN loss 0.0939,  acc 0.9808 || VAL loss 0.8141, acc 0.8931\n",
      "\t230: TRAIN loss 0.0365,  acc 0.9968 || VAL loss 0.8268, acc 0.8979\n",
      "\t240: TRAIN loss 0.0383,  acc 0.9964 || VAL loss 0.8497, acc 0.8971\n",
      "\t250: TRAIN loss 0.0366,  acc 0.9964 || VAL loss 0.8374, acc 0.8963\n",
      "\t260: TRAIN loss 0.0535,  acc 0.9905 || VAL loss 0.9153, acc 0.8804\n",
      "\t270: TRAIN loss 0.0363,  acc 0.9964 || VAL loss 0.8464, acc 0.8994\n",
      "\t280: TRAIN loss 0.0376,  acc 0.9964 || VAL loss 0.8374, acc 0.9002\n",
      "\t290: TRAIN loss 0.0357,  acc 0.9966 || VAL loss 0.8441, acc 0.9002\n",
      "128 32 0.9970308788598575 0.897070467141726\n",
      "\t0: TRAIN loss 5.1150,  acc 0.2943 || VAL loss 2.2932, acc 0.4545\n",
      "\t10: TRAIN loss 0.5721,  acc 0.8414 || VAL loss 0.8287, acc 0.7894\n",
      "\t20: TRAIN loss 0.3827,  acc 0.8981 || VAL loss 0.7148, acc 0.8306\n",
      "\t30: TRAIN loss 0.2654,  acc 0.9400 || VAL loss 0.6851, acc 0.8424\n",
      "\t40: TRAIN loss 0.2921,  acc 0.9355 || VAL loss 0.6650, acc 0.8567\n",
      "\t50: TRAIN loss 0.1295,  acc 0.9669 || VAL loss 0.6527, acc 0.8709\n",
      "\t60: TRAIN loss 0.0915,  acc 0.9818 || VAL loss 0.6668, acc 0.8670\n",
      "\t70: TRAIN loss 0.0668,  acc 0.9885 || VAL loss 0.6493, acc 0.8844\n",
      "\t80: TRAIN loss 0.0597,  acc 0.9899 || VAL loss 0.6884, acc 0.8836\n",
      "\t90: TRAIN loss 0.1355,  acc 0.9711 || VAL loss 0.7492, acc 0.8717\n",
      "\t100: TRAIN loss 0.0487,  acc 0.9945 || VAL loss 0.7194, acc 0.8749\n",
      "\t110: TRAIN loss 0.0501,  acc 0.9943 || VAL loss 0.7036, acc 0.8844\n",
      "\t120: TRAIN loss 0.0498,  acc 0.9939 || VAL loss 0.7200, acc 0.8852\n",
      "\t130: TRAIN loss 0.0414,  acc 0.9956 || VAL loss 0.7628, acc 0.8797\n",
      "\t140: TRAIN loss 0.0386,  acc 0.9966 || VAL loss 0.7723, acc 0.8812\n",
      "\t150: TRAIN loss 0.0321,  acc 0.9968 || VAL loss 0.7508, acc 0.8781\n",
      "\t160: TRAIN loss 0.0274,  acc 0.9974 || VAL loss 0.7472, acc 0.8828\n",
      "\t170: TRAIN loss 0.0293,  acc 0.9960 || VAL loss 0.7420, acc 0.8844\n",
      "\t180: TRAIN loss 0.0287,  acc 0.9964 || VAL loss 0.7842, acc 0.8852\n",
      "\t190: TRAIN loss 0.0273,  acc 0.9966 || VAL loss 0.8055, acc 0.8820\n",
      "\t200: TRAIN loss 0.0420,  acc 0.9921 || VAL loss 0.8949, acc 0.8686\n",
      "\t210: TRAIN loss 0.0251,  acc 0.9972 || VAL loss 0.8013, acc 0.8860\n",
      "\t220: TRAIN loss 0.0241,  acc 0.9970 || VAL loss 0.7976, acc 0.8828\n",
      "\t230: TRAIN loss 0.0253,  acc 0.9974 || VAL loss 0.8167, acc 0.8836\n",
      "\t240: TRAIN loss 0.0254,  acc 0.9962 || VAL loss 0.8499, acc 0.8820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t250: TRAIN loss 0.0291,  acc 0.9956 || VAL loss 0.7854, acc 0.8907\n",
      "\t260: TRAIN loss 0.0225,  acc 0.9972 || VAL loss 0.7731, acc 0.8899\n",
      "\t270: TRAIN loss 0.0406,  acc 0.9915 || VAL loss 0.8112, acc 0.8868\n",
      "\t280: TRAIN loss 0.0222,  acc 0.9974 || VAL loss 0.8012, acc 0.8892\n",
      "\t290: TRAIN loss 0.0239,  acc 0.9974 || VAL loss 0.7944, acc 0.8899\n",
      "128 64 0.9974267616785432 0.8883610451306413\n",
      "\t0: TRAIN loss 5.0096,  acc 0.3256 || VAL loss 2.5984, acc 0.4513\n",
      "\t10: TRAIN loss 0.6464,  acc 0.8521 || VAL loss 0.8655, acc 0.8044\n",
      "\t20: TRAIN loss 0.4421,  acc 0.9078 || VAL loss 0.8903, acc 0.8139\n",
      "\t30: TRAIN loss 0.3875,  acc 0.9226 || VAL loss 0.8050, acc 0.8377\n",
      "\t40: TRAIN loss 0.2898,  acc 0.9580 || VAL loss 0.7360, acc 0.8717\n",
      "\t50: TRAIN loss 0.2486,  acc 0.9673 || VAL loss 0.7095, acc 0.8828\n",
      "\t60: TRAIN loss 0.2365,  acc 0.9707 || VAL loss 0.7122, acc 0.8860\n",
      "\t70: TRAIN loss 0.2446,  acc 0.9673 || VAL loss 0.7269, acc 0.8797\n",
      "\t80: TRAIN loss 0.2003,  acc 0.9818 || VAL loss 0.7520, acc 0.8828\n",
      "\t90: TRAIN loss 0.1785,  acc 0.9861 || VAL loss 0.7302, acc 0.8892\n",
      "\t100: TRAIN loss 0.1739,  acc 0.9875 || VAL loss 0.7403, acc 0.8955\n",
      "\t110: TRAIN loss 0.1941,  acc 0.9828 || VAL loss 0.8125, acc 0.8773\n",
      "\t120: TRAIN loss 0.1694,  acc 0.9887 || VAL loss 0.7496, acc 0.8923\n",
      "\t130: TRAIN loss 0.1669,  acc 0.9885 || VAL loss 0.7491, acc 0.8979\n",
      "\t140: TRAIN loss 0.1874,  acc 0.9806 || VAL loss 0.7925, acc 0.8868\n",
      "\t150: TRAIN loss 0.1661,  acc 0.9879 || VAL loss 0.7594, acc 0.8994\n",
      "\t160: TRAIN loss 0.1696,  acc 0.9879 || VAL loss 0.7579, acc 0.9034\n",
      "\t170: TRAIN loss 0.1660,  acc 0.9879 || VAL loss 0.7561, acc 0.9074\n",
      "\t180: TRAIN loss 0.1658,  acc 0.9879 || VAL loss 0.7929, acc 0.8987\n",
      "\t190: TRAIN loss 0.1651,  acc 0.9879 || VAL loss 0.7490, acc 0.8994\n",
      "\t200: TRAIN loss 0.1602,  acc 0.9887 || VAL loss 0.7475, acc 0.9002\n",
      "\t210: TRAIN loss 0.1599,  acc 0.9893 || VAL loss 0.7543, acc 0.9010\n",
      "\t220: TRAIN loss 0.1599,  acc 0.9891 || VAL loss 0.7679, acc 0.9018\n",
      "\t230: TRAIN loss 0.1617,  acc 0.9887 || VAL loss 0.7855, acc 0.9018\n",
      "\t240: TRAIN loss 0.1665,  acc 0.9875 || VAL loss 0.7724, acc 0.8971\n",
      "\t250: TRAIN loss 0.1599,  acc 0.9887 || VAL loss 0.7661, acc 0.9066\n",
      "\t260: TRAIN loss 0.1589,  acc 0.9895 || VAL loss 0.7777, acc 0.9018\n",
      "\t270: TRAIN loss 0.1595,  acc 0.9887 || VAL loss 0.7814, acc 0.9042\n",
      "\t280: TRAIN loss 0.1595,  acc 0.9885 || VAL loss 0.7896, acc 0.9010\n",
      "\t290: TRAIN loss 0.1827,  acc 0.9863 || VAL loss 0.8456, acc 0.8939\n",
      "128 128 0.9895091053048297 0.8986539984164688\n",
      "\t0: TRAIN loss 3.7451,  acc 0.3888 || VAL loss 2.0253, acc 0.5051\n",
      "\t10: TRAIN loss 0.5247,  acc 0.8652 || VAL loss 0.7877, acc 0.8195\n",
      "\t20: TRAIN loss 0.2724,  acc 0.9291 || VAL loss 0.6332, acc 0.8567\n",
      "\t30: TRAIN loss 0.1702,  acc 0.9634 || VAL loss 0.5797, acc 0.8741\n",
      "\t40: TRAIN loss 0.2710,  acc 0.9523 || VAL loss 0.6461, acc 0.8781\n",
      "\t50: TRAIN loss 0.1244,  acc 0.9798 || VAL loss 0.6320, acc 0.8804\n",
      "\t60: TRAIN loss 0.1092,  acc 0.9836 || VAL loss 0.6226, acc 0.8860\n",
      "\t70: TRAIN loss 0.0868,  acc 0.9909 || VAL loss 0.6357, acc 0.8947\n",
      "\t80: TRAIN loss 0.0792,  acc 0.9941 || VAL loss 0.6351, acc 0.8971\n",
      "\t90: TRAIN loss 0.0859,  acc 0.9915 || VAL loss 0.6893, acc 0.8987\n",
      "\t100: TRAIN loss 0.0692,  acc 0.9913 || VAL loss 0.6201, acc 0.9002\n",
      "\t110: TRAIN loss 0.0493,  acc 0.9956 || VAL loss 0.6352, acc 0.9042\n",
      "\t120: TRAIN loss 0.0411,  acc 0.9960 || VAL loss 0.6381, acc 0.9074\n",
      "\t130: TRAIN loss 0.0412,  acc 0.9962 || VAL loss 0.6224, acc 0.9082\n",
      "\t140: TRAIN loss 0.0386,  acc 0.9956 || VAL loss 0.6018, acc 0.9089\n",
      "\t150: TRAIN loss 0.1419,  acc 0.9644 || VAL loss 0.7242, acc 0.8868\n",
      "\t160: TRAIN loss 0.0365,  acc 0.9968 || VAL loss 0.6051, acc 0.9105\n",
      "\t170: TRAIN loss 0.0353,  acc 0.9968 || VAL loss 0.6148, acc 0.9097\n",
      "\t180: TRAIN loss 0.0373,  acc 0.9964 || VAL loss 0.6268, acc 0.9082\n",
      "\t190: TRAIN loss 0.0363,  acc 0.9962 || VAL loss 0.6511, acc 0.9042\n",
      "\t200: TRAIN loss 0.0363,  acc 0.9960 || VAL loss 0.6341, acc 0.9082\n",
      "\t210: TRAIN loss 0.0540,  acc 0.9952 || VAL loss 0.6664, acc 0.9058\n",
      "\t220: TRAIN loss 0.0352,  acc 0.9964 || VAL loss 0.6308, acc 0.9105\n",
      "\t230: TRAIN loss 0.0352,  acc 0.9966 || VAL loss 0.6411, acc 0.9113\n",
      "\t240: TRAIN loss 0.0355,  acc 0.9966 || VAL loss 0.6417, acc 0.9121\n",
      "\t250: TRAIN loss 0.0359,  acc 0.9958 || VAL loss 0.6562, acc 0.9066\n",
      "\t260: TRAIN loss 0.0356,  acc 0.9964 || VAL loss 0.6391, acc 0.9105\n",
      "\t270: TRAIN loss 0.0551,  acc 0.9921 || VAL loss 0.6993, acc 0.8931\n",
      "\t280: TRAIN loss 0.0319,  acc 0.9970 || VAL loss 0.6221, acc 0.9113\n",
      "\t290: TRAIN loss 0.0313,  acc 0.9964 || VAL loss 0.6226, acc 0.9145\n",
      "128 256 0.9968329374505146 0.9152810768012668\n",
      "\t0: TRAIN loss 5.8664,  acc 0.3519 || VAL loss 3.5127, acc 0.4949\n",
      "\t10: TRAIN loss 0.5429,  acc 0.8551 || VAL loss 0.8039, acc 0.8187\n",
      "\t20: TRAIN loss 0.3331,  acc 0.9196 || VAL loss 0.8426, acc 0.8274\n",
      "\t30: TRAIN loss 0.1804,  acc 0.9620 || VAL loss 0.6124, acc 0.8820\n",
      "\t40: TRAIN loss 0.1323,  acc 0.9808 || VAL loss 0.6255, acc 0.8868\n",
      "\t50: TRAIN loss 0.1889,  acc 0.9719 || VAL loss 0.6443, acc 0.8868\n",
      "\t60: TRAIN loss 0.1099,  acc 0.9873 || VAL loss 0.6295, acc 0.8955\n",
      "\t70: TRAIN loss 0.0934,  acc 0.9905 || VAL loss 0.6246, acc 0.8963\n",
      "\t80: TRAIN loss 0.2081,  acc 0.9568 || VAL loss 0.7604, acc 0.8694\n",
      "\t90: TRAIN loss 0.0852,  acc 0.9929 || VAL loss 0.6408, acc 0.9074\n",
      "\t100: TRAIN loss 0.0820,  acc 0.9941 || VAL loss 0.6496, acc 0.9034\n",
      "\t110: TRAIN loss 0.0835,  acc 0.9933 || VAL loss 0.6555, acc 0.9058\n",
      "\t120: TRAIN loss 0.1584,  acc 0.9830 || VAL loss 0.8042, acc 0.8915\n",
      "\t130: TRAIN loss 0.0848,  acc 0.9925 || VAL loss 0.7389, acc 0.9074\n",
      "\t140: TRAIN loss 0.0718,  acc 0.9941 || VAL loss 0.7041, acc 0.9058\n",
      "\t150: TRAIN loss 0.0718,  acc 0.9945 || VAL loss 0.7108, acc 0.9058\n",
      "\t160: TRAIN loss 0.0755,  acc 0.9937 || VAL loss 0.7173, acc 0.9113\n",
      "\t170: TRAIN loss 0.0940,  acc 0.9875 || VAL loss 0.8235, acc 0.8915\n",
      "\t180: TRAIN loss 0.0742,  acc 0.9943 || VAL loss 0.7152, acc 0.9034\n",
      "\t190: TRAIN loss 0.0732,  acc 0.9947 || VAL loss 0.7153, acc 0.9018\n",
      "\t200: TRAIN loss 0.0730,  acc 0.9947 || VAL loss 0.7219, acc 0.9026\n",
      "\t210: TRAIN loss 0.0742,  acc 0.9941 || VAL loss 0.7254, acc 0.9058\n",
      "\t220: TRAIN loss 0.0736,  acc 0.9941 || VAL loss 0.7541, acc 0.9018\n",
      "\t230: TRAIN loss 0.0756,  acc 0.9935 || VAL loss 0.7981, acc 0.8947\n",
      "\t240: TRAIN loss 0.0703,  acc 0.9941 || VAL loss 0.7169, acc 0.9034\n",
      "\t250: TRAIN loss 0.0632,  acc 0.9949 || VAL loss 0.7239, acc 0.9050\n",
      "\t260: TRAIN loss 0.0628,  acc 0.9949 || VAL loss 0.7186, acc 0.9058\n",
      "\t270: TRAIN loss 0.0631,  acc 0.9951 || VAL loss 0.7289, acc 0.9074\n",
      "\t280: TRAIN loss 0.0634,  acc 0.9951 || VAL loss 0.7317, acc 0.9074\n",
      "\t290: TRAIN loss 0.0639,  acc 0.9945 || VAL loss 0.7403, acc 0.9058\n",
      "128 512 0.9950514647664291 0.9057798891528107\n",
      "\t0: TRAIN loss 5.2172,  acc 0.3640 || VAL loss 3.2909, acc 0.5313\n",
      "\t10: TRAIN loss 2.2335,  acc 0.7951 || VAL loss 2.5078, acc 0.7522\n",
      "\t20: TRAIN loss 0.4707,  acc 0.9107 || VAL loss 0.7484, acc 0.8401\n",
      "\t30: TRAIN loss 0.2954,  acc 0.9673 || VAL loss 0.6546, acc 0.8797\n",
      "\t40: TRAIN loss 0.2639,  acc 0.9735 || VAL loss 0.6979, acc 0.8963\n",
      "\t50: TRAIN loss 0.2486,  acc 0.9788 || VAL loss 0.6682, acc 0.8923\n",
      "\t60: TRAIN loss 0.2313,  acc 0.9840 || VAL loss 0.6822, acc 0.8963\n",
      "\t70: TRAIN loss 0.4743,  acc 0.9329 || VAL loss 1.0636, acc 0.8535\n",
      "\t80: TRAIN loss 0.1898,  acc 0.9867 || VAL loss 0.6777, acc 0.9050\n",
      "\t90: TRAIN loss 0.1866,  acc 0.9871 || VAL loss 0.6814, acc 0.9042\n",
      "\t100: TRAIN loss 0.1874,  acc 0.9867 || VAL loss 0.6864, acc 0.9058\n",
      "\t110: TRAIN loss 0.1861,  acc 0.9867 || VAL loss 0.7106, acc 0.9042\n",
      "\t120: TRAIN loss 0.1860,  acc 0.9875 || VAL loss 0.7200, acc 0.9042\n",
      "\t130: TRAIN loss 0.2051,  acc 0.9755 || VAL loss 0.7428, acc 0.8947\n",
      "\t140: TRAIN loss 0.1782,  acc 0.9877 || VAL loss 0.7579, acc 0.9010\n",
      "\t150: TRAIN loss 0.1888,  acc 0.9873 || VAL loss 0.7543, acc 0.8994\n",
      "\t160: TRAIN loss 0.1883,  acc 0.9871 || VAL loss 0.7756, acc 0.9034\n",
      "\t170: TRAIN loss 0.1876,  acc 0.9867 || VAL loss 0.7681, acc 0.9050\n",
      "\t180: TRAIN loss 0.1849,  acc 0.9869 || VAL loss 0.7725, acc 0.9089\n",
      "\t190: TRAIN loss 0.1861,  acc 0.9865 || VAL loss 0.7838, acc 0.9066\n",
      "\t200: TRAIN loss 0.1848,  acc 0.9875 || VAL loss 0.7706, acc 0.9074\n",
      "\t210: TRAIN loss 0.1841,  acc 0.9871 || VAL loss 0.7723, acc 0.9074\n",
      "\t220: TRAIN loss 0.1848,  acc 0.9873 || VAL loss 0.7737, acc 0.9074\n",
      "\t230: TRAIN loss 0.1842,  acc 0.9871 || VAL loss 0.7920, acc 0.9066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t240: TRAIN loss 0.1844,  acc 0.9871 || VAL loss 0.8108, acc 0.9074\n",
      "\t250: TRAIN loss 0.1844,  acc 0.9869 || VAL loss 0.7872, acc 0.9074\n",
      "\t260: TRAIN loss 0.1839,  acc 0.9873 || VAL loss 0.7967, acc 0.9097\n",
      "\t270: TRAIN loss 0.1901,  acc 0.9852 || VAL loss 0.8162, acc 0.9010\n",
      "\t280: TRAIN loss 0.1391,  acc 0.9901 || VAL loss 0.7794, acc 0.9050\n",
      "\t290: TRAIN loss 0.1359,  acc 0.9905 || VAL loss 0.7713, acc 0.9082\n",
      "128 1024 0.9910926365795725 0.9113222486144101\n",
      "\t0: TRAIN loss 4.2888,  acc 0.1639 || VAL loss 2.2025, acc 0.2059\n",
      "\t10: TRAIN loss 0.9640,  acc 0.6514 || VAL loss 1.1402, acc 0.6477\n",
      "\t20: TRAIN loss 0.5081,  acc 0.8280 || VAL loss 0.9179, acc 0.7625\n",
      "\t30: TRAIN loss 0.3317,  acc 0.8973 || VAL loss 0.7085, acc 0.8290\n",
      "\t40: TRAIN loss 0.2375,  acc 0.9299 || VAL loss 0.6385, acc 0.8527\n",
      "\t50: TRAIN loss 0.1442,  acc 0.9549 || VAL loss 0.6547, acc 0.8472\n",
      "\t60: TRAIN loss 0.1093,  acc 0.9683 || VAL loss 0.6867, acc 0.8622\n",
      "\t70: TRAIN loss 0.1118,  acc 0.9658 || VAL loss 0.7007, acc 0.8614\n",
      "\t80: TRAIN loss 0.0992,  acc 0.9727 || VAL loss 0.7357, acc 0.8678\n",
      "\t90: TRAIN loss 0.1062,  acc 0.9757 || VAL loss 0.7567, acc 0.8725\n",
      "\t100: TRAIN loss 0.0556,  acc 0.9830 || VAL loss 0.7625, acc 0.8717\n",
      "\t110: TRAIN loss 0.0739,  acc 0.9786 || VAL loss 0.7470, acc 0.8797\n",
      "\t120: TRAIN loss 0.0419,  acc 0.9889 || VAL loss 0.7697, acc 0.8781\n",
      "\t130: TRAIN loss 0.0402,  acc 0.9883 || VAL loss 0.7827, acc 0.8812\n",
      "\t140: TRAIN loss 0.0422,  acc 0.9861 || VAL loss 0.8974, acc 0.8757\n",
      "\t150: TRAIN loss 0.0366,  acc 0.9919 || VAL loss 0.7898, acc 0.8876\n",
      "\t160: TRAIN loss 0.0443,  acc 0.9901 || VAL loss 0.8378, acc 0.8733\n",
      "\t170: TRAIN loss 0.0360,  acc 0.9903 || VAL loss 0.9514, acc 0.8614\n",
      "\t180: TRAIN loss 0.0514,  acc 0.9879 || VAL loss 0.9521, acc 0.8709\n",
      "\t190: TRAIN loss 0.0373,  acc 0.9923 || VAL loss 0.8163, acc 0.8892\n",
      "\t200: TRAIN loss 0.0473,  acc 0.9897 || VAL loss 0.8594, acc 0.8868\n",
      "\t210: TRAIN loss 0.0448,  acc 0.9907 || VAL loss 0.8626, acc 0.8781\n",
      "\t220: TRAIN loss 0.0788,  acc 0.9766 || VAL loss 0.8954, acc 0.8733\n",
      "\t230: TRAIN loss 0.0360,  acc 0.9931 || VAL loss 0.8652, acc 0.8860\n",
      "\t240: TRAIN loss 0.0354,  acc 0.9931 || VAL loss 0.8623, acc 0.8860\n",
      "\t250: TRAIN loss 0.0400,  acc 0.9925 || VAL loss 0.8718, acc 0.8828\n",
      "\t260: TRAIN loss 0.0328,  acc 0.9931 || VAL loss 0.8518, acc 0.8907\n",
      "\t270: TRAIN loss 0.0338,  acc 0.9925 || VAL loss 0.8241, acc 0.8963\n",
      "\t280: TRAIN loss 0.0399,  acc 0.9901 || VAL loss 0.9024, acc 0.8797\n",
      "\t290: TRAIN loss 0.0323,  acc 0.9929 || VAL loss 0.8564, acc 0.8955\n",
      "256 16 0.9926761678543151 0.8931116389548693\n",
      "\t0: TRAIN loss 3.4138,  acc 0.3577 || VAL loss 1.7937, acc 0.5075\n",
      "\t10: TRAIN loss 0.5180,  acc 0.8591 || VAL loss 0.8081, acc 0.8005\n",
      "\t20: TRAIN loss 0.2910,  acc 0.9204 || VAL loss 0.6253, acc 0.8401\n",
      "\t30: TRAIN loss 0.1897,  acc 0.9505 || VAL loss 0.5932, acc 0.8686\n",
      "\t40: TRAIN loss 0.1271,  acc 0.9683 || VAL loss 0.6283, acc 0.8725\n",
      "\t50: TRAIN loss 0.0939,  acc 0.9788 || VAL loss 0.5640, acc 0.8828\n",
      "\t60: TRAIN loss 0.0757,  acc 0.9859 || VAL loss 0.5701, acc 0.8899\n",
      "\t70: TRAIN loss 0.0906,  acc 0.9830 || VAL loss 0.6143, acc 0.8923\n",
      "\t80: TRAIN loss 0.0947,  acc 0.9859 || VAL loss 0.5919, acc 0.9002\n",
      "\t90: TRAIN loss 0.0453,  acc 0.9939 || VAL loss 0.6463, acc 0.8947\n",
      "\t100: TRAIN loss 0.0426,  acc 0.9945 || VAL loss 0.6820, acc 0.8899\n",
      "\t110: TRAIN loss 0.0520,  acc 0.9921 || VAL loss 0.7143, acc 0.8812\n",
      "\t120: TRAIN loss 0.0537,  acc 0.9923 || VAL loss 0.6281, acc 0.8994\n",
      "\t130: TRAIN loss 0.0436,  acc 0.9960 || VAL loss 0.6509, acc 0.8955\n",
      "\t140: TRAIN loss 0.0463,  acc 0.9960 || VAL loss 0.6642, acc 0.8994\n",
      "\t150: TRAIN loss 0.0445,  acc 0.9956 || VAL loss 0.6912, acc 0.8963\n",
      "\t160: TRAIN loss 0.0569,  acc 0.9905 || VAL loss 0.7623, acc 0.8931\n",
      "\t170: TRAIN loss 0.0308,  acc 0.9966 || VAL loss 0.6755, acc 0.9034\n",
      "\t180: TRAIN loss 0.0304,  acc 0.9962 || VAL loss 0.6916, acc 0.8979\n",
      "\t190: TRAIN loss 0.0657,  acc 0.9848 || VAL loss 0.8423, acc 0.8757\n",
      "\t200: TRAIN loss 0.0302,  acc 0.9970 || VAL loss 0.6684, acc 0.9034\n",
      "\t210: TRAIN loss 0.0294,  acc 0.9968 || VAL loss 0.6765, acc 0.9058\n",
      "\t220: TRAIN loss 0.0316,  acc 0.9970 || VAL loss 0.6596, acc 0.9050\n",
      "\t230: TRAIN loss 0.1583,  acc 0.9681 || VAL loss 0.9407, acc 0.8662\n",
      "\t240: TRAIN loss 0.0294,  acc 0.9970 || VAL loss 0.7025, acc 0.9034\n",
      "\t250: TRAIN loss 0.0286,  acc 0.9972 || VAL loss 0.7090, acc 0.9050\n",
      "\t260: TRAIN loss 0.0283,  acc 0.9976 || VAL loss 0.7178, acc 0.9018\n",
      "\t270: TRAIN loss 0.0292,  acc 0.9966 || VAL loss 0.6697, acc 0.9050\n",
      "\t280: TRAIN loss 0.0295,  acc 0.9966 || VAL loss 0.7139, acc 0.9050\n",
      "\t290: TRAIN loss 0.0300,  acc 0.9966 || VAL loss 0.7144, acc 0.9034\n",
      "256 32 0.9974267616785432 0.9041963578780681\n",
      "\t0: TRAIN loss 5.3949,  acc 0.3535 || VAL loss 2.5341, acc 0.4996\n",
      "\t10: TRAIN loss 0.4853,  acc 0.8513 || VAL loss 0.8467, acc 0.7918\n",
      "\t20: TRAIN loss 0.2855,  acc 0.9224 || VAL loss 0.7059, acc 0.8377\n",
      "\t30: TRAIN loss 0.1667,  acc 0.9602 || VAL loss 0.5682, acc 0.8749\n",
      "\t40: TRAIN loss 0.1262,  acc 0.9699 || VAL loss 0.5597, acc 0.8892\n",
      "\t50: TRAIN loss 0.1016,  acc 0.9788 || VAL loss 0.5657, acc 0.8963\n",
      "\t60: TRAIN loss 0.1386,  acc 0.9729 || VAL loss 0.6935, acc 0.8804\n",
      "\t70: TRAIN loss 0.0729,  acc 0.9865 || VAL loss 0.5474, acc 0.9002\n",
      "\t80: TRAIN loss 0.0667,  acc 0.9895 || VAL loss 0.5614, acc 0.9018\n",
      "\t90: TRAIN loss 0.0508,  acc 0.9943 || VAL loss 0.5696, acc 0.9026\n",
      "\t100: TRAIN loss 0.0545,  acc 0.9923 || VAL loss 0.6050, acc 0.8892\n",
      "\t110: TRAIN loss 0.0587,  acc 0.9905 || VAL loss 0.7031, acc 0.8868\n",
      "\t120: TRAIN loss 0.0823,  acc 0.9905 || VAL loss 0.7730, acc 0.8971\n",
      "\t130: TRAIN loss 0.0296,  acc 0.9962 || VAL loss 0.6455, acc 0.9105\n",
      "\t140: TRAIN loss 0.0296,  acc 0.9968 || VAL loss 0.6295, acc 0.9089\n",
      "\t150: TRAIN loss 0.0345,  acc 0.9954 || VAL loss 0.6691, acc 0.9018\n",
      "\t160: TRAIN loss 0.0512,  acc 0.9907 || VAL loss 0.6726, acc 0.9050\n",
      "\t170: TRAIN loss 0.0285,  acc 0.9970 || VAL loss 0.6366, acc 0.9145\n",
      "\t180: TRAIN loss 0.0281,  acc 0.9962 || VAL loss 0.6605, acc 0.9145\n",
      "\t190: TRAIN loss 0.0306,  acc 0.9964 || VAL loss 0.7183, acc 0.8979\n",
      "\t200: TRAIN loss 0.0271,  acc 0.9972 || VAL loss 0.6509, acc 0.9153\n",
      "\t210: TRAIN loss 0.1270,  acc 0.9820 || VAL loss 0.7426, acc 0.8979\n",
      "\t220: TRAIN loss 0.0582,  acc 0.9949 || VAL loss 0.6973, acc 0.9097\n",
      "\t230: TRAIN loss 0.0583,  acc 0.9951 || VAL loss 0.6967, acc 0.9082\n",
      "\t240: TRAIN loss 0.0606,  acc 0.9947 || VAL loss 0.6857, acc 0.9097\n",
      "\t250: TRAIN loss 0.0596,  acc 0.9945 || VAL loss 0.7170, acc 0.9058\n",
      "\t260: TRAIN loss 0.1004,  acc 0.9806 || VAL loss 0.7782, acc 0.8947\n",
      "\t270: TRAIN loss 0.0233,  acc 0.9972 || VAL loss 0.6710, acc 0.9097\n",
      "\t280: TRAIN loss 0.0230,  acc 0.9970 || VAL loss 0.6728, acc 0.9105\n",
      "\t290: TRAIN loss 0.0239,  acc 0.9970 || VAL loss 0.6726, acc 0.9121\n",
      "256 64 0.9978226444972288 0.9081551860649247\n",
      "\t0: TRAIN loss 4.9721,  acc 0.3529 || VAL loss 2.1179, acc 0.5107\n",
      "\t10: TRAIN loss 0.4192,  acc 0.8854 || VAL loss 0.7133, acc 0.8187\n",
      "\t20: TRAIN loss 0.2687,  acc 0.9418 || VAL loss 0.5806, acc 0.8646\n",
      "\t30: TRAIN loss 0.2020,  acc 0.9539 || VAL loss 0.5438, acc 0.8757\n",
      "\t40: TRAIN loss 0.1591,  acc 0.9669 || VAL loss 0.5300, acc 0.8860\n",
      "\t50: TRAIN loss 0.3564,  acc 0.9365 || VAL loss 0.7710, acc 0.8575\n",
      "\t60: TRAIN loss 0.1253,  acc 0.9796 || VAL loss 0.6029, acc 0.8789\n",
      "\t70: TRAIN loss 0.0861,  acc 0.9915 || VAL loss 0.5717, acc 0.9066\n",
      "\t80: TRAIN loss 0.1039,  acc 0.9854 || VAL loss 0.5614, acc 0.8994\n",
      "\t90: TRAIN loss 0.0705,  acc 0.9939 || VAL loss 0.5572, acc 0.9121\n",
      "\t100: TRAIN loss 0.0690,  acc 0.9941 || VAL loss 0.5822, acc 0.9010\n",
      "\t110: TRAIN loss 0.0657,  acc 0.9947 || VAL loss 0.5482, acc 0.9121\n",
      "\t120: TRAIN loss 0.0666,  acc 0.9895 || VAL loss 0.6265, acc 0.9050\n",
      "\t130: TRAIN loss 0.0501,  acc 0.9954 || VAL loss 0.6036, acc 0.9058\n",
      "\t140: TRAIN loss 0.0537,  acc 0.9947 || VAL loss 0.5947, acc 0.9129\n",
      "\t150: TRAIN loss 0.0514,  acc 0.9949 || VAL loss 0.6180, acc 0.9058\n",
      "\t160: TRAIN loss 0.0948,  acc 0.9814 || VAL loss 0.7808, acc 0.8749\n",
      "\t170: TRAIN loss 0.0741,  acc 0.9921 || VAL loss 0.5805, acc 0.9137\n",
      "\t180: TRAIN loss 0.0514,  acc 0.9949 || VAL loss 0.5924, acc 0.9177\n",
      "\t190: TRAIN loss 0.0485,  acc 0.9954 || VAL loss 0.6090, acc 0.9105\n",
      "\t200: TRAIN loss 0.0525,  acc 0.9952 || VAL loss 0.6102, acc 0.9161\n",
      "\t210: TRAIN loss 0.0493,  acc 0.9952 || VAL loss 0.6151, acc 0.9161\n",
      "\t220: TRAIN loss 0.0487,  acc 0.9958 || VAL loss 0.6239, acc 0.9161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t230: TRAIN loss 0.0498,  acc 0.9954 || VAL loss 0.6277, acc 0.9145\n",
      "\t240: TRAIN loss 0.0711,  acc 0.9897 || VAL loss 0.7124, acc 0.8947\n",
      "\t250: TRAIN loss 0.0377,  acc 0.9968 || VAL loss 0.6299, acc 0.9105\n",
      "\t260: TRAIN loss 0.0375,  acc 0.9970 || VAL loss 0.6296, acc 0.9137\n",
      "\t270: TRAIN loss 0.0388,  acc 0.9960 || VAL loss 0.6385, acc 0.9153\n",
      "\t280: TRAIN loss 0.0380,  acc 0.9964 || VAL loss 0.6351, acc 0.9169\n",
      "\t290: TRAIN loss 0.0381,  acc 0.9964 || VAL loss 0.6229, acc 0.9177\n",
      "256 128 0.9970308788598575 0.9136975455265242\n",
      "\t0: TRAIN loss 7.1867,  acc 0.3179 || VAL loss 3.6688, acc 0.4774\n",
      "\t10: TRAIN loss 0.4322,  acc 0.8822 || VAL loss 0.6955, acc 0.8337\n",
      "\t20: TRAIN loss 0.2792,  acc 0.9347 || VAL loss 0.6723, acc 0.8638\n",
      "\t30: TRAIN loss 0.2388,  acc 0.9487 || VAL loss 0.6765, acc 0.8741\n",
      "\t40: TRAIN loss 0.1240,  acc 0.9834 || VAL loss 0.5363, acc 0.9082\n",
      "\t50: TRAIN loss 0.1212,  acc 0.9840 || VAL loss 0.5997, acc 0.8907\n",
      "\t60: TRAIN loss 0.1313,  acc 0.9798 || VAL loss 0.6010, acc 0.8963\n",
      "\t70: TRAIN loss 0.0966,  acc 0.9911 || VAL loss 0.5692, acc 0.9082\n",
      "\t80: TRAIN loss 0.0932,  acc 0.9927 || VAL loss 0.5648, acc 0.9129\n",
      "\t90: TRAIN loss 0.0918,  acc 0.9921 || VAL loss 0.6219, acc 0.9066\n",
      "\t100: TRAIN loss 0.2804,  acc 0.9638 || VAL loss 0.6778, acc 0.8947\n",
      "\t110: TRAIN loss 0.0900,  acc 0.9925 || VAL loss 0.6315, acc 0.9105\n",
      "\t120: TRAIN loss 0.0859,  acc 0.9931 || VAL loss 0.6269, acc 0.9153\n",
      "\t130: TRAIN loss 0.0838,  acc 0.9939 || VAL loss 0.6219, acc 0.9161\n",
      "\t140: TRAIN loss 0.0889,  acc 0.9929 || VAL loss 0.6039, acc 0.9097\n",
      "\t150: TRAIN loss 0.0857,  acc 0.9935 || VAL loss 0.6176, acc 0.9153\n",
      "\t160: TRAIN loss 0.0848,  acc 0.9933 || VAL loss 0.6188, acc 0.9184\n",
      "\t170: TRAIN loss 0.0833,  acc 0.9935 || VAL loss 0.6419, acc 0.9145\n",
      "\t180: TRAIN loss 0.1279,  acc 0.9818 || VAL loss 0.7087, acc 0.8987\n",
      "\t190: TRAIN loss 0.0419,  acc 0.9958 || VAL loss 0.6198, acc 0.9224\n",
      "\t200: TRAIN loss 0.0414,  acc 0.9958 || VAL loss 0.6230, acc 0.9216\n",
      "\t210: TRAIN loss 0.0416,  acc 0.9968 || VAL loss 0.6480, acc 0.9224\n",
      "\t220: TRAIN loss 0.0413,  acc 0.9960 || VAL loss 0.6376, acc 0.9224\n",
      "\t230: TRAIN loss 0.0423,  acc 0.9960 || VAL loss 0.6366, acc 0.9216\n",
      "\t240: TRAIN loss 0.0410,  acc 0.9960 || VAL loss 0.6512, acc 0.9145\n",
      "\t250: TRAIN loss 0.0417,  acc 0.9956 || VAL loss 0.6583, acc 0.9216\n",
      "\t260: TRAIN loss 0.0887,  acc 0.9871 || VAL loss 0.6871, acc 0.9010\n",
      "\t270: TRAIN loss 0.0437,  acc 0.9962 || VAL loss 0.5823, acc 0.9272\n",
      "\t280: TRAIN loss 0.0435,  acc 0.9960 || VAL loss 0.5920, acc 0.9264\n",
      "\t290: TRAIN loss 0.0438,  acc 0.9958 || VAL loss 0.5957, acc 0.9248\n",
      "256 256 0.9958432304038005 0.9192399049881235\n",
      "\t0: TRAIN loss 4.2658,  acc 0.4313 || VAL loss 3.6344, acc 0.4980\n",
      "\t10: TRAIN loss 0.4051,  acc 0.8973 || VAL loss 0.7233, acc 0.8401\n",
      "\t20: TRAIN loss 0.2022,  acc 0.9559 || VAL loss 0.6339, acc 0.8812\n",
      "\t30: TRAIN loss 0.1059,  acc 0.9806 || VAL loss 0.6026, acc 0.8876\n",
      "\t40: TRAIN loss 0.1395,  acc 0.9778 || VAL loss 0.6285, acc 0.9010\n",
      "\t50: TRAIN loss 0.0948,  acc 0.9909 || VAL loss 0.5721, acc 0.9177\n",
      "\t60: TRAIN loss 0.0937,  acc 0.9909 || VAL loss 0.5820, acc 0.9145\n",
      "\t70: TRAIN loss 0.1360,  acc 0.9808 || VAL loss 0.6669, acc 0.8947\n",
      "\t80: TRAIN loss 0.0639,  acc 0.9947 || VAL loss 0.5966, acc 0.9153\n",
      "\t90: TRAIN loss 0.0638,  acc 0.9951 || VAL loss 0.6286, acc 0.9137\n",
      "\t100: TRAIN loss 0.0698,  acc 0.9935 || VAL loss 0.6386, acc 0.9113\n",
      "\t110: TRAIN loss 0.1033,  acc 0.9913 || VAL loss 0.5898, acc 0.9224\n",
      "\t120: TRAIN loss 0.0981,  acc 0.9919 || VAL loss 0.6144, acc 0.9208\n",
      "\t130: TRAIN loss 0.0934,  acc 0.9925 || VAL loss 0.6149, acc 0.9216\n",
      "\t140: TRAIN loss 0.0934,  acc 0.9923 || VAL loss 0.6027, acc 0.9200\n",
      "\t150: TRAIN loss 0.0928,  acc 0.9929 || VAL loss 0.6141, acc 0.9208\n",
      "\t160: TRAIN loss 0.1070,  acc 0.9909 || VAL loss 0.6576, acc 0.9097\n",
      "\t170: TRAIN loss 0.1089,  acc 0.9919 || VAL loss 0.6591, acc 0.9145\n",
      "\t180: TRAIN loss 0.1079,  acc 0.9923 || VAL loss 0.6826, acc 0.9137\n",
      "\t190: TRAIN loss 0.1088,  acc 0.9921 || VAL loss 0.6621, acc 0.9177\n",
      "\t200: TRAIN loss 0.1081,  acc 0.9921 || VAL loss 0.6677, acc 0.9145\n",
      "\t210: TRAIN loss 0.1089,  acc 0.9917 || VAL loss 0.6636, acc 0.9232\n",
      "\t220: TRAIN loss 0.1081,  acc 0.9919 || VAL loss 0.6681, acc 0.9224\n",
      "\t230: TRAIN loss 0.0796,  acc 0.9941 || VAL loss 0.6028, acc 0.9145\n",
      "\t240: TRAIN loss 0.0794,  acc 0.9941 || VAL loss 0.6113, acc 0.9169\n",
      "\t250: TRAIN loss 0.0795,  acc 0.9941 || VAL loss 0.6210, acc 0.9232\n",
      "\t260: TRAIN loss 0.0788,  acc 0.9939 || VAL loss 0.6259, acc 0.9216\n",
      "\t270: TRAIN loss 0.0791,  acc 0.9943 || VAL loss 0.6240, acc 0.9256\n",
      "\t280: TRAIN loss 0.0786,  acc 0.9937 || VAL loss 0.6294, acc 0.9240\n",
      "\t290: TRAIN loss 0.0789,  acc 0.9939 || VAL loss 0.6279, acc 0.9248\n",
      "256 512 0.9932699920823437 0.9168646080760094\n",
      "\t0: TRAIN loss 7.4535,  acc 0.3230 || VAL loss 6.1491, acc 0.3634\n",
      "\t10: TRAIN loss 1.1986,  acc 0.8537 || VAL loss 1.4919, acc 0.7981\n",
      "\t20: TRAIN loss 1.0587,  acc 0.9024 || VAL loss 1.4257, acc 0.8290\n",
      "\t30: TRAIN loss 0.9353,  acc 0.9248 || VAL loss 1.3160, acc 0.8290\n",
      "\t40: TRAIN loss 0.8400,  acc 0.9388 || VAL loss 1.2606, acc 0.8614\n",
      "\t50: TRAIN loss 0.8056,  acc 0.9481 || VAL loss 1.2262, acc 0.8709\n",
      "\t60: TRAIN loss 0.8023,  acc 0.9479 || VAL loss 1.2812, acc 0.8694\n",
      "\t70: TRAIN loss 0.2071,  acc 0.9679 || VAL loss 0.6564, acc 0.8987\n",
      "\t80: TRAIN loss 0.1064,  acc 0.9923 || VAL loss 0.5449, acc 0.9169\n",
      "\t90: TRAIN loss 0.1041,  acc 0.9919 || VAL loss 0.5483, acc 0.9200\n",
      "\t100: TRAIN loss 0.1037,  acc 0.9921 || VAL loss 0.5645, acc 0.9200\n",
      "\t110: TRAIN loss 0.1050,  acc 0.9919 || VAL loss 0.5605, acc 0.9192\n",
      "\t120: TRAIN loss 0.1077,  acc 0.9899 || VAL loss 0.6437, acc 0.9192\n",
      "\t130: TRAIN loss 0.0833,  acc 0.9933 || VAL loss 0.5690, acc 0.9232\n",
      "\t140: TRAIN loss 0.0826,  acc 0.9937 || VAL loss 0.5622, acc 0.9256\n",
      "\t150: TRAIN loss 0.0839,  acc 0.9929 || VAL loss 0.5737, acc 0.9248\n",
      "\t160: TRAIN loss 0.0825,  acc 0.9939 || VAL loss 0.5753, acc 0.9248\n",
      "\t170: TRAIN loss 0.0822,  acc 0.9941 || VAL loss 0.5888, acc 0.9216\n",
      "\t180: TRAIN loss 0.0828,  acc 0.9937 || VAL loss 0.5864, acc 0.9216\n",
      "\t190: TRAIN loss 0.0825,  acc 0.9931 || VAL loss 0.5966, acc 0.9240\n",
      "\t200: TRAIN loss 0.0867,  acc 0.9919 || VAL loss 0.6025, acc 0.9192\n",
      "\t210: TRAIN loss 0.0444,  acc 0.9960 || VAL loss 0.5413, acc 0.9224\n",
      "\t220: TRAIN loss 0.0439,  acc 0.9958 || VAL loss 0.5619, acc 0.9240\n",
      "\t230: TRAIN loss 0.0439,  acc 0.9962 || VAL loss 0.5736, acc 0.9224\n",
      "\t240: TRAIN loss 0.0437,  acc 0.9960 || VAL loss 0.5857, acc 0.9224\n",
      "\t250: TRAIN loss 0.0436,  acc 0.9960 || VAL loss 0.5892, acc 0.9232\n",
      "\t260: TRAIN loss 0.0436,  acc 0.9954 || VAL loss 0.6023, acc 0.9216\n",
      "\t270: TRAIN loss 0.0436,  acc 0.9958 || VAL loss 0.6007, acc 0.9256\n",
      "\t280: TRAIN loss 0.0435,  acc 0.9962 || VAL loss 0.6064, acc 0.9264\n",
      "\t290: TRAIN loss 0.1063,  acc 0.9850 || VAL loss 0.6431, acc 0.9074\n",
      "256 1024 0.9974267616785432 0.9263657957244655\n",
      "\t0: TRAIN loss 3.7516,  acc 0.1718 || VAL loss 2.2648, acc 0.1568\n",
      "\t10: TRAIN loss 1.2235,  acc 0.5825 || VAL loss 1.3924, acc 0.5772\n",
      "\t20: TRAIN loss 0.5828,  acc 0.8100 || VAL loss 0.9022, acc 0.7482\n",
      "\t30: TRAIN loss 0.2941,  acc 0.9129 || VAL loss 0.6434, acc 0.8416\n",
      "\t40: TRAIN loss 0.1943,  acc 0.9434 || VAL loss 0.5732, acc 0.8670\n",
      "\t50: TRAIN loss 0.1796,  acc 0.9471 || VAL loss 0.6647, acc 0.8670\n",
      "\t60: TRAIN loss 0.0990,  acc 0.9770 || VAL loss 0.5653, acc 0.8892\n",
      "\t70: TRAIN loss 0.0789,  acc 0.9798 || VAL loss 0.5796, acc 0.8994\n",
      "\t80: TRAIN loss 0.0516,  acc 0.9895 || VAL loss 0.5907, acc 0.8979\n",
      "\t90: TRAIN loss 0.0441,  acc 0.9915 || VAL loss 0.6393, acc 0.9010\n",
      "\t100: TRAIN loss 0.1089,  acc 0.9757 || VAL loss 0.6690, acc 0.8892\n",
      "\t110: TRAIN loss 0.0585,  acc 0.9877 || VAL loss 0.7104, acc 0.8931\n",
      "\t120: TRAIN loss 0.0816,  acc 0.9806 || VAL loss 0.8081, acc 0.8781\n",
      "\t130: TRAIN loss 0.0341,  acc 0.9958 || VAL loss 0.6987, acc 0.9050\n",
      "\t140: TRAIN loss 0.0230,  acc 0.9949 || VAL loss 0.7295, acc 0.8987\n",
      "\t150: TRAIN loss 0.0208,  acc 0.9970 || VAL loss 0.7438, acc 0.8947\n",
      "\t160: TRAIN loss 0.0603,  acc 0.9838 || VAL loss 0.8225, acc 0.8773\n",
      "\t170: TRAIN loss 0.0196,  acc 0.9966 || VAL loss 0.7823, acc 0.8939\n",
      "\t180: TRAIN loss 0.0195,  acc 0.9966 || VAL loss 0.7805, acc 0.8979\n",
      "\t190: TRAIN loss 0.0643,  acc 0.9836 || VAL loss 0.8582, acc 0.8773\n",
      "\t200: TRAIN loss 0.0235,  acc 0.9964 || VAL loss 0.7441, acc 0.9058\n",
      "\t210: TRAIN loss 0.0225,  acc 0.9966 || VAL loss 0.7610, acc 0.9026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t220: TRAIN loss 0.0218,  acc 0.9966 || VAL loss 0.7652, acc 0.9018\n",
      "\t230: TRAIN loss 0.0362,  acc 0.9923 || VAL loss 0.8422, acc 0.8836\n",
      "\t240: TRAIN loss 0.0273,  acc 0.9943 || VAL loss 0.7810, acc 0.9058\n",
      "\t250: TRAIN loss 0.0195,  acc 0.9964 || VAL loss 0.8050, acc 0.8994\n",
      "\t260: TRAIN loss 0.0170,  acc 0.9972 || VAL loss 0.7987, acc 0.9026\n",
      "\t270: TRAIN loss 0.0166,  acc 0.9974 || VAL loss 0.7795, acc 0.9034\n",
      "\t280: TRAIN loss 0.0166,  acc 0.9970 || VAL loss 0.7846, acc 0.9034\n",
      "\t290: TRAIN loss 0.0467,  acc 0.9947 || VAL loss 0.8283, acc 0.9034\n",
      "512 16 0.9974267616785432 0.8986539984164688\n",
      "\t0: TRAIN loss 3.7928,  acc 0.3561 || VAL loss 1.6486, acc 0.5099\n",
      "\t10: TRAIN loss 0.5021,  acc 0.8537 || VAL loss 0.7466, acc 0.8124\n",
      "\t20: TRAIN loss 0.3494,  acc 0.9022 || VAL loss 0.6913, acc 0.8440\n",
      "\t30: TRAIN loss 0.2334,  acc 0.9410 || VAL loss 0.6042, acc 0.8741\n",
      "\t40: TRAIN loss 0.1179,  acc 0.9727 || VAL loss 0.5443, acc 0.8899\n",
      "\t50: TRAIN loss 0.1136,  acc 0.9768 || VAL loss 0.5719, acc 0.8931\n",
      "\t60: TRAIN loss 0.0725,  acc 0.9905 || VAL loss 0.5258, acc 0.9042\n",
      "\t70: TRAIN loss 0.0717,  acc 0.9895 || VAL loss 0.5351, acc 0.9026\n",
      "\t80: TRAIN loss 0.0577,  acc 0.9927 || VAL loss 0.5475, acc 0.9026\n",
      "\t90: TRAIN loss 0.1906,  acc 0.9656 || VAL loss 0.6322, acc 0.8915\n",
      "\t100: TRAIN loss 0.1521,  acc 0.9739 || VAL loss 0.6235, acc 0.8963\n",
      "\t110: TRAIN loss 0.0504,  acc 0.9958 || VAL loss 0.6073, acc 0.9074\n",
      "\t120: TRAIN loss 0.0543,  acc 0.9951 || VAL loss 0.5916, acc 0.9082\n",
      "\t130: TRAIN loss 0.0502,  acc 0.9952 || VAL loss 0.5774, acc 0.9129\n",
      "\t140: TRAIN loss 0.0513,  acc 0.9952 || VAL loss 0.6054, acc 0.9018\n",
      "\t150: TRAIN loss 0.0242,  acc 0.9964 || VAL loss 0.6012, acc 0.9137\n",
      "\t160: TRAIN loss 0.0198,  acc 0.9974 || VAL loss 0.5959, acc 0.9105\n",
      "\t170: TRAIN loss 0.0169,  acc 0.9980 || VAL loss 0.6207, acc 0.9089\n",
      "\t180: TRAIN loss 0.0446,  acc 0.9883 || VAL loss 0.7741, acc 0.8844\n",
      "\t190: TRAIN loss 0.0187,  acc 0.9974 || VAL loss 0.6008, acc 0.9121\n",
      "\t200: TRAIN loss 0.0177,  acc 0.9982 || VAL loss 0.6154, acc 0.9129\n",
      "\t210: TRAIN loss 0.0180,  acc 0.9972 || VAL loss 0.6119, acc 0.9169\n",
      "\t220: TRAIN loss 0.0302,  acc 0.9949 || VAL loss 0.7486, acc 0.9034\n",
      "\t230: TRAIN loss 0.0268,  acc 0.9956 || VAL loss 0.6617, acc 0.9105\n",
      "\t240: TRAIN loss 0.0167,  acc 0.9976 || VAL loss 0.6320, acc 0.9089\n",
      "\t250: TRAIN loss 0.0173,  acc 0.9972 || VAL loss 0.6302, acc 0.9089\n",
      "\t260: TRAIN loss 0.0180,  acc 0.9978 || VAL loss 0.6580, acc 0.9113\n",
      "\t270: TRAIN loss 0.0169,  acc 0.9980 || VAL loss 0.6307, acc 0.9129\n",
      "\t280: TRAIN loss 0.0189,  acc 0.9972 || VAL loss 0.6495, acc 0.9089\n",
      "\t290: TRAIN loss 0.0170,  acc 0.9976 || VAL loss 0.6725, acc 0.9074\n",
      "512 32 0.9980205859065716 0.9081551860649247\n",
      "\t0: TRAIN loss 6.7783,  acc 0.3626 || VAL loss 5.6981, acc 0.4624\n",
      "\t10: TRAIN loss 0.5748,  acc 0.8440 || VAL loss 0.8759, acc 0.7696\n",
      "\t20: TRAIN loss 0.2827,  acc 0.9341 || VAL loss 0.6705, acc 0.8551\n",
      "\t30: TRAIN loss 0.2034,  acc 0.9632 || VAL loss 0.6148, acc 0.8773\n",
      "\t40: TRAIN loss 0.1887,  acc 0.9654 || VAL loss 0.6975, acc 0.8717\n",
      "\t50: TRAIN loss 0.1237,  acc 0.9838 || VAL loss 0.5413, acc 0.9026\n",
      "\t60: TRAIN loss 0.1043,  acc 0.9895 || VAL loss 0.5520, acc 0.9050\n",
      "\t70: TRAIN loss 0.0966,  acc 0.9917 || VAL loss 0.6119, acc 0.8939\n",
      "\t80: TRAIN loss 0.1340,  acc 0.9753 || VAL loss 0.6936, acc 0.8828\n",
      "\t90: TRAIN loss 0.0864,  acc 0.9927 || VAL loss 0.6009, acc 0.9097\n",
      "\t100: TRAIN loss 0.0911,  acc 0.9921 || VAL loss 0.6086, acc 0.9089\n",
      "\t110: TRAIN loss 0.2843,  acc 0.9424 || VAL loss 0.9098, acc 0.8464\n",
      "\t120: TRAIN loss 0.1251,  acc 0.9881 || VAL loss 0.6789, acc 0.9034\n",
      "\t130: TRAIN loss 0.0860,  acc 0.9929 || VAL loss 0.6411, acc 0.9121\n",
      "\t140: TRAIN loss 0.0844,  acc 0.9933 || VAL loss 0.6418, acc 0.9074\n",
      "\t150: TRAIN loss 0.0868,  acc 0.9927 || VAL loss 0.6846, acc 0.9074\n",
      "\t160: TRAIN loss 0.0820,  acc 0.9933 || VAL loss 0.6564, acc 0.9097\n",
      "\t170: TRAIN loss 0.0816,  acc 0.9933 || VAL loss 0.6516, acc 0.9129\n",
      "\t180: TRAIN loss 0.0855,  acc 0.9921 || VAL loss 0.6032, acc 0.9089\n",
      "\t190: TRAIN loss 0.0822,  acc 0.9931 || VAL loss 0.6021, acc 0.9121\n",
      "\t200: TRAIN loss 0.0802,  acc 0.9939 || VAL loss 0.6073, acc 0.9137\n",
      "\t210: TRAIN loss 0.0810,  acc 0.9935 || VAL loss 0.5966, acc 0.9161\n",
      "\t220: TRAIN loss 0.0804,  acc 0.9937 || VAL loss 0.6032, acc 0.9169\n",
      "\t230: TRAIN loss 0.0805,  acc 0.9937 || VAL loss 0.6216, acc 0.9105\n",
      "\t240: TRAIN loss 0.1729,  acc 0.9844 || VAL loss 0.6975, acc 0.9105\n",
      "\t250: TRAIN loss 0.1237,  acc 0.9913 || VAL loss 0.6835, acc 0.9169\n",
      "\t260: TRAIN loss 0.1237,  acc 0.9913 || VAL loss 0.6846, acc 0.9129\n",
      "\t270: TRAIN loss 0.1242,  acc 0.9909 || VAL loss 0.6930, acc 0.9169\n",
      "\t280: TRAIN loss 0.1240,  acc 0.9909 || VAL loss 0.6866, acc 0.9192\n",
      "\t290: TRAIN loss 0.0853,  acc 0.9937 || VAL loss 0.6231, acc 0.9184\n",
      "512 64 0.9936658749010293 0.9184481393507522\n",
      "\t0: TRAIN loss 5.7895,  acc 0.3519 || VAL loss 3.2851, acc 0.4996\n",
      "\t10: TRAIN loss 0.5430,  acc 0.8731 || VAL loss 0.8065, acc 0.8203\n",
      "\t20: TRAIN loss 0.3372,  acc 0.9404 || VAL loss 0.6433, acc 0.8789\n",
      "\t30: TRAIN loss 0.2600,  acc 0.9622 || VAL loss 0.6508, acc 0.8892\n",
      "\t40: TRAIN loss 0.2281,  acc 0.9703 || VAL loss 0.5656, acc 0.9058\n",
      "\t50: TRAIN loss 0.2082,  acc 0.9764 || VAL loss 0.6547, acc 0.8923\n",
      "\t60: TRAIN loss 0.1797,  acc 0.9861 || VAL loss 0.5858, acc 0.9066\n",
      "\t70: TRAIN loss 0.2908,  acc 0.9679 || VAL loss 0.9278, acc 0.8765\n",
      "\t80: TRAIN loss 0.1943,  acc 0.9842 || VAL loss 0.6715, acc 0.9105\n",
      "\t90: TRAIN loss 0.1008,  acc 0.9852 || VAL loss 0.6175, acc 0.8979\n",
      "\t100: TRAIN loss 0.0640,  acc 0.9947 || VAL loss 0.5284, acc 0.9184\n",
      "\t110: TRAIN loss 0.0661,  acc 0.9943 || VAL loss 0.5364, acc 0.9240\n",
      "\t120: TRAIN loss 0.0721,  acc 0.9917 || VAL loss 0.5932, acc 0.9161\n",
      "\t130: TRAIN loss 0.1240,  acc 0.9832 || VAL loss 0.7854, acc 0.8899\n",
      "\t140: TRAIN loss 0.0628,  acc 0.9937 || VAL loss 0.6238, acc 0.9066\n",
      "\t150: TRAIN loss 0.0563,  acc 0.9951 || VAL loss 0.5701, acc 0.9161\n",
      "\t160: TRAIN loss 0.0563,  acc 0.9954 || VAL loss 0.5614, acc 0.9224\n",
      "\t170: TRAIN loss 0.0563,  acc 0.9951 || VAL loss 0.5652, acc 0.9272\n",
      "\t180: TRAIN loss 0.0845,  acc 0.9861 || VAL loss 0.7598, acc 0.8884\n",
      "\t190: TRAIN loss 0.1237,  acc 0.9834 || VAL loss 0.7014, acc 0.9058\n",
      "\t200: TRAIN loss 0.0512,  acc 0.9954 || VAL loss 0.5554, acc 0.9272\n",
      "\t210: TRAIN loss 0.0512,  acc 0.9958 || VAL loss 0.5637, acc 0.9279\n",
      "\t220: TRAIN loss 0.0514,  acc 0.9954 || VAL loss 0.5772, acc 0.9264\n",
      "\t230: TRAIN loss 0.0507,  acc 0.9954 || VAL loss 0.5479, acc 0.9272\n",
      "\t240: TRAIN loss 0.0513,  acc 0.9954 || VAL loss 0.5772, acc 0.9272\n",
      "\t250: TRAIN loss 0.0513,  acc 0.9954 || VAL loss 0.5746, acc 0.9272\n",
      "\t260: TRAIN loss 0.0508,  acc 0.9956 || VAL loss 0.5575, acc 0.9303\n",
      "\t270: TRAIN loss 0.0876,  acc 0.9881 || VAL loss 0.6119, acc 0.9145\n",
      "\t280: TRAIN loss 0.0472,  acc 0.9958 || VAL loss 0.5563, acc 0.9256\n",
      "\t290: TRAIN loss 0.0476,  acc 0.9952 || VAL loss 0.5523, acc 0.9287\n",
      "512 128 0.9966349960411718 0.9271575613618369\n",
      "\t0: TRAIN loss 6.6530,  acc 0.3569 || VAL loss 5.6807, acc 0.4307\n",
      "\t10: TRAIN loss 0.6079,  acc 0.8508 || VAL loss 0.7742, acc 0.8345\n",
      "\t20: TRAIN loss 0.2141,  acc 0.9470 || VAL loss 0.5880, acc 0.8551\n",
      "\t30: TRAIN loss 0.1004,  acc 0.9842 || VAL loss 0.5080, acc 0.8963\n",
      "\t40: TRAIN loss 0.0782,  acc 0.9907 || VAL loss 0.4713, acc 0.9177\n",
      "\t50: TRAIN loss 0.0703,  acc 0.9931 || VAL loss 0.5296, acc 0.9074\n",
      "\t60: TRAIN loss 0.0579,  acc 0.9945 || VAL loss 0.5307, acc 0.9184\n",
      "\t70: TRAIN loss 0.1939,  acc 0.9685 || VAL loss 0.6145, acc 0.9018\n",
      "\t80: TRAIN loss 0.0633,  acc 0.9951 || VAL loss 0.5282, acc 0.9256\n",
      "\t90: TRAIN loss 0.0636,  acc 0.9943 || VAL loss 0.5438, acc 0.9272\n",
      "\t100: TRAIN loss 0.0596,  acc 0.9951 || VAL loss 0.5389, acc 0.9319\n",
      "\t110: TRAIN loss 0.0613,  acc 0.9943 || VAL loss 0.5591, acc 0.9208\n",
      "\t120: TRAIN loss 0.0603,  acc 0.9954 || VAL loss 0.5076, acc 0.9224\n",
      "\t130: TRAIN loss 0.0599,  acc 0.9945 || VAL loss 0.5294, acc 0.9264\n",
      "\t140: TRAIN loss 0.0588,  acc 0.9951 || VAL loss 0.5563, acc 0.9208\n",
      "\t150: TRAIN loss 0.0593,  acc 0.9949 || VAL loss 0.5673, acc 0.9279\n",
      "\t160: TRAIN loss 0.0959,  acc 0.9850 || VAL loss 0.7314, acc 0.8899\n",
      "\t170: TRAIN loss 0.0689,  acc 0.9919 || VAL loss 0.5700, acc 0.9232\n",
      "\t180: TRAIN loss 0.0508,  acc 0.9952 || VAL loss 0.5491, acc 0.9303\n",
      "\t190: TRAIN loss 0.0505,  acc 0.9960 || VAL loss 0.5665, acc 0.9303\n",
      "\t200: TRAIN loss 0.0505,  acc 0.9958 || VAL loss 0.5711, acc 0.9335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t210: TRAIN loss 0.0511,  acc 0.9954 || VAL loss 0.5631, acc 0.9335\n",
      "\t220: TRAIN loss 0.0521,  acc 0.9954 || VAL loss 0.5820, acc 0.9327\n",
      "\t230: TRAIN loss 0.0524,  acc 0.9949 || VAL loss 0.5833, acc 0.9295\n",
      "\t240: TRAIN loss 0.0518,  acc 0.9952 || VAL loss 0.6204, acc 0.9216\n",
      "\t250: TRAIN loss 0.0507,  acc 0.9958 || VAL loss 0.5847, acc 0.9248\n",
      "\t260: TRAIN loss 0.0500,  acc 0.9958 || VAL loss 0.5874, acc 0.9232\n",
      "\t270: TRAIN loss 0.0498,  acc 0.9962 || VAL loss 0.6061, acc 0.9248\n",
      "\t280: TRAIN loss 0.0504,  acc 0.9954 || VAL loss 0.5992, acc 0.9232\n",
      "\t290: TRAIN loss 0.0501,  acc 0.9960 || VAL loss 0.6126, acc 0.9232\n",
      "512 256 0.9962391132224862 0.9247822644497229\n",
      "\t0: TRAIN loss 7.3812,  acc 0.3385 || VAL loss 5.5105, acc 0.3880\n",
      "\t10: TRAIN loss 1.1158,  acc 0.8563 || VAL loss 1.4142, acc 0.8005\n",
      "\t20: TRAIN loss 1.0553,  acc 0.8941 || VAL loss 1.3648, acc 0.8211\n",
      "\t30: TRAIN loss 0.8654,  acc 0.9305 || VAL loss 1.3045, acc 0.8496\n",
      "\t40: TRAIN loss 0.8225,  acc 0.9452 || VAL loss 1.2558, acc 0.8662\n",
      "\t50: TRAIN loss 0.8103,  acc 0.9479 || VAL loss 1.2797, acc 0.8662\n",
      "\t60: TRAIN loss 0.8367,  acc 0.9359 || VAL loss 1.2927, acc 0.8662\n",
      "\t70: TRAIN loss 0.1696,  acc 0.9798 || VAL loss 0.5941, acc 0.9121\n",
      "\t80: TRAIN loss 0.1076,  acc 0.9919 || VAL loss 0.5391, acc 0.9248\n",
      "\t90: TRAIN loss 0.1046,  acc 0.9921 || VAL loss 0.5708, acc 0.9248\n",
      "\t100: TRAIN loss 0.1072,  acc 0.9915 || VAL loss 0.5938, acc 0.9145\n",
      "\t110: TRAIN loss 0.1040,  acc 0.9925 || VAL loss 0.5770, acc 0.9208\n",
      "\t120: TRAIN loss 0.1028,  acc 0.9921 || VAL loss 0.5785, acc 0.9232\n",
      "\t130: TRAIN loss 0.1030,  acc 0.9913 || VAL loss 0.5953, acc 0.9248\n",
      "\t140: TRAIN loss 0.1035,  acc 0.9921 || VAL loss 0.5892, acc 0.9240\n",
      "\t150: TRAIN loss 0.2190,  acc 0.9749 || VAL loss 0.6903, acc 0.9042\n",
      "\t160: TRAIN loss 0.0459,  acc 0.9956 || VAL loss 0.6272, acc 0.9169\n",
      "\t170: TRAIN loss 0.0454,  acc 0.9958 || VAL loss 0.6289, acc 0.9200\n",
      "\t180: TRAIN loss 0.0450,  acc 0.9954 || VAL loss 0.6378, acc 0.9200\n",
      "\t190: TRAIN loss 0.0444,  acc 0.9958 || VAL loss 0.6329, acc 0.9169\n",
      "\t200: TRAIN loss 0.0453,  acc 0.9952 || VAL loss 0.6453, acc 0.9177\n",
      "\t210: TRAIN loss 0.0448,  acc 0.9954 || VAL loss 0.6427, acc 0.9169\n",
      "\t220: TRAIN loss 0.0450,  acc 0.9956 || VAL loss 0.6071, acc 0.9192\n",
      "\t230: TRAIN loss 0.0439,  acc 0.9960 || VAL loss 0.6117, acc 0.9184\n",
      "\t240: TRAIN loss 0.0444,  acc 0.9958 || VAL loss 0.6095, acc 0.9216\n",
      "\t250: TRAIN loss 0.0441,  acc 0.9962 || VAL loss 0.6337, acc 0.9184\n",
      "\t260: TRAIN loss 0.0440,  acc 0.9960 || VAL loss 0.6350, acc 0.9200\n",
      "\t270: TRAIN loss 0.0436,  acc 0.9960 || VAL loss 0.6365, acc 0.9224\n",
      "\t280: TRAIN loss 0.0443,  acc 0.9952 || VAL loss 0.6372, acc 0.9192\n",
      "\t290: TRAIN loss 0.0441,  acc 0.9956 || VAL loss 0.6455, acc 0.9256\n",
      "512 512 0.9962391132224862 0.9239904988123515\n",
      "\t0: TRAIN loss 8.4977,  acc 0.3169 || VAL loss 6.3630, acc 0.3808\n",
      "\t10: TRAIN loss 3.4180,  acc 0.7340 || VAL loss 3.0665, acc 0.6508\n",
      "\t20: TRAIN loss 0.2926,  acc 0.9440 || VAL loss 0.6786, acc 0.8797\n",
      "\t30: TRAIN loss 0.1041,  acc 0.9889 || VAL loss 0.5660, acc 0.9066\n",
      "\t40: TRAIN loss 0.0923,  acc 0.9919 || VAL loss 0.5614, acc 0.9177\n",
      "\t50: TRAIN loss 0.1708,  acc 0.9749 || VAL loss 0.7314, acc 0.8979\n",
      "\t60: TRAIN loss 0.1836,  acc 0.9780 || VAL loss 0.6299, acc 0.9018\n",
      "\t70: TRAIN loss 0.1717,  acc 0.9879 || VAL loss 0.6239, acc 0.9248\n",
      "\t80: TRAIN loss 0.1702,  acc 0.9881 || VAL loss 0.6320, acc 0.9216\n",
      "\t90: TRAIN loss 0.1701,  acc 0.9881 || VAL loss 0.6369, acc 0.9192\n",
      "\t100: TRAIN loss 0.1716,  acc 0.9877 || VAL loss 0.6459, acc 0.9200\n",
      "\t110: TRAIN loss 0.1710,  acc 0.9873 || VAL loss 0.6614, acc 0.9161\n",
      "\t120: TRAIN loss 0.0632,  acc 0.9947 || VAL loss 0.5841, acc 0.9232\n",
      "\t130: TRAIN loss 0.0606,  acc 0.9947 || VAL loss 0.6068, acc 0.9145\n",
      "\t140: TRAIN loss 0.0608,  acc 0.9941 || VAL loss 0.5977, acc 0.9184\n",
      "\t150: TRAIN loss 0.1419,  acc 0.9871 || VAL loss 0.6111, acc 0.9177\n",
      "\t160: TRAIN loss 0.1242,  acc 0.9905 || VAL loss 0.6054, acc 0.9272\n",
      "\t170: TRAIN loss 0.1236,  acc 0.9913 || VAL loss 0.6100, acc 0.9287\n",
      "\t180: TRAIN loss 0.1235,  acc 0.9913 || VAL loss 0.6111, acc 0.9295\n",
      "\t190: TRAIN loss 0.1237,  acc 0.9909 || VAL loss 0.6173, acc 0.9287\n",
      "\t200: TRAIN loss 0.1249,  acc 0.9911 || VAL loss 0.6187, acc 0.9327\n",
      "\t210: TRAIN loss 0.1245,  acc 0.9907 || VAL loss 0.6164, acc 0.9287\n",
      "\t220: TRAIN loss 0.0621,  acc 0.9939 || VAL loss 0.5954, acc 0.9272\n",
      "\t230: TRAIN loss 0.0499,  acc 0.9958 || VAL loss 0.5678, acc 0.9343\n",
      "\t240: TRAIN loss 0.0503,  acc 0.9952 || VAL loss 0.5714, acc 0.9359\n",
      "\t250: TRAIN loss 0.0499,  acc 0.9956 || VAL loss 0.5777, acc 0.9351\n",
      "\t260: TRAIN loss 0.0498,  acc 0.9960 || VAL loss 0.5831, acc 0.9335\n",
      "\t270: TRAIN loss 0.0505,  acc 0.9958 || VAL loss 0.5894, acc 0.9375\n",
      "\t280: TRAIN loss 0.0503,  acc 0.9956 || VAL loss 0.5874, acc 0.9343\n",
      "\t290: TRAIN loss 0.0497,  acc 0.9952 || VAL loss 0.5830, acc 0.9351\n",
      "512 1024 0.9827790973871734 0.894695170229612\n",
      "\t0: TRAIN loss 2.9521,  acc 0.1291 || VAL loss 2.2910, acc 0.1291\n",
      "\t10: TRAIN loss 2.2217,  acc 0.1429 || VAL loss 2.2655, acc 0.1354\n",
      "\t20: TRAIN loss 2.1724,  acc 0.1625 || VAL loss 2.1792, acc 0.1623\n",
      "\t30: TRAIN loss 2.1017,  acc 0.1781 || VAL loss 2.1037, acc 0.1797\n",
      "\t40: TRAIN loss 1.8927,  acc 0.2407 || VAL loss 1.9536, acc 0.2241\n",
      "\t50: TRAIN loss 1.7870,  acc 0.2668 || VAL loss 1.8799, acc 0.2542\n",
      "\t60: TRAIN loss 1.6233,  acc 0.3533 || VAL loss 1.7472, acc 0.3080\n",
      "\t70: TRAIN loss 0.7926,  acc 0.6936 || VAL loss 1.0453, acc 0.6556\n",
      "\t80: TRAIN loss 0.4471,  acc 0.8525 || VAL loss 0.7221, acc 0.8013\n",
      "\t90: TRAIN loss 0.3358,  acc 0.8886 || VAL loss 0.6512, acc 0.8187\n",
      "\t100: TRAIN loss 0.2058,  acc 0.9297 || VAL loss 0.7273, acc 0.8488\n",
      "\t110: TRAIN loss 0.1606,  acc 0.9450 || VAL loss 0.6480, acc 0.8717\n",
      "\t120: TRAIN loss 0.1504,  acc 0.9555 || VAL loss 0.7118, acc 0.8702\n",
      "\t130: TRAIN loss 0.1624,  acc 0.9539 || VAL loss 0.7140, acc 0.8646\n",
      "\t140: TRAIN loss 0.1035,  acc 0.9705 || VAL loss 0.6761, acc 0.8939\n",
      "\t150: TRAIN loss 0.1280,  acc 0.9662 || VAL loss 0.6887, acc 0.8868\n",
      "\t160: TRAIN loss 0.1083,  acc 0.9705 || VAL loss 0.7239, acc 0.8828\n",
      "\t170: TRAIN loss 0.0846,  acc 0.9745 || VAL loss 0.6897, acc 0.8947\n",
      "\t180: TRAIN loss 0.1209,  acc 0.9606 || VAL loss 0.7176, acc 0.8702\n",
      "\t190: TRAIN loss 0.0782,  acc 0.9760 || VAL loss 0.6671, acc 0.8892\n",
      "\t200: TRAIN loss 0.0687,  acc 0.9792 || VAL loss 0.7135, acc 0.8915\n",
      "\t210: TRAIN loss 0.0822,  acc 0.9768 || VAL loss 0.7079, acc 0.8852\n",
      "\t220: TRAIN loss 0.0723,  acc 0.9751 || VAL loss 0.7129, acc 0.8947\n",
      "\t230: TRAIN loss 0.0706,  acc 0.9794 || VAL loss 0.7987, acc 0.8725\n",
      "\t240: TRAIN loss 0.0659,  acc 0.9812 || VAL loss 0.6767, acc 0.8931\n",
      "\t250: TRAIN loss 0.0630,  acc 0.9806 || VAL loss 0.7226, acc 0.8939\n",
      "\t260: TRAIN loss 0.1243,  acc 0.9608 || VAL loss 0.8350, acc 0.8733\n",
      "\t270: TRAIN loss 0.0528,  acc 0.9818 || VAL loss 0.7336, acc 0.8939\n",
      "\t280: TRAIN loss 0.0606,  acc 0.9808 || VAL loss 0.7324, acc 0.8899\n",
      "\t290: TRAIN loss 0.0530,  acc 0.9822 || VAL loss 0.7498, acc 0.8892\n",
      "1024 16 0.9825811559778306 0.889944576405384\n",
      "\t0: TRAIN loss 2.9453,  acc 0.2506 || VAL loss 1.9403, acc 0.3444\n",
      "\t10: TRAIN loss 0.9252,  acc 0.7098 || VAL loss 1.0123, acc 0.6857\n",
      "\t20: TRAIN loss 0.4037,  acc 0.8747 || VAL loss 0.6773, acc 0.8250\n",
      "\t30: TRAIN loss 0.2350,  acc 0.9361 || VAL loss 0.6164, acc 0.8432\n",
      "\t40: TRAIN loss 0.1430,  acc 0.9640 || VAL loss 0.6057, acc 0.8773\n",
      "\t50: TRAIN loss 0.1295,  acc 0.9685 || VAL loss 0.5881, acc 0.8844\n",
      "\t60: TRAIN loss 0.0794,  acc 0.9846 || VAL loss 0.5424, acc 0.9050\n",
      "\t70: TRAIN loss 0.1396,  acc 0.9701 || VAL loss 0.6750, acc 0.8820\n",
      "\t80: TRAIN loss 0.0474,  acc 0.9941 || VAL loss 0.5719, acc 0.9050\n",
      "\t90: TRAIN loss 0.0398,  acc 0.9952 || VAL loss 0.6111, acc 0.9042\n",
      "\t100: TRAIN loss 0.0497,  acc 0.9923 || VAL loss 0.5910, acc 0.9050\n",
      "\t110: TRAIN loss 0.0347,  acc 0.9935 || VAL loss 0.6023, acc 0.8994\n",
      "\t120: TRAIN loss 0.0295,  acc 0.9952 || VAL loss 0.6247, acc 0.9050\n",
      "\t130: TRAIN loss 0.0446,  acc 0.9887 || VAL loss 0.6581, acc 0.8971\n",
      "\t140: TRAIN loss 0.1092,  acc 0.9757 || VAL loss 0.7532, acc 0.8884\n",
      "\t150: TRAIN loss 0.0370,  acc 0.9931 || VAL loss 0.6974, acc 0.9050\n",
      "\t160: TRAIN loss 0.0519,  acc 0.9879 || VAL loss 0.6653, acc 0.8979\n",
      "\t170: TRAIN loss 0.0537,  acc 0.9899 || VAL loss 0.7597, acc 0.8987\n",
      "\t180: TRAIN loss 0.0465,  acc 0.9909 || VAL loss 0.7128, acc 0.8923\n",
      "\t190: TRAIN loss 0.0428,  acc 0.9911 || VAL loss 0.7464, acc 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t200: TRAIN loss 0.0244,  acc 0.9962 || VAL loss 0.6309, acc 0.9177\n",
      "\t210: TRAIN loss 0.0237,  acc 0.9958 || VAL loss 0.6223, acc 0.9184\n",
      "\t220: TRAIN loss 0.0246,  acc 0.9960 || VAL loss 0.6475, acc 0.9169\n",
      "\t230: TRAIN loss 0.0378,  acc 0.9907 || VAL loss 0.7485, acc 0.8994\n",
      "\t240: TRAIN loss 0.0295,  acc 0.9949 || VAL loss 0.6849, acc 0.9113\n",
      "\t250: TRAIN loss 0.0254,  acc 0.9956 || VAL loss 0.6764, acc 0.9145\n",
      "\t260: TRAIN loss 0.0204,  acc 0.9966 || VAL loss 0.6802, acc 0.9153\n",
      "\t270: TRAIN loss 0.0217,  acc 0.9960 || VAL loss 0.7020, acc 0.9121\n",
      "\t280: TRAIN loss 0.0204,  acc 0.9968 || VAL loss 0.6794, acc 0.9208\n",
      "\t290: TRAIN loss 0.0195,  acc 0.9960 || VAL loss 0.6879, acc 0.9208\n",
      "1024 32 0.9958432304038005 0.9089469517022961\n",
      "\t0: TRAIN loss 6.2973,  acc 0.3418 || VAL loss 3.9219, acc 0.4561\n",
      "\t10: TRAIN loss 0.4223,  acc 0.8862 || VAL loss 0.7496, acc 0.8337\n",
      "\t20: TRAIN loss 0.2947,  acc 0.9242 || VAL loss 0.6926, acc 0.8551\n",
      "\t30: TRAIN loss 0.2001,  acc 0.9561 || VAL loss 0.5908, acc 0.8804\n",
      "\t40: TRAIN loss 0.1533,  acc 0.9699 || VAL loss 0.6665, acc 0.8836\n",
      "\t50: TRAIN loss 0.0597,  acc 0.9915 || VAL loss 0.5151, acc 0.9129\n",
      "\t60: TRAIN loss 0.0569,  acc 0.9901 || VAL loss 0.5503, acc 0.9082\n",
      "\t70: TRAIN loss 0.0527,  acc 0.9921 || VAL loss 0.5569, acc 0.9082\n",
      "\t80: TRAIN loss 0.0468,  acc 0.9947 || VAL loss 0.5537, acc 0.9082\n",
      "\t90: TRAIN loss 0.1270,  acc 0.9808 || VAL loss 0.6045, acc 0.8955\n",
      "\t100: TRAIN loss 0.0978,  acc 0.9915 || VAL loss 0.5675, acc 0.9129\n",
      "\t110: TRAIN loss 0.0811,  acc 0.9937 || VAL loss 0.5414, acc 0.9208\n",
      "\t120: TRAIN loss 0.0801,  acc 0.9933 || VAL loss 0.5528, acc 0.9177\n",
      "\t130: TRAIN loss 0.0860,  acc 0.9921 || VAL loss 0.6050, acc 0.9161\n",
      "\t140: TRAIN loss 0.0809,  acc 0.9929 || VAL loss 0.5781, acc 0.9208\n",
      "\t150: TRAIN loss 0.1219,  acc 0.9818 || VAL loss 0.6025, acc 0.9097\n",
      "\t160: TRAIN loss 0.0776,  acc 0.9939 || VAL loss 0.5705, acc 0.9224\n",
      "\t170: TRAIN loss 0.0769,  acc 0.9883 || VAL loss 0.7965, acc 0.8892\n",
      "\t180: TRAIN loss 0.0712,  acc 0.9943 || VAL loss 0.6020, acc 0.9113\n",
      "\t190: TRAIN loss 0.0716,  acc 0.9943 || VAL loss 0.5899, acc 0.9200\n",
      "\t200: TRAIN loss 0.0716,  acc 0.9941 || VAL loss 0.5871, acc 0.9200\n",
      "\t210: TRAIN loss 0.0739,  acc 0.9931 || VAL loss 0.6542, acc 0.9153\n",
      "\t220: TRAIN loss 0.0650,  acc 0.9949 || VAL loss 0.5739, acc 0.9224\n",
      "\t230: TRAIN loss 0.0653,  acc 0.9945 || VAL loss 0.5640, acc 0.9208\n",
      "\t240: TRAIN loss 0.0648,  acc 0.9943 || VAL loss 0.5714, acc 0.9216\n",
      "\t250: TRAIN loss 0.0637,  acc 0.9941 || VAL loss 0.5757, acc 0.9161\n",
      "\t260: TRAIN loss 0.0648,  acc 0.9941 || VAL loss 0.5697, acc 0.9200\n",
      "\t270: TRAIN loss 0.1284,  acc 0.9747 || VAL loss 0.7983, acc 0.8789\n",
      "\t280: TRAIN loss 0.0391,  acc 0.9960 || VAL loss 0.5647, acc 0.9240\n",
      "\t290: TRAIN loss 0.0383,  acc 0.9964 || VAL loss 0.5699, acc 0.9232\n",
      "1024 64 0.9970308788598575 0.9231987331749802\n",
      "\t0: TRAIN loss 6.8576,  acc 0.3286 || VAL loss 3.4156, acc 0.4735\n",
      "\t10: TRAIN loss 0.4759,  acc 0.8897 || VAL loss 0.7382, acc 0.8377\n",
      "\t20: TRAIN loss 0.4227,  acc 0.9208 || VAL loss 0.6960, acc 0.8583\n",
      "\t30: TRAIN loss 0.1176,  acc 0.9737 || VAL loss 0.4911, acc 0.8963\n",
      "\t40: TRAIN loss 0.0748,  acc 0.9891 || VAL loss 0.4536, acc 0.9105\n",
      "\t50: TRAIN loss 0.2003,  acc 0.9586 || VAL loss 0.5921, acc 0.8979\n",
      "\t60: TRAIN loss 0.0819,  acc 0.9897 || VAL loss 0.5879, acc 0.9082\n",
      "\t70: TRAIN loss 0.0550,  acc 0.9949 || VAL loss 0.5379, acc 0.9177\n",
      "\t80: TRAIN loss 0.0516,  acc 0.9956 || VAL loss 0.5295, acc 0.9216\n",
      "\t90: TRAIN loss 0.0633,  acc 0.9921 || VAL loss 0.5945, acc 0.9066\n",
      "\t100: TRAIN loss 0.0638,  acc 0.9925 || VAL loss 0.4713, acc 0.9224\n",
      "\t110: TRAIN loss 0.0386,  acc 0.9954 || VAL loss 0.4693, acc 0.9248\n",
      "\t120: TRAIN loss 0.0382,  acc 0.9956 || VAL loss 0.4879, acc 0.9224\n",
      "\t130: TRAIN loss 0.0365,  acc 0.9962 || VAL loss 0.4596, acc 0.9311\n",
      "\t140: TRAIN loss 0.0365,  acc 0.9964 || VAL loss 0.4668, acc 0.9279\n",
      "\t150: TRAIN loss 0.0372,  acc 0.9960 || VAL loss 0.5129, acc 0.9264\n",
      "\t160: TRAIN loss 0.0607,  acc 0.9909 || VAL loss 0.6057, acc 0.9074\n",
      "\t170: TRAIN loss 0.0547,  acc 0.9952 || VAL loss 0.5485, acc 0.9256\n",
      "\t180: TRAIN loss 0.0551,  acc 0.9945 || VAL loss 0.5531, acc 0.9232\n",
      "\t190: TRAIN loss 0.0556,  acc 0.9949 || VAL loss 0.5627, acc 0.9208\n",
      "\t200: TRAIN loss 0.0542,  acc 0.9956 || VAL loss 0.5555, acc 0.9248\n",
      "\t210: TRAIN loss 0.0537,  acc 0.9954 || VAL loss 0.5742, acc 0.9208\n",
      "\t220: TRAIN loss 0.0544,  acc 0.9947 || VAL loss 0.5593, acc 0.9248\n",
      "\t230: TRAIN loss 0.0548,  acc 0.9947 || VAL loss 0.5787, acc 0.9224\n",
      "\t240: TRAIN loss 0.0417,  acc 0.9958 || VAL loss 0.5068, acc 0.9232\n",
      "\t250: TRAIN loss 0.0380,  acc 0.9964 || VAL loss 0.5242, acc 0.9216\n",
      "\t260: TRAIN loss 0.0375,  acc 0.9960 || VAL loss 0.5304, acc 0.9264\n",
      "\t270: TRAIN loss 0.0379,  acc 0.9960 || VAL loss 0.5220, acc 0.9264\n",
      "\t280: TRAIN loss 0.0377,  acc 0.9964 || VAL loss 0.5275, acc 0.9279\n",
      "\t290: TRAIN loss 0.0376,  acc 0.9964 || VAL loss 0.5419, acc 0.9303\n",
      "1024 128 0.9968329374505146 0.9279493269992082\n",
      "\t0: TRAIN loss 7.9297,  acc 0.3298 || VAL loss 6.6438, acc 0.4086\n",
      "\t10: TRAIN loss 2.4360,  acc 0.7922 || VAL loss 2.7539, acc 0.7031\n",
      "\t20: TRAIN loss 0.3097,  acc 0.9325 || VAL loss 0.5481, acc 0.8852\n",
      "\t30: TRAIN loss 0.1945,  acc 0.9699 || VAL loss 0.5130, acc 0.9002\n",
      "\t40: TRAIN loss 0.3906,  acc 0.9339 || VAL loss 0.7293, acc 0.8654\n",
      "\t50: TRAIN loss 0.1493,  acc 0.9739 || VAL loss 0.5339, acc 0.9129\n",
      "\t60: TRAIN loss 0.0722,  acc 0.9939 || VAL loss 0.5317, acc 0.9240\n",
      "\t70: TRAIN loss 0.0675,  acc 0.9941 || VAL loss 0.5363, acc 0.9264\n",
      "\t80: TRAIN loss 0.0762,  acc 0.9913 || VAL loss 0.5581, acc 0.9192\n",
      "\t90: TRAIN loss 0.0591,  acc 0.9935 || VAL loss 0.5081, acc 0.9367\n",
      "\t100: TRAIN loss 0.0526,  acc 0.9954 || VAL loss 0.5300, acc 0.9319\n",
      "\t110: TRAIN loss 0.0532,  acc 0.9952 || VAL loss 0.5276, acc 0.9287\n",
      "\t120: TRAIN loss 0.1106,  acc 0.9871 || VAL loss 0.8853, acc 0.8654\n",
      "\t130: TRAIN loss 0.0557,  acc 0.9933 || VAL loss 0.5534, acc 0.9224\n",
      "\t140: TRAIN loss 0.0415,  acc 0.9964 || VAL loss 0.5600, acc 0.9295\n",
      "\t150: TRAIN loss 0.0416,  acc 0.9960 || VAL loss 0.5482, acc 0.9327\n",
      "\t160: TRAIN loss 0.0427,  acc 0.9954 || VAL loss 0.5555, acc 0.9295\n",
      "\t170: TRAIN loss 0.0417,  acc 0.9956 || VAL loss 0.5664, acc 0.9295\n",
      "\t180: TRAIN loss 0.0417,  acc 0.9958 || VAL loss 0.5570, acc 0.9303\n",
      "\t190: TRAIN loss 0.0904,  acc 0.9877 || VAL loss 0.5490, acc 0.9200\n",
      "\t200: TRAIN loss 0.0419,  acc 0.9960 || VAL loss 0.4967, acc 0.9351\n",
      "\t210: TRAIN loss 0.0414,  acc 0.9960 || VAL loss 0.5029, acc 0.9351\n",
      "\t220: TRAIN loss 0.0411,  acc 0.9960 || VAL loss 0.5041, acc 0.9375\n",
      "\t230: TRAIN loss 0.0408,  acc 0.9958 || VAL loss 0.5079, acc 0.9382\n",
      "\t240: TRAIN loss 0.0412,  acc 0.9962 || VAL loss 0.5180, acc 0.9367\n",
      "\t250: TRAIN loss 0.0413,  acc 0.9960 || VAL loss 0.5125, acc 0.9390\n",
      "\t260: TRAIN loss 0.0423,  acc 0.9954 || VAL loss 0.5052, acc 0.9398\n",
      "\t270: TRAIN loss 0.0418,  acc 0.9958 || VAL loss 0.5217, acc 0.9343\n",
      "\t280: TRAIN loss 0.0407,  acc 0.9962 || VAL loss 0.5231, acc 0.9335\n",
      "\t290: TRAIN loss 0.0406,  acc 0.9962 || VAL loss 0.5345, acc 0.9319\n",
      "1024 256 0.9966349960411718 0.9334916864608076\n",
      "\t0: TRAIN loss 9.0883,  acc 0.3147 || VAL loss 7.8745, acc 0.4244\n",
      "\t10: TRAIN loss 2.9147,  acc 0.7767 || VAL loss 3.1006, acc 0.7387\n",
      "\t20: TRAIN loss 2.7680,  acc 0.8224 || VAL loss 2.9635, acc 0.7815\n",
      "\t30: TRAIN loss 0.2170,  acc 0.9477 || VAL loss 0.5740, acc 0.8931\n",
      "\t40: TRAIN loss 0.0893,  acc 0.9856 || VAL loss 0.5337, acc 0.9145\n",
      "\t50: TRAIN loss 0.0557,  acc 0.9947 || VAL loss 0.5041, acc 0.9192\n",
      "\t60: TRAIN loss 0.0637,  acc 0.9921 || VAL loss 0.5379, acc 0.9192\n",
      "\t70: TRAIN loss 0.0561,  acc 0.9949 || VAL loss 0.5201, acc 0.9192\n",
      "\t80: TRAIN loss 0.1090,  acc 0.9774 || VAL loss 0.7604, acc 0.8725\n",
      "\t90: TRAIN loss 0.0967,  acc 0.9856 || VAL loss 0.6019, acc 0.9153\n",
      "\t100: TRAIN loss 0.0589,  acc 0.9943 || VAL loss 0.5141, acc 0.9295\n",
      "\t110: TRAIN loss 0.0569,  acc 0.9954 || VAL loss 0.5234, acc 0.9272\n",
      "\t120: TRAIN loss 0.0576,  acc 0.9947 || VAL loss 0.5526, acc 0.9240\n",
      "\t130: TRAIN loss 0.0579,  acc 0.9951 || VAL loss 0.5208, acc 0.9264\n",
      "\t140: TRAIN loss 0.0591,  acc 0.9941 || VAL loss 0.5282, acc 0.9279\n",
      "\t150: TRAIN loss 0.0579,  acc 0.9943 || VAL loss 0.5372, acc 0.9279\n",
      "\t160: TRAIN loss 0.0572,  acc 0.9947 || VAL loss 0.5353, acc 0.9279\n",
      "\t170: TRAIN loss 0.0569,  acc 0.9949 || VAL loss 0.5314, acc 0.9327\n",
      "\t180: TRAIN loss 0.0574,  acc 0.9951 || VAL loss 0.5545, acc 0.9303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t190: TRAIN loss 0.1358,  acc 0.9848 || VAL loss 0.5936, acc 0.9153\n",
      "\t200: TRAIN loss 0.0698,  acc 0.9947 || VAL loss 0.5427, acc 0.9311\n",
      "\t210: TRAIN loss 0.0696,  acc 0.9941 || VAL loss 0.5569, acc 0.9335\n",
      "\t220: TRAIN loss 0.0695,  acc 0.9947 || VAL loss 0.5581, acc 0.9311\n",
      "\t230: TRAIN loss 0.1386,  acc 0.9869 || VAL loss 0.6688, acc 0.9145\n",
      "\t240: TRAIN loss 0.1237,  acc 0.9915 || VAL loss 0.6245, acc 0.9264\n",
      "\t250: TRAIN loss 0.1236,  acc 0.9907 || VAL loss 0.6303, acc 0.9256\n",
      "\t260: TRAIN loss 0.1235,  acc 0.9913 || VAL loss 0.6336, acc 0.9272\n",
      "\t270: TRAIN loss 0.1242,  acc 0.9905 || VAL loss 0.6283, acc 0.9256\n",
      "\t280: TRAIN loss 0.1235,  acc 0.9907 || VAL loss 0.6339, acc 0.9256\n",
      "\t290: TRAIN loss 0.1243,  acc 0.9850 || VAL loss 0.7558, acc 0.9105\n",
      "1024 512 0.9956452889944576 0.9279493269992082\n",
      "\t0: TRAIN loss 11.2469,  acc 0.2520 || VAL loss 11.4968, acc 0.2581\n",
      "\t10: TRAIN loss 0.5381,  acc 0.9080 || VAL loss 0.8312, acc 0.8464\n",
      "\t20: TRAIN loss 0.2277,  acc 0.9757 || VAL loss 0.6101, acc 0.8994\n",
      "\t30: TRAIN loss 0.1445,  acc 0.9861 || VAL loss 0.6771, acc 0.9066\n",
      "\t40: TRAIN loss 0.1223,  acc 0.9867 || VAL loss 0.6458, acc 0.9058\n",
      "\t50: TRAIN loss 0.1057,  acc 0.9917 || VAL loss 0.6208, acc 0.9200\n",
      "\t60: TRAIN loss 0.1039,  acc 0.9917 || VAL loss 0.6293, acc 0.9200\n",
      "\t70: TRAIN loss 0.1037,  acc 0.9917 || VAL loss 0.6364, acc 0.9224\n",
      "\t80: TRAIN loss 0.3572,  acc 0.9309 || VAL loss 0.6600, acc 0.8884\n",
      "\t90: TRAIN loss 0.1026,  acc 0.9919 || VAL loss 0.5592, acc 0.9264\n",
      "\t100: TRAIN loss 0.0924,  acc 0.9931 || VAL loss 0.5697, acc 0.9287\n",
      "\t110: TRAIN loss 0.0931,  acc 0.9927 || VAL loss 0.5800, acc 0.9256\n",
      "\t120: TRAIN loss 0.0924,  acc 0.9931 || VAL loss 0.5859, acc 0.9248\n",
      "\t130: TRAIN loss 0.0931,  acc 0.9931 || VAL loss 0.6232, acc 0.9200\n",
      "\t140: TRAIN loss 0.2101,  acc 0.9762 || VAL loss 0.7044, acc 0.9082\n",
      "\t150: TRAIN loss 0.0746,  acc 0.9919 || VAL loss 0.6489, acc 0.9272\n",
      "\t160: TRAIN loss 0.0665,  acc 0.9945 || VAL loss 0.6254, acc 0.9272\n",
      "\t170: TRAIN loss 0.0662,  acc 0.9949 || VAL loss 0.6287, acc 0.9279\n",
      "\t180: TRAIN loss 0.0664,  acc 0.9947 || VAL loss 0.6283, acc 0.9232\n",
      "\t190: TRAIN loss 0.0660,  acc 0.9945 || VAL loss 0.6320, acc 0.9295\n",
      "\t200: TRAIN loss 0.0672,  acc 0.9945 || VAL loss 0.6395, acc 0.9272\n",
      "\t210: TRAIN loss 0.0732,  acc 0.9933 || VAL loss 0.7437, acc 0.9082\n",
      "\t220: TRAIN loss 0.0635,  acc 0.9945 || VAL loss 0.6097, acc 0.9272\n",
      "\t230: TRAIN loss 0.0626,  acc 0.9951 || VAL loss 0.6229, acc 0.9264\n",
      "\t240: TRAIN loss 0.0626,  acc 0.9951 || VAL loss 0.6186, acc 0.9272\n",
      "\t250: TRAIN loss 0.0627,  acc 0.9951 || VAL loss 0.6263, acc 0.9287\n",
      "\t260: TRAIN loss 0.0628,  acc 0.9949 || VAL loss 0.6284, acc 0.9279\n",
      "\t270: TRAIN loss 0.1122,  acc 0.9850 || VAL loss 0.7451, acc 0.9018\n",
      "\t280: TRAIN loss 0.0659,  acc 0.9945 || VAL loss 0.6204, acc 0.9295\n",
      "\t290: TRAIN loss 0.0655,  acc 0.9947 || VAL loss 0.6156, acc 0.9303\n",
      "1024 1024 0.9954473475851148 0.9311163895486936\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for n_layer1 in [16,32,64,128,256,2*256,4*256]:\n",
    "    for n_layer2 in [16,32,64,128,256,2*256,4*256]:\n",
    "        # Build the Estimator\n",
    "        model=build_model(n_layer1,n_layer2)\n",
    "        model.fit(features_train,labels_train,validation_data=(features_val,labels_val),\n",
    "                  epochs=nepochs,batch_size=100,\n",
    "                  verbose=0,callbacks=[ReportCallback(10)])\n",
    "        Y_pred=np.argmax(model.predict(features_train),axis=1)\n",
    "        acc_train=np.mean(Y_pred==labels_train)\n",
    "        Y_pred=np.argmax(model.predict(features_val),axis=1)\n",
    "        acc_val=np.mean(Y_pred==labels_val)\n",
    "        print(n_layer1,n_layer2,acc_train,acc_val)\n",
    "        results.append((n_layer1,n_layer2,acc_train,acc_val))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T13:01:10.748990Z",
     "start_time": "2019-01-14T13:01:10.717731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer1</th>\n",
       "      <th>layer2</th>\n",
       "      <th>train</th>\n",
       "      <th>valuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.884600</td>\n",
       "      <td>0.762470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>0.923199</td>\n",
       "      <td>0.806017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>0.967538</td>\n",
       "      <td>0.813143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>0.985352</td>\n",
       "      <td>0.836105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>0.998416</td>\n",
       "      <td>0.857482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer1  layer2     train  valuation\n",
       "0      16      16  0.884600   0.762470\n",
       "1      16      32  0.923199   0.806017\n",
       "2      16      64  0.967538   0.813143\n",
       "3      16     128  0.985352   0.836105\n",
       "4      16     256  0.998416   0.857482"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame(results,columns=[\"layer1\",\"layer2\",\"train\",\"valuation\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T13:01:25.296007Z",
     "start_time": "2019-01-14T13:01:25.264745Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-fa502d19aa37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/DNN_layer_accuracy.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data_dir' is not defined"
     ]
    }
   ],
   "source": [
    "data.to_csv(data_dir+\"/DNN_layer_accuracy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T13:01:34.193670Z",
     "start_time": "2019-01-14T13:01:34.178057Z"
    }
   },
   "outputs": [],
   "source": [
    "val_error=data[[\"layer1\",\"layer2\",\"valuation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T13:01:35.353038Z",
     "start_time": "2019-01-14T13:01:35.321798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer1</th>\n",
       "      <th>layer2</th>\n",
       "      <th>valuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.762470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>0.806017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>0.813143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>0.836105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>0.857482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer1  layer2  valuation\n",
       "0      16      16   0.762470\n",
       "1      16      32   0.806017\n",
       "2      16      64   0.813143\n",
       "3      16     128   0.836105\n",
       "4      16     256   0.857482"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T13:01:41.118346Z",
     "start_time": "2019-01-14T13:01:41.102734Z"
    }
   },
   "outputs": [],
   "source": [
    "pivot=val_error.pivot('layer1', 'layer2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T13:01:41.801146Z",
     "start_time": "2019-01-14T13:01:41.769908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"7\" halign=\"left\">valuation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer2</th>\n",
       "      <th>16</th>\n",
       "      <th>32</th>\n",
       "      <th>64</th>\n",
       "      <th>128</th>\n",
       "      <th>256</th>\n",
       "      <th>512</th>\n",
       "      <th>1024</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.762470</td>\n",
       "      <td>0.806017</td>\n",
       "      <td>0.813143</td>\n",
       "      <td>0.836105</td>\n",
       "      <td>0.857482</td>\n",
       "      <td>0.842439</td>\n",
       "      <td>0.878068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.821061</td>\n",
       "      <td>0.843230</td>\n",
       "      <td>0.851940</td>\n",
       "      <td>0.833729</td>\n",
       "      <td>0.878860</td>\n",
       "      <td>0.901821</td>\n",
       "      <td>0.900238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.843230</td>\n",
       "      <td>0.852732</td>\n",
       "      <td>0.878860</td>\n",
       "      <td>0.889153</td>\n",
       "      <td>0.910530</td>\n",
       "      <td>0.906572</td>\n",
       "      <td>0.901821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.856690</td>\n",
       "      <td>0.897070</td>\n",
       "      <td>0.888361</td>\n",
       "      <td>0.898654</td>\n",
       "      <td>0.915281</td>\n",
       "      <td>0.905780</td>\n",
       "      <td>0.911322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.893112</td>\n",
       "      <td>0.904196</td>\n",
       "      <td>0.908155</td>\n",
       "      <td>0.913698</td>\n",
       "      <td>0.919240</td>\n",
       "      <td>0.916865</td>\n",
       "      <td>0.926366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.898654</td>\n",
       "      <td>0.908155</td>\n",
       "      <td>0.918448</td>\n",
       "      <td>0.927158</td>\n",
       "      <td>0.924782</td>\n",
       "      <td>0.923990</td>\n",
       "      <td>0.894695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>0.889945</td>\n",
       "      <td>0.908947</td>\n",
       "      <td>0.923199</td>\n",
       "      <td>0.927949</td>\n",
       "      <td>0.933492</td>\n",
       "      <td>0.927949</td>\n",
       "      <td>0.931116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       valuation                                                            \n",
       "layer2      16        32        64        128       256       512       1024\n",
       "layer1                                                                      \n",
       "16      0.762470  0.806017  0.813143  0.836105  0.857482  0.842439  0.878068\n",
       "32      0.821061  0.843230  0.851940  0.833729  0.878860  0.901821  0.900238\n",
       "64      0.843230  0.852732  0.878860  0.889153  0.910530  0.906572  0.901821\n",
       "128     0.856690  0.897070  0.888361  0.898654  0.915281  0.905780  0.911322\n",
       "256     0.893112  0.904196  0.908155  0.913698  0.919240  0.916865  0.926366\n",
       "512     0.898654  0.908155  0.918448  0.927158  0.924782  0.923990  0.894695\n",
       "1024    0.889945  0.908947  0.923199  0.927949  0.933492  0.927949  0.931116"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, the larger the size of the two layers, the better the **generalization** error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T13:01:59.270157Z",
     "start_time": "2019-01-14T13:01:59.254542Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import colors, ticker, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T13:02:00.287435Z",
     "start_time": "2019-01-14T13:02:00.271819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7,) (7,) (7, 7)\n"
     ]
    }
   ],
   "source": [
    "X=pivot.columns.levels[1].values\n",
    "Y=pivot.index.values\n",
    "Z=val_error[\"valuation\"].values.reshape(len(X),-1)\n",
    "print(X.shape,Y.shape,Z.shape)\n",
    "Xi,Yi = np.meshgrid(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T13:02:02.519641Z",
     "start_time": "2019-01-14T13:02:01.801067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_title(\"Training Error as function of layer size\")\n",
    "ax.set_xlabel(\"layer1\")\n",
    "ax.set_ylabel(\"layer1\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "cs=plt.contourf(Yi, Xi, 1-Z,locator=ticker.LogLocator(base=1.5,numdecs=10),  cmap=plt.cm.jet)\n",
    "cbar = fig.colorbar(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T10:05:24.335299Z",
     "start_time": "2019-01-15T10:05:24.319653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024.0, 256.0, 0.9334916864608076)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_idx=val_error[\"valuation\"].idxmax()\n",
    "best=val_error.iloc[best_idx]\n",
    "best_hidden1,best_hidden2,err=best\n",
    "best_hidden1,best_hidden2,err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems we need a large layer 1, layer 2 can be a bit smaller (error has less slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is **very large**, it has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T10:27:29.669776Z",
     "start_time": "2019-01-15T10:27:29.654199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters in layer1 198,656\n",
      "Parameters in layer2 262,400\n",
      "Parameters in output layer  2,570\n",
      "Total Parameters 463,626\n"
     ]
    }
   ],
   "source": [
    "layer1_params=best_hidden1*(193+1)\n",
    "layer2_params=best_hidden2*(best_hidden1+1)\n",
    "output_params=  num_classes*(best_hidden2+1)\n",
    "total_params=layer1_params+layer2_params+output_params\n",
    "print(f\"Parameters in layer1 {layer1_params:6,.0f}\")\n",
    "print(f\"Parameters in layer2 {layer2_params:6,.0f}\",)\n",
    "print(f\"Parameters in output layer {output_params:6,.0f}\")\n",
    "print(f\"Total Parameters {total_params:6,.0f}\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A 3 layer network does no better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T10:28:59.001249Z",
     "start_time": "2019-01-15T10:28:58.985634Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_3layer_model(hidden1,hidden2,hidden3):\n",
    "    model=keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(193,)),\n",
    "        keras.layers.Dense(hidden1,activation=\"relu\"),\n",
    "        keras.layers.Dense(hidden2,activation=\"relu\"),\n",
    "        keras.layers.Dense(hidden3,activation=\"relu\"),\n",
    "        keras.layers.Dense(num_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    optimizer=keras.optimizers.Adam(lr=0.001,decay=1e-4)\n",
    "    model.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T10:28:59.871303Z",
     "start_time": "2019-01-15T10:28:59.730768Z"
    }
   },
   "outputs": [],
   "source": [
    "hidden1=512\n",
    "hidden2=256\n",
    "hidden3=256\n",
    "model3=build_3layer_model(hidden1,hidden2,hidden3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T10:30:35.026705Z",
     "start_time": "2019-01-15T10:29:02.514663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0: TRAIN loss 5.3737,  acc 0.3468 || VAL loss 3.3855, acc 0.4719\n",
      "\t10: TRAIN loss 0.3714,  acc 0.8994 || VAL loss 0.6325, acc 0.8496\n",
      "\t20: TRAIN loss 0.1595,  acc 0.9610 || VAL loss 0.5138, acc 0.8971\n",
      "\t30: TRAIN loss 0.2952,  acc 0.9337 || VAL loss 0.5994, acc 0.8820\n",
      "\t40: TRAIN loss 0.1366,  acc 0.9774 || VAL loss 0.6178, acc 0.8907\n",
      "\t50: TRAIN loss 0.0839,  acc 0.9919 || VAL loss 0.5795, acc 0.9074\n",
      "\t60: TRAIN loss 0.0781,  acc 0.9937 || VAL loss 0.5595, acc 0.9169\n",
      "\t70: TRAIN loss 0.0776,  acc 0.9935 || VAL loss 0.5846, acc 0.9177\n",
      "\t80: TRAIN loss 0.1160,  acc 0.9808 || VAL loss 0.5904, acc 0.9082\n",
      "\t90: TRAIN loss 0.0637,  acc 0.9949 || VAL loss 0.5899, acc 0.9216\n",
      "\t100: TRAIN loss 0.1085,  acc 0.9808 || VAL loss 0.7089, acc 0.8947\n",
      "\t110: TRAIN loss 0.0560,  acc 0.9949 || VAL loss 0.5624, acc 0.9279\n",
      "\t120: TRAIN loss 0.0556,  acc 0.9949 || VAL loss 0.5782, acc 0.9264\n",
      "\t130: TRAIN loss 0.0550,  acc 0.9951 || VAL loss 0.6050, acc 0.9216\n",
      "\t140: TRAIN loss 0.0546,  acc 0.9954 || VAL loss 0.6137, acc 0.9184\n",
      "\t150: TRAIN loss 0.0664,  acc 0.9901 || VAL loss 0.5907, acc 0.9184\n",
      "\t160: TRAIN loss 0.0581,  acc 0.9943 || VAL loss 0.6128, acc 0.9224\n",
      "\t170: TRAIN loss 0.0549,  acc 0.9952 || VAL loss 0.6073, acc 0.9287\n",
      "\t180: TRAIN loss 0.0539,  acc 0.9954 || VAL loss 0.6048, acc 0.9287\n",
      "\t190: TRAIN loss 0.0538,  acc 0.9951 || VAL loss 0.6279, acc 0.9248\n",
      "\t200: TRAIN loss 0.0536,  acc 0.9951 || VAL loss 0.6206, acc 0.9303\n",
      "\t210: TRAIN loss 0.0537,  acc 0.9954 || VAL loss 0.6235, acc 0.9287\n",
      "\t220: TRAIN loss 0.0583,  acc 0.9909 || VAL loss 0.7244, acc 0.8994\n",
      "\t230: TRAIN loss 0.0440,  acc 0.9960 || VAL loss 0.5898, acc 0.9224\n",
      "\t240: TRAIN loss 0.0441,  acc 0.9954 || VAL loss 0.5995, acc 0.9264\n",
      "\t250: TRAIN loss 0.0436,  acc 0.9960 || VAL loss 0.6031, acc 0.9256\n",
      "\t260: TRAIN loss 0.0438,  acc 0.9962 || VAL loss 0.6122, acc 0.9232\n",
      "\t270: TRAIN loss 0.0458,  acc 0.9954 || VAL loss 0.6399, acc 0.9184\n",
      "\t280: TRAIN loss 0.0468,  acc 0.9952 || VAL loss 0.6136, acc 0.9256\n",
      "\t290: TRAIN loss 0.0619,  acc 0.9931 || VAL loss 0.6236, acc 0.9208\n"
     ]
    }
   ],
   "source": [
    "result3=model3.fit(features_train,labels_train,validation_data=(features_val,labels_val),\n",
    "                  epochs=nepochs,batch_size=100,\n",
    "                  verbose=0,callbacks=[ReportCallback(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T10:30:42.328184Z",
     "start_time": "2019-01-15T10:30:42.212834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9287410926365796"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred=np.argmax(model0.predict(features_val),axis=1)\n",
    "np.mean(Y_pred==labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the best model with  all the data and measure performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T10:32:12.750728Z",
     "start_time": "2019-01-15T10:32:12.735150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024.0, 256.0)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hidden1,best_hidden2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T10:32:52.401018Z",
     "start_time": "2019-01-15T10:32:52.260434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_63 (Flatten)         (None, 193)               0         \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 1024)              198656    \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 463,626\n",
      "Trainable params: 463,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model=build_model(best_hidden1,best_hidden2)\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T10:36:39.839923Z",
     "start_time": "2019-01-15T10:34:01.026382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0: TRAIN loss 9.1110,  acc 0.2993 || VAL loss 8.5492, acc 0.3496\n",
      "\t10: TRAIN loss 0.4708,  acc 0.8925 || VAL loss 0.6291, acc 0.8588\n",
      "\t20: TRAIN loss 0.2354,  acc 0.9515 || VAL loss 0.4884, acc 0.8968\n",
      "\t30: TRAIN loss 0.1137,  acc 0.9846 || VAL loss 0.4144, acc 0.9259\n",
      "\t40: TRAIN loss 0.1634,  acc 0.9693 || VAL loss 0.5733, acc 0.8911\n",
      "\t50: TRAIN loss 0.0860,  acc 0.9856 || VAL loss 0.4574, acc 0.9208\n",
      "\t60: TRAIN loss 0.0847,  acc 0.9905 || VAL loss 0.5318, acc 0.9234\n",
      "\t70: TRAIN loss 0.0455,  acc 0.9952 || VAL loss 0.3879, acc 0.9392\n",
      "\t80: TRAIN loss 0.0441,  acc 0.9956 || VAL loss 0.4055, acc 0.9373\n",
      "\t90: TRAIN loss 0.0440,  acc 0.9951 || VAL loss 0.4183, acc 0.9379\n",
      "\t100: TRAIN loss 0.0434,  acc 0.9959 || VAL loss 0.4403, acc 0.9360\n",
      "\t110: TRAIN loss 0.1511,  acc 0.9832 || VAL loss 0.6153, acc 0.9151\n",
      "\t120: TRAIN loss 0.1306,  acc 0.9875 || VAL loss 0.5009, acc 0.9297\n",
      "\t130: TRAIN loss 0.1080,  acc 0.9914 || VAL loss 0.4900, acc 0.9367\n",
      "\t140: TRAIN loss 0.0505,  acc 0.9948 || VAL loss 0.4385, acc 0.9335\n",
      "\t150: TRAIN loss 0.0470,  acc 0.9954 || VAL loss 0.4383, acc 0.9360\n",
      "\t160: TRAIN loss 0.0478,  acc 0.9952 || VAL loss 0.4372, acc 0.9411\n",
      "\t170: TRAIN loss 0.0474,  acc 0.9946 || VAL loss 0.4347, acc 0.9379\n",
      "\t180: TRAIN loss 0.1069,  acc 0.9802 || VAL loss 0.5383, acc 0.9170\n",
      "\t190: TRAIN loss 0.0444,  acc 0.9952 || VAL loss 0.4701, acc 0.9367\n",
      "\t200: TRAIN loss 0.0341,  acc 0.9957 || VAL loss 0.5042, acc 0.9341\n",
      "\t210: TRAIN loss 0.0520,  acc 0.9948 || VAL loss 0.4575, acc 0.9348\n",
      "\t220: TRAIN loss 0.0511,  acc 0.9954 || VAL loss 0.4696, acc 0.9379\n",
      "\t230: TRAIN loss 0.0523,  acc 0.9946 || VAL loss 0.4734, acc 0.9367\n",
      "\t240: TRAIN loss 0.0794,  acc 0.9919 || VAL loss 0.5118, acc 0.9310\n",
      "\t250: TRAIN loss 0.0585,  acc 0.9952 || VAL loss 0.5044, acc 0.9373\n",
      "\t260: TRAIN loss 0.0587,  acc 0.9946 || VAL loss 0.5062, acc 0.9373\n",
      "\t270: TRAIN loss 0.0591,  acc 0.9945 || VAL loss 0.5185, acc 0.9341\n",
      "\t280: TRAIN loss 0.0384,  acc 0.9962 || VAL loss 0.4645, acc 0.9405\n",
      "\t290: TRAIN loss 0.0383,  acc 0.9962 || VAL loss 0.4733, acc 0.9417\n"
     ]
    }
   ],
   "source": [
    "best_result=best_model.fit(features,labels,validation_data=(features_test,labels_test),\n",
    "                  epochs=nepochs,batch_size=100,\n",
    "                  verbose=0,callbacks=[ReportCallback(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T10:37:23.759112Z",
     "start_time": "2019-01-15T10:37:23.506160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23580b0c278>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history=best_result.history\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history[\"loss\"],label=\"loss\")\n",
    "plt.plot(history[\"val_loss\"],label=\"valuation loss\")\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history[\"acc\"],label=\"accuracy\")\n",
    "plt.plot(history[\"val_acc\"],label=\"valuation accuracy\")\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T10:37:33.567732Z",
     "start_time": "2019-01-15T10:37:32.489833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9398353388220393"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred=np.argmax(best_model.predict(features_test),axis=1)\n",
    "np.mean(Y_pred==labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We have achieved nearly **94%** out of sample accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
